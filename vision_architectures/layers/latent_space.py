# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/layers/04_latent_space.ipynb.

# %% auto 0
__all__ = ['LatentEncoderConfig', 'LatentDecoderConfig', 'GaussianLatentSpaceConfig', 'LatentEncoder', 'LatentDecoder',
           'GaussianLatentSpace']

# %% ../../nbs/layers/04_latent_space.ipynb 2
from typing import Literal

import torch
from torch import nn
from torch.distributions import Normal, kl_divergence

from ..blocks.cnn import CNNBlock3D, CNNBlockConfig
from ..utils.custom_base_model import CustomBaseModel, Field, model_validator
from ..utils.rearrange import rearrange_channels

# %% ../../nbs/layers/04_latent_space.ipynb 4
class LatentEncoderConfig(CNNBlockConfig):
    init_low_var: bool = Field(True, description="Whether to initialize weights such that output variance is low")

    @model_validator(mode="before")
    @classmethod
    def validate_before(cls, data: dict):
        data.setdefault("in_channels", data.get("dim"))
        data.setdefault("out_channels", data.get("latent_dim"))
        return data

    @property
    def dim(self):
        return self.in_channels

    @property
    def latent_dim(self):
        return self.out_channels


class LatentDecoderConfig(CNNBlockConfig):
    @model_validator(mode="before")
    @classmethod
    def validate_before(cls, data: dict):
        data.setdefault("in_channels", data.get("latent_dim"))
        data.setdefault("out_channels", data.get("dim"))
        return data

    @property
    def latent_dim(self):
        return self.in_channels

    @property
    def dim(self):
        return self.out_channels


class GaussianLatentSpaceConfig(CustomBaseModel):
    pass

# %% ../../nbs/layers/04_latent_space.ipynb 6
class LatentEncoder(nn.Module):
    def __init__(self, config: LatentEncoderConfig = {}, checkpointing_level: int = 0, **kwargs):
        super().__init__()

        self.config = LatentEncoderConfig.model_validate(config | kwargs)

        latent_dim = self.config.latent_dim

        self.dim_mapper = CNNBlock3D(self.config, checkpointing_level)
        self.quant_conv_mu = nn.Conv3d(latent_dim, latent_dim, 1)
        self.quant_conv_log_var = nn.Conv3d(latent_dim, latent_dim, 1)

        if self.config.init_low_var:
            self.init_low_var()

    def init_low_var(self, bias_constant: float = -1.0):
        nn.init.zeros_(self.quant_conv_log_var.weight)
        nn.init.constant_(self.quant_conv_log_var.bias, bias_constant)

    def forward(self, x: torch.Tensor, channels_first: bool = True):
        # x: (b, [dim], z, y, x, [dim])

        x = rearrange_channels(x, channels_first, True)
        # (b, dim, z, y, x)

        x = self.dim_mapper(x, channels_first=True)
        # (b, latent_dim, z, y, x)

        z_mu = self.quant_conv_mu(x)
        z_log_var = self.quant_conv_log_var(x)
        z_log_var = torch.clamp(z_log_var, -30.0, 20.0)
        z_sigma = torch.exp(z_log_var / 2)
        # (b, latent_dim, z, y, x)

        z_mu = rearrange_channels(z_mu, True, channels_first)
        z_sigma = rearrange_channels(z_sigma, True, channels_first)
        # (b, [latent_dim], z, y, x, [latent_dim])

        return z_mu, z_sigma

# %% ../../nbs/layers/04_latent_space.ipynb 8
class LatentDecoder(nn.Module):
    def __init__(self, config: LatentDecoderConfig = {}, checkpointing_level: int = 0, **kwargs):
        super().__init__()

        self.config = LatentDecoderConfig.model_validate(config | kwargs)

        latent_dim = self.config.latent_dim

        self.post_quant_conv = nn.Conv3d(latent_dim, latent_dim, 1)
        self.dim_mapper = CNNBlock3D(self.config, checkpointing_level)

    def forward(self, z: torch.Tensor, channels_first: bool = True):
        # z: (b, [latent_dim], z, y, x, [latent_dim])

        z = rearrange_channels(z, channels_first, True)
        # (b, latent_dim, z, y, x)

        z = self.post_quant_conv(z)
        # (b, latent_dim, z, y, x)

        x = self.dim_mapper(z, channels_first=True)
        # (b, dim, z, y, x)

        x = rearrange_channels(x, True, channels_first)
        # (b, [dim], z, y, x, [dim])

        return x

# %% ../../nbs/layers/04_latent_space.ipynb 10
class GaussianLatentSpace(nn.Module):
    def __init__(self, config: GaussianLatentSpaceConfig = {}, **kwargs):
        super().__init__()

        self.config = GaussianLatentSpaceConfig.model_validate(config | kwargs)

    def sample(self, z_mu: torch.Tensor, z_sigma: torch.Tensor, force_sampling: bool = False):
        if not self.training and not force_sampling:
            return z_mu
        eps = torch.randn_like(z_sigma)
        z_vae = z_mu + eps * z_sigma
        return z_vae

    @staticmethod
    def kl_divergence(
        z_mu: torch.Tensor,
        z_sigma: torch.Tensor,
        prior_mu: torch.Tensor | None = None,
        prior_sigma: torch.Tensor | None = None,
        reduction: Literal["allsum", "channelssum"] | None = "allsum",
        channels_first: bool = True,
    ):
        if prior_mu is None:
            prior_mu = torch.zeros_like(z_mu)
        if prior_sigma is None:
            prior_sigma = torch.ones_like(z_sigma)

        prior = Normal(prior_mu, prior_sigma)
        posterior = Normal(z_mu, z_sigma)
        kl_div = kl_divergence(posterior, prior)

        if reduction is None:
            pass
        elif reduction == "allsum":
            kl_div = kl_div.sum(dim=list(range(1, kl_div.ndim))).mean()
        elif reduction == "channelssum":
            if channels_first:
                channels_dim = 1
            else:
                channels_dim = -1
            kl_div = kl_div.sum(dim=channels_dim).mean()
        else:
            raise NotImplementedError(f"Reduction {reduction} not implemented")

        return kl_div

    def forward(
        self,
        z_mu: torch.Tensor,
        z_sigma: torch.Tensor,
        prior_mu: torch.Tensor | None = None,
        prior_sigma: torch.Tensor | None = None,
        kl_divergence_reduction: Literal["allsum", "channelssum"] | None = "allsum",
        force_sampling: bool = False,
        channels_first: bool = True,
    ):
        return self.sample(z_mu, z_sigma, force_sampling), self.kl_divergence(
            z_mu, z_sigma, prior_mu, prior_sigma, kl_divergence_reduction, channels_first
        )
