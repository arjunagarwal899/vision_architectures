# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/blocks/03_se_3d.ipynb.

# %% auto 0
__all__ = ['SEBlock3DConfig', 'SEBlock3D']

# %% ../../nbs/blocks/03_se_3d.ipynb 2
import torch
from torch import nn

from .cnn import CNNBlock3D, CNNBlockConfig
from ..utils.activation_checkpointing import ActivationCheckpointing
from ..utils.rearrange import rearrange_channels

# %% ../../nbs/blocks/03_se_3d.ipynb 4
class SEBlock3DConfig(CNNBlockConfig):
    dim: int
    r: float

    kernel_size: int = 1
    normalization: str = "batchnorm3d"
    activation: str = "silu"

    in_channels: None = None  # determined by dim and r
    out_channels: None = None  # determined by dim and r

# %% ../../nbs/blocks/03_se_3d.ipynb 6
class SEBlock3D(nn.Module):
    def __init__(self, config: SEBlock3DConfig = {}, checkpointing_level: int = 0, **kwargs):
        super().__init__()

        self.config = SEBlock3DConfig.model_validate(config | kwargs)

        dim = self.config.dim
        r = self.config.r

        excitation_dim = int(dim // r)

        self.squeeze = nn.AdaptiveAvgPool3d((1, 1, 1))
        self.excite = nn.Sequential(
            CNNBlock3D(
                self.config.model_dump()
                | {
                    "in_channels": dim,
                    "out_channels": excitation_dim,
                },
                checkpointing_level,
            ),
            CNNBlock3D(
                self.config.model_dump()
                | {
                    "in_channels": excitation_dim,
                    "out_channels": dim,
                    "activation": "sigmoid",
                },
                checkpointing_level,
            ),
        )

        self.checkpointing_level2 = ActivationCheckpointing(2, checkpointing_level)

    def _forward(self, x: torch.Tensor, channels_first: bool = True):
        # x: (b, [dim], z, y, x, [dim])

        x = rearrange_channels(x, channels_first, True)
        # Now x is (b, dim, z, y, x)

        p = self.squeeze(x)
        # (b, dim, 1, 1, 1)
        p = self.excite(p)
        # (b, dim, 1, 1, 1)
        x = x * p
        # (b, dim, z, y, x)

        x = rearrange_channels(x, True, channels_first)
        # (b, [dim], z, y, x, [dim])

        return x

    def forward(self, *args, **kwargs):
        return self.checkpointing_level2(self._forward, *args, **kwargs)
