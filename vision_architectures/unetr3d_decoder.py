# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_unetr3d_decoder.ipynb.

# %% auto 0
__all__ = ['UNetR3DBlock', 'UNetR3DDecoder']

# %% ../nbs/02_unetr3d_decoder.ipynb 2
import torch

from torch import nn

# %% ../nbs/02_unetr3d_decoder.ipynb 5
class UNetR3DBlock(nn.Module):
    def __init__(self, in_dim, out_dim, conv_kernel_size, deconv_kernel_size, is_first_layer):
        super().__init__()

        self.conv = nn.Conv3d(
            in_dim, in_dim, kernel_size=conv_kernel_size, padding=tuple([k // 2 for k in conv_kernel_size])
        )
        if not is_first_layer:
            in_dim = in_dim * 2
        self.deconv = nn.ConvTranspose3d(
            in_dim, out_dim, kernel_size=deconv_kernel_size, stride=deconv_kernel_size, padding=0
        )

    def forward(self, current_layer, previous_layer=None):
        x = self.conv(current_layer)
        if previous_layer is not None:
            x = torch.cat([x, previous_layer], dim=1)
        x = self.deconv(x)
        return x

# %% ../nbs/02_unetr3d_decoder.ipynb 9
class UNetR3DDecoder(nn.Module):
    def __init__(self, config):
        super().__init__()

        self.blocks = nn.ModuleList()
        for i in range(len(config["stages"])):
            stage = config["stages"][-i - 1]

            in_dim = stage["_out_dim"]
            is_first_layer = i == 0

            if i == len(config["stages"]) - 1:
                out_dim = config["decoder"]["num_outputs"]
                deconv_kernel_size = stage["_out_patch_size"]
            else:
                out_dim = stage["_in_dim"]
                deconv_kernel_size = tuple([o // i for o, i in zip(stage["_out_patch_size"], stage["_in_patch_size"])])

            self.blocks.append(
                UNetR3DBlock(
                    in_dim=in_dim,
                    out_dim=out_dim,
                    conv_kernel_size=config["decoder"]["conv_kernel_size"],
                    deconv_kernel_size=deconv_kernel_size,
                    is_first_layer=is_first_layer,
                )
            )

    def forward(self, embeddings):
        # embeddings is a list of (B, C_layer, D_layer, W_layer, H_layer)
        embeddings = embeddings[::-1]

        decoded = None
        for i in range(len(embeddings)):
            embedding = embeddings[i]
            if i == 0:
                decoded = self.blocks[i](embedding)
            else:
                decoded = self.blocks[i](embedding, decoded)

        return decoded
