# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/06_cait_decoder_3d.ipynb.

# %% auto 0
__all__ = ['CaiT3DLayerMLP', 'CaiT3DMHCA', 'CaiT3DDecoderLayer', 'CaiT3DDecoder', 'CaiT3DModel']

# %% ../nbs/06_cait_decoder_3d.ipynb 2
import torch

from einops import repeat
from torch import nn
from .vit_3d import ViT3DMHCA, ViT3DLayerMLP

# %% ../nbs/06_cait_decoder_3d.ipynb 5
class CaiT3DMHCA(ViT3DMHCA):
    def forward(self, class_tokens: torch.Tensor, embeddings: torch.Tensor):
        return super().forward(class_tokens, torch.cat([class_tokens, embeddings], dim=1))

# %% ../nbs/06_cait_decoder_3d.ipynb 7
CaiT3DLayerMLP = ViT3DLayerMLP

# %% ../nbs/06_cait_decoder_3d.ipynb 9
class CaiT3DDecoderLayer(nn.Module):
    def __init__(
        self,
        dim,
        num_heads,
        intermediate_ratio,
        layer_norm_eps,
        attn_drop_prob=0.0,
        proj_drop_prob=0.0,
        mlp_drop_prob=0.0,
    ):
        super().__init__()

        self.mhca = CaiT3DMHCA(dim, num_heads, attn_drop_prob, proj_drop_prob)
        self.gamma1 = nn.Parameter(torch.empty(1, 1, dim))
        self.layernorm1 = nn.LayerNorm(dim, eps=layer_norm_eps)
        self.mlp = CaiT3DLayerMLP(dim, intermediate_ratio, mlp_drop_prob)
        self.gamma2 = nn.Parameter(torch.empty(1, 1, dim))
        self.layernorm2 = nn.LayerNorm(dim, eps=layer_norm_eps)

        nn.init.uniform_(self.gamma1, a=-1e-4, b=1e-4)
        nn.init.uniform_(self.gamma2, a=-1e-4, b=1e-4)

    def forward(self, class_tokens: torch.Tensor, embeddings: torch.Tensor):  # This uses post-normalization
        # class_tokens: (b, num_class_tokens, dim)
        # embeddings: (b, num_encoding_tokens, dim)

        res_connection1 = class_tokens
        # (b, num_tokens_in_q, dim)

        hidden_states = self.mhca(res_connection1, embeddings)
        hidden_states = self.gamma1 * hidden_states
        hidden_states = self.layernorm1(hidden_states)
        # (b, num_tokens_in_q, dim)

        res_connection2 = hidden_states + res_connection1
        # (b, num_tokens_in_q, dim)

        hidden_states = self.mlp(res_connection2)
        hidden_states = self.gamma2 * hidden_states
        hidden_states = self.layernorm2(hidden_states)
        # (b, num_tokens_in_q, dim)

        hidden_states = hidden_states + res_connection2
        # (b, num_tokens_in_q, dim)

        return hidden_states

# %% ../nbs/06_cait_decoder_3d.ipynb 12
class CaiT3DDecoder(nn.Module):
    def __init__(self, config):
        super().__init__()

        self.layers = nn.ModuleList(
            [
                CaiT3DDecoderLayer(
                    config["dim"],
                    config["num_heads"],
                    config["intermediate_ratio"],
                    config["layer_norm_eps"],
                    config["attn_drop_prob"],
                    config["proj_drop_prob"],
                    config["mlp_drop_prob"],
                )
                for _ in range(config["encoder_depth"])
            ]
        )

    def forward(self, class_tokens: torch.Tensor, embeddings: torch.Tensor):
        # class_tokens: (b, num_class_tokens, dim)
        # embeddings: (b, num_enbedding_tokens, dim)

        class_embeddings = class_tokens

        layer_outputs = []
        for decoder_layer in self.layers:
            class_embeddings = decoder_layer(class_embeddings, embeddings)
            # (b, num_class_tokens, dim)

            layer_outputs.append(class_embeddings)

        return class_embeddings, layer_outputs

# %% ../nbs/06_cait_decoder_3d.ipynb 15
class CaiT3DModel(nn.Module):
    def __init__(self, config):
        super().__init__()

        self.num_class_tokens = config["num_class_tokens"]
        self.class_tokens = nn.Parameter(torch.randn(1, config["num_class_tokens"], config["dim"]))

        self.decoder = CaiT3DDecoder(config)

        num_classes_per_class_token = config["num_classes_per_class_token"]
        self.classifiers = nn.ModuleList(
            [nn.Linear(config["dim"], num_classes_per_class_token[i]) for i in range(self.num_class_tokens)]
        )

    def forward(self, embeddings: torch.Tensor):
        # embeddings: (b, num_embedding_tokens, dim)

        class_tokens = repeat(self.class_tokens, "1 n d -> b n d", b=embeddings.shape[0])
        # (b, num_class_tokens, dim)

        class_embeddings, layer_outputs = self.decoder(class_tokens, embeddings)
        # class_embeddings: (b, num_class_tokens, dim)
        # layer_outputs: list of (b, num_embedding_tokens, dim)

        class_logits = [self.classifiers[i](class_embeddings[:, i]) for i in range(len(self.classifiers))]
        # (b, num_classes)

        return class_logits, class_embeddings, layer_outputs
