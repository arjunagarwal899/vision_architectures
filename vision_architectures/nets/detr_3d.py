# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/nets/06_detr_3d.ipynb.

# %% auto 0
__all__ = ['DETRDecoderConfig', 'DETRBBoxMLPConfig', 'DETR3DConfig', 'DETRDecoder', 'DETRBBoxMLP', 'DETR3D']

# %% ../../nbs/nets/06_detr_3d.ipynb 2
from functools import wraps
from typing import Literal

import torch
from einops import rearrange, repeat
from huggingface_hub import PyTorchModelHubMixin
from scipy.optimize import linear_sum_assignment
from torch import nn
from torch.nn import functional as F
from torch.nn.utils.rnn import pad_sequence

from ..blocks.transformer import Attention1DWithMLPConfig, TransformerDecoderBlock1D
from ..docstrings import populate_docstring
from ..layers.embeddings import AbsolutePositionEmbeddings3D, AbsolutePositionEmbeddings3DConfig
from vision_architectures.losses.class_balanced_cross_entropy_loss import (
    ClassBalancedCrossEntropyLoss,
    ClassBalancedCrossEntropyLossConfig,
)
from ..utils.activation_checkpointing import ActivationCheckpointing
from ..utils.custom_base_model import CustomBaseModel, Field, model_validator
from ..utils.rearrange import rearrange_channels

# %% ../../nbs/nets/06_detr_3d.ipynb 4
class DETRDecoderConfig(Attention1DWithMLPConfig):
    num_layers: int = Field(..., description="Number of transformer decoder layers.")


class DETRBBoxMLPConfig(CustomBaseModel):
    dim: int = Field(..., description="Dimension of the input features.")
    num_classes: int = Field(..., description="Number of classes for the bounding box predictions.")
    bbox_size_activation: Literal["sigmoid", "softplus"] = Field(
        "sigmoid",
        description=(
            'Activation function for the bounding box size. "sigmoid" for normalized coordinates, "softplus" '
            "for absolute coordinates."
        ),
    )

    @model_validator(mode="after")
    def validate(self):
        super().validate()
        assert self.num_classes > 0, "Number of classes must be greater than zero. If not predicting classes, set to 1."
        return self


class DETR3DConfig(DETRDecoderConfig, DETRBBoxMLPConfig, AbsolutePositionEmbeddings3DConfig):
    num_objects: int = Field(..., description="Maximum number of objects to detect.")
    drop_prob: float = Field(0.0, description="Dropout probability for input embeddings.")
    classification_cost_fn: Literal["softmax", "log_softmax"] = Field(
        "softmax",
        description=(
            "Method used to compute classification cost in Hungarian matching. While softmax is the default (as per "
            "the paper), log_sofmtax is encouraged as the final bipartite matching loss calculation uses cross entropy "
            "loss which performs log_softmax and NLLLoss internally making log_softmax more apt."
        ),
    )
    classification_loss_fn: (
        Literal["cross_entropy", "class_balanced_cross_entropy"] | dict | ClassBalancedCrossEntropyLossConfig
    ) = Field("cross_entropy", description="Loss function for bbox classification.")

    @model_validator(mode="after")
    def validate(self):
        super().validate()

        # Create an object of ClassBalancedCrossEntropyLossConfig if applicable
        if self.classification_loss_fn == "class_balanced_cross_entropy":
            self.classification_loss_fn = ClassBalancedCrossEntropyLossConfig(num_classes=self.num_classes + 1)
        elif isinstance(self.classification_loss_fn, dict):
            self.classification_loss_fn = ClassBalancedCrossEntropyLossConfig.model_validate(
                self.classification_loss_fn
            )

        return self

# %% ../../nbs/nets/06_detr_3d.ipynb 7
class DETRDecoder(nn.Module, PyTorchModelHubMixin):
    """DETR Transformer decoder."""

    @populate_docstring
    def __init__(self, config: DETRDecoderConfig = {}, checkpointing_level: int = 0, **kwargs):
        """Initialize the DETRDecoder. Activation checkpointing level 4.

        Args:
            config: {CONFIG_INSTANCE_DOC}
            checkpointing_level: {CHECKPOINTING_LEVEL_DOC}
            **kwargs: {CONFIG_KWARGS_DOC}
        """
        super().__init__()

        self.config = DETRDecoderConfig.model_validate(config | kwargs)

        self.layers = nn.ModuleList(
            [TransformerDecoderBlock1D(config, checkpointing_level) for _ in range(self.config.num_layers)]
        )

        self.checkpointing_level4 = ActivationCheckpointing(4, checkpointing_level)

    @populate_docstring
    def _forward(
        self, object_queries: torch.Tensor, embeddings: torch.Tensor, return_intermediates: bool = False
    ) -> torch.Tensor | tuple[torch.Tensor, list[torch.Tensor]]:
        """Forward pass of the DETR3D decoder.

        Args:
            object_queries: Tokens that represent object queries. {INPUT_1D_DOC}
            embeddings: Actual embeddings of the input. {INPUT_1D_DOC}
            return_intermediates: If True, also returns the outputs of all layers. Defaults to False.

        Returns:
            If return_intermediates is True, returns the final object embeddings and a list of outputs from all layers.
            Otherwise, returns only the final object embeddings.
        """
        # object_queries: (b, num_possible_objects, dim)
        # embeddings: (b, num_embed_tokens, dim)

        object_embeddings = object_queries

        layer_outputs = []
        for layer in self.layers:
            object_embeddings = layer(object_embeddings, embeddings)
            layer_outputs.append(object_embeddings)

        if return_intermediates:
            return object_embeddings, layer_outputs
        return object_embeddings

    @wraps(_forward)
    def forward(self, *args, **kwargs):
        return self.checkpointing_level4(self._forward, *args, **kwargs)

# %% ../../nbs/nets/06_detr_3d.ipynb 9
class DETRBBoxMLP(nn.Module):
    """DETR Bounding Box MLP. This module predicts bounding boxes and class scores from object query embeddings."""

    @populate_docstring
    def __init__(self, config: DETRBBoxMLPConfig = {}, **kwargs):
        """Initialize the DETRBBoxMLP.

        Args:
            config: {CONFIG_INSTANCE_DOC}
            **kwargs: {CONFIG_KWARGS_DOC}
        """
        super().__init__()

        self.config = DETRBBoxMLPConfig.model_validate(config | kwargs)

        # Keeping bbox and classification heads separate so that bias-init/clipping/freezing can be done if needed
        self.bbox_head = nn.Linear(self.config.dim, 6)
        self.class_head = nn.Linear(self.config.dim, 1 + self.config.num_classes)

    @populate_docstring
    def forward(
        self,
        object_embeddings: torch.Tensor,
    ) -> torch.Tensor:
        """Forward pass of the DETRBBoxMLP.

        Args:
            object_embeddings: Object embeddings from the DETR decoder. {INPUT_1D_DOC}

        Returns:
            A tensor of shape (b, num_possible_objects, 1 objectness class + 6 bounding box parameters + num_classes)
            containing the predicted bounding boxes and class scores. {BOUNDING_BOXES_FORMAT_DOC}
        """
        # object_embeddings: (b, num_possible_objects, dim)

        bbox_parameters: torch.Tensor = self.bbox_head(object_embeddings)
        class_logits: torch.Tensor = self.class_head(object_embeddings)
        # (b, num_possible_objects, 6 + 1 + num_classes)

        # Bound the bounding box parameters
        centers, sizes = bbox_parameters[:, :, :3], bbox_parameters[:, :, 3:6]
        centers = centers.sigmoid()  # center coordinates should be in the bbox
        if self.config.bbox_size_activation == "sigmoid":
            sizes = sizes.sigmoid()  # sizes should be between 0 and 1
        elif self.config.bbox_size_activation == "softplus":
            sizes = F.softplus(sizes)  # sizes should be positive but unbounded
        bboxes = torch.cat([centers, sizes, class_logits], dim=-1)

        return bboxes

# %% ../../nbs/nets/06_detr_3d.ipynb 13
class DETR3D(nn.Module, PyTorchModelHubMixin):
    """DETR 3D model. Also implements bipartite matching loss which is essential for DETR training."""

    @populate_docstring
    def __init__(self, config: DETR3DConfig = {}, checkpointing_level: int = 0, **kwargs):
        """Initialize the DETR3D. Activation checkpointing level 4.

        Args:
            config: {CONFIG_INSTANCE_DOC}
            checkpointing_level: {CHECKPOINTING_LEVEL_DOC}
            **kwargs: {CONFIG_KWARGS_DOC}
        """
        super().__init__()

        self.config = DETR3DConfig.model_validate(config | kwargs)

        self.position_embeddings = AbsolutePositionEmbeddings3D(config)
        self.pos_drop = nn.Dropout(self.config.drop_prob)
        self.num_possible_objects = self.config.num_objects
        self.object_queries = nn.Parameter(torch.randn(1, self.num_possible_objects, self.config.dim) * 0.01)
        self.decoder = DETRDecoder(config, checkpointing_level)
        self.bbox_mlp = DETRBBoxMLP(config)

        self.class_balanced_cross_entropy_loss = None
        if isinstance(self.config.classification_loss_fn, ClassBalancedCrossEntropyLossConfig):
            self.class_balanced_cross_entropy_loss = ClassBalancedCrossEntropyLoss(
                config=self.config.classification_loss_fn
            )

        self.checkpointing_level4 = ActivationCheckpointing(4, checkpointing_level)

    @populate_docstring
    def _forward(
        self,
        embeddings: torch.Tensor,
        spacings: torch.Tensor | None = None,
        channels_first: bool = True,
        return_intermediates: bool = False,
    ) -> torch.Tensor | tuple[torch.Tensor, torch.Tensor, list[torch.Tensor]]:
        """Forward pass of the DETR3D.

        Args:
            embeddings: Encoded input features. {INPUT_3D_DOC}
            spacings: {SPACINGS_DOC}
            channels_first: {CHANNELS_FIRST_DOC}
            return_intermediates: If True, also returns the outputs of all layers. Defaults to False.

        Returns:
            A tuple containing bounding boxes, object embeddings, and layer outputs if return_intermediates is True.
            Else, returns only the bounding boxes. {BOUNDING_BOXES_FORMAT_DOC}
        """
        # embeddings: (b, [dim], num_tokens_z, num_tokens_y, num_tokens_x, [dim])
        # spacings: (b, 3)

        embeddings = rearrange_channels(embeddings, channels_first, True)
        # (b, dim, num_tokens_z, num_tokens_y, num_tokens_x)

        embeddings = self.position_embeddings(embeddings, spacings=spacings)
        embeddings = self.pos_drop(embeddings)
        # (b, dim, num_tokens_z, num_tokens_y, num_tokens_x)

        embeddings = rearrange(embeddings, "b d z y x -> b (z y x) d")
        # (b, num_embed_tokens, dim)

        object_queries = repeat(self.object_queries, "1 n d -> b n d", b=embeddings.shape[0])
        # (b, num_possible_objects, dim)

        object_embeddings, layer_outputs = self.decoder(object_queries, embeddings, return_intermediates=True)
        # object_embeddings: (b, num_possible_objects, dim)
        # layer_outputs: list of (b, num_possible_objects, dim)

        bboxes = self.bbox_mlp(object_embeddings)
        # (b, num_possible_objects, 6 + 1 + num_classes)

        if return_intermediates:
            return bboxes, object_embeddings, layer_outputs

        return bboxes

    @wraps(_forward)
    def forward(self, *args, **kwargs):
        return self.checkpointing_level4(self._forward, *args, **kwargs)

    def bipartite_matching_loss(
        self,
        pred: torch.Tensor,
        target: torch.Tensor | list[torch.Tensor],
        classification_cost_weight: float = 1.0,
        bbox_l1_cost_weight: float = 1.0,
        bbox_giou_cost_weight: float = 1.0,
        reduction: str = "mean",
        return_matching: bool = False,
        return_loss_components: bool = False,
    ) -> torch.Tensor | tuple[torch.Tensor, list] | tuple[torch.Tensor, dict] | tuple[torch.Tensor, list, dict]:
        """Bipartite matching loss for DETR. The classes are expected to optimize for a multi-class classification
        problem. Expects raw logits in class predictions, not probabilities. Use ``logits_to_scores_fn=None`` in the
        ``forward`` function to avoid applying any transformation.

        Args:
            pred: Predicted bounding boxes and class scores. It should be of shape
                `(B, num_objects, 6 + 1 + num_classes)`. Number of objects and number of classes will be inferred from
                here.
            target: Target bounding boxes and class scores. If provided as a list, each element should be a tensor for
                the corresponding batch element in ``pred`` and therefore should have a length of `B`. Each tensor
                should have less than or equal to the number of objects in `pred`. The number of classes can either be
                the exact same as in `pred`, or it should be 1 argmax (one-cold) decoding.
            classification_cost_weight: Weight for the classification cost in hungarian matching.
            bbox_l1_cost_weight: Weight for the bounding box L1 loss cost in hungarian matching.
            bbox_giou_cost_weight: Weight for the bounding box IoU cost in hungarian matching.
            reduction: Specifies the reduction to apply to the output.
            return_matching: Whether or not to return the matched indices from the bipartite matching.
            return_loss_components: Whether or not to return the individual loss components.

        Returns:
            A tensor containing the bipartite matching loss with the shape depending on the `reduction` argument. If
            `return_matching` is True, also returns a list of tuples containing matched indices for predictions and
            targets. Each tuple is of the form `(pred_indices, target_indices)`, where `pred_indices` and
            `target_indices` are lists of indices for the matched predictions and targets, respectively. If
            `return_loss_components` is True, also returns a dict of each loss component reduced based on `reduction`.
        """
        B = pred.shape[0]

        # Convert target to a list of tensors if not already
        if isinstance(target, torch.Tensor):
            target = list(target)

        # argmax encode the class labels if they are not already
        for i in range(len(target)):
            if target[i].shape[-1] > 7:  # 6 bbox + 1 class
                target[i] = torch.cat([target[i][:, :6], target[i][:, 6:].argmax(-1, keepdims=True)], dim=-1)

        # Perform hungarian matching
        matched_indices = self.hungarian_matching(
            pred, target, classification_cost_weight, bbox_l1_cost_weight, bbox_giou_cost_weight
        )

        # Update class prevalences in class balanced cross entropy loss
        self._update_class_prevalences(target)

        losses = {
            "classification_loss": [],
            "bbox_l1_loss": [],
            "bbox_giou_loss": [],
            "total_loss": [],
        }
        for i in range(B):
            batch_losses = {}

            pred_indices, target_indices = matched_indices[i]

            # Classification loss for ALL predictions
            all_class_labels = torch.zeros_like(pred[i][:, 6], dtype=torch.long)
            all_class_labels[pred_indices] = target[i][target_indices, 6].long()
            all_pred_classes = pred[i][..., 6:]
            if self.class_balanced_cross_entropy_loss is None:
                batch_losses["classification_loss"] = F.cross_entropy(all_pred_classes, all_class_labels)
            else:
                batch_losses["classification_loss"] = self.class_balanced_cross_entropy_loss(
                    all_pred_classes, all_class_labels, update_class_prevalences=False
                )

            # Calculate all other losses only if prediction and target have objects
            if pred_indices != [] and target_indices != []:
                matched_pred = pred[i][pred_indices]
                matched_target = target[i][target_indices]

                pred_bboxes = matched_pred[:, :6].clone()
                target_bboxes = matched_target[:, :6].clone()

                # Compute losses for matched pairs
                # BBox L1 loss
                batch_losses["bbox_l1_loss"] = F.l1_loss(pred_bboxes, target_bboxes)

                # For IOU calculation, it does not matter if bboxes are in actual pixel lengths or normalized based on
                # image size, metric value will be the same.

                # BBox IOU loss
                batch_losses["bbox_giou_loss"] = 1 - DETR3D._generalized_bbox_iou(pred_bboxes, target_bboxes).mean()

            # Total loss for this batch element
            total_loss = (
                classification_cost_weight * batch_losses.get("classification_loss", 0.0)
                + bbox_l1_cost_weight * batch_losses.get("bbox_l1_loss", 0.0)
                + bbox_giou_cost_weight * batch_losses.get("bbox_giou_loss", 0.0)
            )

            # Add to losses
            losses["classification_loss"].append(
                batch_losses.get("classification_loss", torch.tensor(torch.nan, device=pred.device)),
            )
            losses["bbox_l1_loss"].append(
                batch_losses.get("bbox_l1_loss", torch.tensor(torch.nan, device=pred.device)),
            )
            losses["bbox_giou_loss"].append(
                batch_losses.get("bbox_giou_loss", torch.tensor(torch.nan, device=pred.device)),
            )
            losses["total_loss"].append(total_loss)

        # Stack batch losses and apply reduction
        for key in losses:
            loss = torch.stack(losses[key])

            if reduction == "mean":
                loss = loss.nanmean()
            elif reduction == "sum":
                loss = loss.nansum()
            elif reduction == "none" or reduction is None:
                pass
            else:
                raise ValueError(f"Invalid reduction mode: {reduction}")

            losses[key] = loss

        loss = losses["total_loss"]
        losses.pop("total_loss", None)

        match return_matching, return_loss_components:
            case False, False:
                return loss
            case True, False:
                return loss, matched_indices
            case False, True:
                return loss, losses
            case True, True:
                return loss, matched_indices, losses

    @torch.no_grad()
    def hungarian_matching(
        self,
        pred: torch.Tensor,
        target: list[torch.Tensor],
        classification_cost_weight: float = 1.0,
        bbox_l1_cost_weight: float = 1.0,
        bbox_giou_cost_weight: float = 1.0,
    ) -> list[tuple[list[int], list[int]]]:
        """Hungarian matching between predictions and targets.

        Args:
            pred: Predicted bounding boxes and class scores. It should be of shape
                `(B, num_objects, 6 + 1 + num_classes)`. Number of objects and number of classes will be inferred from
                here.
            target: Target bounding boxes and class scores. This is expected in argmax encoding or one-hot encoding.
            classification_cost_weight: Weight for the classification cost.
            bbox_l1_cost_weight: Weight for the bounding box L1 loss cost.
            bbox_giou_cost_weight: Weight for the bounding box IoU cost.

        Returns:
            A list of tuples containing matched indices for predictions and targets. Each tuple is of the form
            `(pred_indices, target_indices)`, where `pred_indices` and `target_indices` are lists of indices for the
            matched predictions and targets, respectively.
        """
        B = pred.shape[0]

        matched_indices = []
        for i in range(B):
            pred_bboxes = pred[i, :, :6]  # (num_objects, 6)
            target_bboxes = target[i][:, :6]  # (<=num_objects, 6)

            # If either prediction or target has no objects, skip matching
            if pred_bboxes.shape[0] == 0 or target_bboxes.shape[0] == 0:
                matched_indices.append(([], []))
                continue

            pred_class_logits = pred[i, :, 6:]  # (num_objects, num_classes)
            target_class_labels = target[i][:, 6].long()  # (<=num_objects,) this is in argmax encoding

            # ----- Cost matrix calculation -----

            # Classification cost
            if self.config.classification_cost_fn == "softmax":
                pred_class_probabilities = F.softmax(pred_class_logits, dim=-1)
            elif self.config.classification_cost_fn == "log_softmax":
                pred_class_probabilities = F.log_softmax(pred_class_logits, dim=-1)
            # (num_objects, num_classes)

            classification_cost = -pred_class_probabilities[:, target_class_labels]
            # (num_objects, <=num_objects)

            # L1 loss for bounding boxes
            bbox_l1_cost = torch.cdist(pred_bboxes, target_bboxes, p=1)
            # (num_objects, <=num_objects)

            # IOU cost for bounding boxes
            bbox_giou_cost = 1 - DETR3D._generalized_pairwise_bbox_iou(pred_bboxes, target_bboxes)
            # (num_objects, <=num_objects)

            # Total cost matrix
            cost_matrix = (
                classification_cost_weight * classification_cost
                + bbox_l1_cost_weight * bbox_l1_cost
                + bbox_giou_cost_weight * bbox_giou_cost
            )
            # (num_objects, <=num_objects)

            # Hungarian matching
            pred_indices_element, target_indices_element = linear_sum_assignment(cost_matrix.detach().cpu().numpy())

            matched_indices.append((list(pred_indices_element), list(target_indices_element)))

        return matched_indices

    @staticmethod
    @populate_docstring
    def _generalized_bbox_iou(
        pred_bboxes: torch.Tensor,
        target_bboxes: torch.Tensor,
    ) -> torch.Tensor:
        """Compute the IoU loss between two matched sets of bounding boxes.

        Args:
            pred_bboxes: Predicted bounding boxes of shape `(num_boxes, 6)`. {BOUNDING_BOXES_FORMAT_DOC}
            target_bboxes: Target bounding boxes of shape `(num_boxes, 6)`. {BOUNDING_BOXES_FORMAT_DOC}

        Returns:
            A tensor containing the IoU loss.
        """

        # Convert bboxes from center format (z, y, x, d, h, w) to corner format
        def center_to_corners(bboxes):
            centers = bboxes[:, :3]
            sizes = bboxes[:, 3:] / 2
            min_coords = centers - sizes
            max_coords = centers + sizes
            return torch.cat([min_coords, max_coords], dim=1)  # shape (N, 6)

        pred_corners = center_to_corners(pred_bboxes)
        target_corners = center_to_corners(target_bboxes)

        # Intersection corners
        max_min = torch.max(pred_corners[:, :3], target_corners[:, :3])
        min_max = torch.min(pred_corners[:, 3:], target_corners[:, 3:])
        inter_dims = (min_max - max_min).clamp(min=0)
        inter_vol = inter_dims.prod(dim=1)

        # Volumes
        pred_dims = pred_corners[:, 3:] - pred_corners[:, :3]
        target_dims = target_corners[:, 3:] - target_corners[:, :3]
        pred_vol = pred_dims.prod(dim=1)
        target_vol = target_dims.prod(dim=1)
        union_vol = pred_vol + target_vol - inter_vol

        # Enclosing box corners
        enc_min = torch.min(pred_corners[:, :3], target_corners[:, :3])
        enc_max = torch.max(pred_corners[:, 3:], target_corners[:, 3:])
        enc_dims = (enc_max - enc_min).clamp(min=0)
        enc_vol = enc_dims.prod(dim=1)

        iou = inter_vol / union_vol.clamp(min=1e-7)
        gious = iou - (enc_vol - union_vol) / enc_vol.clamp(min=1e-7)

        return gious

    @staticmethod
    @populate_docstring
    def _generalized_pairwise_bbox_iou(
        pred_bboxes: torch.Tensor,
        target_bboxes: torch.Tensor,
    ) -> torch.Tensor:
        """Compute the IoU loss between all combinations of predicted and target bounding boxes.

        Args:
            pred_bboxes: Predicted bounding boxes of shape `(num_objects, 6)`. {BOUNDING_BOXES_FORMAT_DOC}
            target_bboxes: Target bounding boxes of shape `(<=num_objects, 6)`. {BOUNDING_BOXES_FORMAT_DOC}

        Returns:
            A tensor containing the IoU losses of all combinations.
        """
        # Compute pairwise IoU
        gious = []
        for i in range(pred_bboxes.shape[0]):
            row_gious = []
            for j in range(target_bboxes.shape[0]):
                row_gious.append(DETR3D._generalized_bbox_iou(pred_bboxes[i : i + 1], target_bboxes[j : j + 1]).mean())

            gious.append(torch.stack(row_gious))

        return torch.stack(gious)

    def _update_class_prevalences(self, target: list[torch.Tensor]):
        """Update the class prevalences based on the classes present in the ground truth

        Args:
            target: A list of ground truth tensors, each of shape (num_objects, 7) where the last dimension contains the
                bounding box class.
        """
        if self.class_balanced_cross_entropy_loss is not None:
            # Note that target classes will not be in order here. But since counts are all that matters, this doesn't
            # affect the results
            target_classes = pad_sequence(target, batch_first=True)[..., -1].long()
            if target_classes.shape[-1] > self.config.num_objects:
                # If there are more than self.config.num_objects targets, only the first self.config.num_objects will be
                # considered
                target_classes = target_classes[..., : self.config.num_objects]
            elif target_classes.shape[-1] < self.config.num_objects:
                # If there are less than self.config.num_objects targets, pad with background class
                target_classes = F.pad(target_classes, (0, self.config.num_objects - target_classes.shape[-1]), value=0)
            self.class_balanced_cross_entropy_loss.update_class_prevalences(target_classes)
