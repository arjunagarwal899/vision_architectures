{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp vit_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from einops import rearrange, repeat\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = {\n",
    "    \"patch_size\": (8, 16, 16),\n",
    "    \"in_channels\": 1,\n",
    "    \"use_absolute_position_embeddings\": True,\n",
    "    \"learnable_absolute_position_embeddings\": False,\n",
    "    \"embed_spacing_info\": False,\n",
    "    \"image_size\": (32, 512, 512),\n",
    "    \"dim\": 768,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_coords_grid(grid_size):\n",
    "    d, h, w = grid_size\n",
    "\n",
    "    grid_d = torch.arange(d, dtype=torch.int32)\n",
    "    grid_h = torch.arange(h, dtype=torch.int32)\n",
    "    grid_w = torch.arange(w, dtype=torch.int32)\n",
    "\n",
    "    grid = torch.meshgrid(grid_w, grid_h, grid_d, indexing=\"ij\")\n",
    "    grid = torch.stack(grid, axis=0)\n",
    "    # (3, d, h, w)\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ViT3DMHA(nn.Module):  # Multi-head-attention\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        attn_drop_prob=0.0,\n",
    "        proj_drop_prob=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert dim % num_heads == 0, \"dimension must be divisible by number of heads\"\n",
    "\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.per_head_dim = int(dim // num_heads)\n",
    "\n",
    "        self.W_q = nn.Linear(dim, dim)\n",
    "        self.W_k = nn.Linear(dim, dim)\n",
    "        self.W_v = nn.Linear(dim, dim)\n",
    "        self.attn_drop = nn.Dropout(attn_drop_prob)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop_prob)\n",
    "\n",
    "    def forward(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor):\n",
    "        # q: (b, num_tokens_of_q, dim)\n",
    "        # k: (b, num_tokens_of_k, dim)\n",
    "        # v: (b, num_tokens_of_v, dim)\n",
    "\n",
    "        query = rearrange(\n",
    "            self.W_q(q), \"b num_tokens (num_heads d) -> b num_heads num_tokens d\", num_heads=self.num_heads\n",
    "        )\n",
    "        key = rearrange(self.W_k(k), \"b num_tokens (num_heads d) -> b num_heads num_tokens d\", num_heads=self.num_heads)\n",
    "        value = rearrange(\n",
    "            self.W_v(v), \"b num_tokens (num_heads d) -> b num_heads num_tokens d\", num_heads=self.num_heads\n",
    "        )\n",
    "        # Each is (b, num_heads, num_tokens_in_the_tensor, per_head_dim)\n",
    "\n",
    "        attention_scores = query @ rearrange(key, \"b num_heads num_tokens d -> b num_heads d num_tokens\")\n",
    "        attention_scores = attention_scores / (self.per_head_dim**0.5)\n",
    "        # (b, num_heads, num_tokens_in_q, num_tokens_in_kv)\n",
    "\n",
    "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
    "        attention_probs = self.attn_drop(attention_probs)\n",
    "        # (b, num_heads, num_tokens_in_q, num_tokens_in_kv)\n",
    "\n",
    "        context = attention_probs @ value\n",
    "        # (b, num_heads, num_tokens_in_q, per_head_dim)\n",
    "        context = rearrange(context, \"b num_heads num_tokens d -> b num_tokens (num_heads d)\")\n",
    "        # (b, num_tokens_of_q, dim)\n",
    "\n",
    "        context = self.proj(context)\n",
    "        context = self.proj_drop(context)\n",
    "        # (b, num_tokens_of_q, dim)\n",
    "\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ViT3DMHSA(ViT3DMHA):  # Multi head self attention\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        attn_drop_prob=0.0,\n",
    "        proj_drop_prob=0.0,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            dim,\n",
    "            num_heads,\n",
    "            attn_drop_prob,\n",
    "            proj_drop_prob,\n",
    "        )\n",
    "\n",
    "    def forward(self, qkv: torch.Tensor):\n",
    "        return super().forward(qkv, qkv, qkv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mViT3DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m54\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = ViT3DMHSA(54, 6)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 64, 54)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ViT3DMHCA(ViT3DMHA):  # Multi head cross attention\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        attn_drop_prob=0.0,\n",
    "        proj_drop_prob=0.0,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            dim,\n",
    "            num_heads,\n",
    "            attn_drop_prob,\n",
    "            proj_drop_prob,\n",
    "        )\n",
    "\n",
    "    def forward(self, q: torch.Tensor, kv: torch.Tensor):\n",
    "        return super().forward(q, kv, kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mViT3DMHCA\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m54\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = ViT3DMHCA(54, 6)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 64, 54), torch.randn(2, 64, 54)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mViT3DMHCA\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m54\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = ViT3DMHCA(54, 6)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 1, 54), torch.randn(2, 64, 54)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ViT3DLayerMLP(nn.Module):\n",
    "    def __init__(self, dim, intermediate_ratio, dropout_prob=0.0):\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.Linear(dim, dim * intermediate_ratio)\n",
    "        self.act = nn.GELU()\n",
    "        self.dense2 = nn.Linear(dim * intermediate_ratio, dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (b, num_tokens, dim)\n",
    "        hidden_states = self.dense1(hidden_states)\n",
    "        hidden_states = self.act(hidden_states)\n",
    "        hidden_states = self.dense2(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mViT3DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m16384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m16384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = ViT3DLayerMLP(64, 256)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 64, 64)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ViT3DEncoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        intermediate_ratio,\n",
    "        layer_norm_eps,\n",
    "        attn_drop_prob=0.0,\n",
    "        proj_drop_prob=0.0,\n",
    "        mlp_drop_prob=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mhsa = ViT3DMHSA(dim, num_heads, attn_drop_prob, proj_drop_prob)\n",
    "        self.layernorm1 = nn.LayerNorm(dim, eps=layer_norm_eps)\n",
    "        self.mlp = ViT3DLayerMLP(dim, intermediate_ratio, mlp_drop_prob)\n",
    "        self.layernorm2 = nn.LayerNorm(dim, eps=layer_norm_eps)\n",
    "\n",
    "    def forward(self, qkv: torch.Tensor):\n",
    "        \"\"\"Note: This uses post-normalization instead of pre-normalization. This is inspired by SwinV2\"\"\"\n",
    "        # qkv: (b, num_tokens, dim)\n",
    "\n",
    "        res_connection1 = qkv\n",
    "        # (b, num_tokens, dim)\n",
    "\n",
    "        hidden_states = self.mhsa(qkv)\n",
    "        hidden_states = self.layernorm1(hidden_states)\n",
    "        # (b, num_tokens, dim)\n",
    "\n",
    "        res_connection2 = hidden_states + res_connection1\n",
    "        # (b, num_tokens, dim)\n",
    "\n",
    "        hidden_states = self.mlp(res_connection2)\n",
    "        hidden_states = self.layernorm2(hidden_states)\n",
    "        # (b, num_tokens, dim)\n",
    "\n",
    "        hidden_states = hidden_states + res_connection2\n",
    "        # (b, num_tokens, dim)\n",
    "\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mViT3DEncoderLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mViT3DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m52\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mViT3DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m104\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m104\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m52\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m52\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = ViT3DEncoderLayer(52, 4, 2, 1e-6)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 64, 52)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ViT3DDecoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        intermediate_ratio,\n",
    "        layer_norm_eps,\n",
    "        attn_drop_prob=0.0,\n",
    "        proj_drop_prob=0.0,\n",
    "        mlp_drop_prob=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mhsa = ViT3DMHSA(dim, num_heads, attn_drop_prob, proj_drop_prob)\n",
    "        self.layernorm1 = nn.LayerNorm(dim, eps=layer_norm_eps)\n",
    "        self.mhca = ViT3DMHCA(dim, num_heads, attn_drop_prob, proj_drop_prob)\n",
    "        self.layernorm2 = nn.LayerNorm(dim, eps=layer_norm_eps)\n",
    "        self.mlp = ViT3DLayerMLP(dim, intermediate_ratio, mlp_drop_prob)\n",
    "        self.layernorm3 = nn.LayerNorm(dim, eps=layer_norm_eps)\n",
    "\n",
    "    def forward(self, q: torch.Tensor, kv: torch.Tensor):  # This uses post-normalization\n",
    "        # q: (b, num_tokens_in_q, dim)\n",
    "        # kv: (b, num_tokens_in_kv, dim)\n",
    "\n",
    "        res_connection1 = q\n",
    "        # (b, num_tokens_in_q, dim)\n",
    "\n",
    "        hidden_states_q = self.mhsa(q)\n",
    "        hidden_states_q = self.layernorm1(hidden_states_q)\n",
    "        # (b, num_tokens_in_q, dim)\n",
    "\n",
    "        res_connection2 = hidden_states_q + res_connection1\n",
    "        # (b, num_tokens_in_q, dim)\n",
    "\n",
    "        hidden_states = self.mhca(res_connection2, kv)\n",
    "        hidden_states = self.layernorm2(hidden_states)\n",
    "        # (b, num_tokens_in_q, dim)\n",
    "\n",
    "        res_connection3 = hidden_states + res_connection2\n",
    "        # (b, num_tokens_in_q, dim)\n",
    "\n",
    "        hidden_states = self.mlp(res_connection3)\n",
    "        hidden_states = self.layernorm3(hidden_states)\n",
    "        # (b, num_tokens_in_q, dim)\n",
    "\n",
    "        hidden_states = hidden_states + res_connection3\n",
    "        # (b, num_tokens_in_q, dim)\n",
    "\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mViT3DDecoderLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mViT3DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m52\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmhca\u001b[1m)\u001b[0m: \u001b[1;35mViT3DMHCA\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m52\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mViT3DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m104\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m104\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayernorm3\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m52\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m52\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = ViT3DDecoderLayer(52, 4, 2, 1e-6)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 64, 52), torch.randn(2, 64, 52)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mViT3DDecoderLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mViT3DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m52\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmhca\u001b[1m)\u001b[0m: \u001b[1;35mViT3DMHCA\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m52\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mViT3DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m104\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m104\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m52\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayernorm3\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m52\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m52\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = ViT3DDecoderLayer(52, 4, 2, 1e-6)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 3, 52), torch.randn(2, 64, 52)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ViT3DEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                ViT3DEncoderLayer(\n",
    "                    config[\"dim\"],\n",
    "                    config[\"num_heads\"],\n",
    "                    config[\"intermediate_ratio\"],\n",
    "                    config[\"layer_norm_eps\"],\n",
    "                    config[\"attn_drop_prob\"],\n",
    "                    config[\"proj_drop_prob\"],\n",
    "                    config[\"mlp_drop_prob\"],\n",
    "                )\n",
    "                for _ in range(config[\"encoder_depth\"])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, embeddings: torch.Tensor):\n",
    "        # hidden_states: (b, num_tokens, dim)\n",
    "\n",
    "        layer_outputs = []\n",
    "        for encoder_layer in self.layers:\n",
    "            embeddings = encoder_layer(embeddings)\n",
    "            # (b, num_tokens, dim)\n",
    "\n",
    "            layer_outputs.append(embeddings)\n",
    "\n",
    "        return embeddings, layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mViT3DEncoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayers\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m5\u001b[0m x \u001b[1;35mViT3DEncoderLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mViT3DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m54\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mViT3DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m54\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m54\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m54\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m54\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m54\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m54\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m54\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"dim\": 54,\n",
    "    \"num_heads\": 6,\n",
    "    \"intermediate_ratio\": 2,\n",
    "    \"layer_norm_eps\": 1e-6,\n",
    "    \"attn_drop_prob\": 0.0,\n",
    "    \"proj_drop_prob\": 0.0,\n",
    "    \"mlp_drop_prob\": 0.0,\n",
    "    \"encoder_depth\": 5,\n",
    "}\n",
    "\n",
    "test = ViT3DEncoder(test_config)\n",
    "display(test)\n",
    "o = test(torch.randn(2, 64, 54))\n",
    "display((o[0].shape, [x.shape for x in o[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ViT3DPatchEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        patch_size = config[\"patch_size\"]\n",
    "        num_channels = config[\"in_channels\"]\n",
    "        dim = config[\"dim\"]\n",
    "\n",
    "        self.patch_embeddings = nn.Conv3d(\n",
    "            in_channels=num_channels,\n",
    "            out_channels=dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=patch_size,\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values: torch.Tensor):\n",
    "        # pixel_values: (b, c, z, y, x)\n",
    "\n",
    "        embeddings = self.patch_embeddings(pixel_values)\n",
    "        # (b, dim, num_tokens_z, num_tokens_y, num_tokens_x)\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mViT3DPatchEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"patch_size\": (1, 8, 8),\n",
    "    \"in_channels\": 1,\n",
    "    \"dim\": 12,\n",
    "}\n",
    "\n",
    "test = ViT3DPatchEmbeddings(test_config)\n",
    "display(test)\n",
    "o = test(torch.randn(2, 1, 32, 512, 512))\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_3d_position_embeddings(embedding_size, grid_size, patch_size=(1, 1, 1)):\n",
    "    if embedding_size % 6 != 0:\n",
    "        raise ValueError(\"embed_dim must be divisible by 6\")\n",
    "\n",
    "    grid = get_coords_grid(grid_size)\n",
    "    # (3, d, h, w)\n",
    "\n",
    "    grid = rearrange(grid, \"x d h w -> x 1 d h w\")\n",
    "    # (3, 1, d, h, w)\n",
    "\n",
    "    omega = torch.arange(embedding_size // 6, dtype=torch.float32)\n",
    "    omega /= embedding_size / 6.0\n",
    "    omega = 1.0 / 10000**omega\n",
    "    # (d // 6)\n",
    "\n",
    "    patch_multiplier = torch.Tensor(patch_size) / min(patch_size)\n",
    "\n",
    "    position_embeddings = []\n",
    "    for i, grid_subset in enumerate(grid):\n",
    "        grid_subset = grid_subset.reshape(-1)\n",
    "        out = torch.einsum(\"m,d->md\", grid_subset, omega)\n",
    "\n",
    "        emb_sin = torch.sin(out)\n",
    "        emb_cos = torch.cos(out)\n",
    "\n",
    "        emb = torch.cat([emb_sin, emb_cos], axis=1) * patch_multiplier[i]\n",
    "        position_embeddings.append(emb)\n",
    "\n",
    "    position_embeddings = torch.cat(position_embeddings, axis=1)\n",
    "    # (embedding_size, d * h * w)\n",
    "    d, h, w = grid_size\n",
    "    position_embeddings = rearrange(position_embeddings, \"(d h w) e -> 1 e d h w\", d=d, h=h, w=w)\n",
    "    # (1, embedding_size, d, h, w)\n",
    "\n",
    "    return position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def embed_spacings_in_position_embeddings(embeddings: torch.Tensor, spacings: torch.Tensor):\n",
    "    assert spacings.ndim == 2, \"Please provide spacing information for each batch element\"\n",
    "    _, embedding_size, _, _, _ = embeddings.shape\n",
    "    assert embedding_size % 3 == 0, \"To embed spacing info, the embedding size must be divisible by 3\"\n",
    "    embeddings = embeddings * repeat(spacings, f\"B S -> B (S {int(embedding_size / 3)}) 1 1 1\", S=3)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ViT3DEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        dim = config[\"dim\"]\n",
    "\n",
    "        self.patch_embeddings = ViT3DPatchEmbeddings(config)\n",
    "        self.layer_norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.absolute_position_embeddings = None\n",
    "        if config[\"use_absolute_position_embeddings\"]:\n",
    "            grid_size = (\n",
    "                config[\"image_size\"][0] // config[\"patch_size\"][0],\n",
    "                config[\"image_size\"][1] // config[\"patch_size\"][1],\n",
    "                config[\"image_size\"][2] // config[\"patch_size\"][2],\n",
    "            )\n",
    "            if config[\"learnable_absolute_position_embeddings\"]:\n",
    "                self.absolute_position_embeddings = nn.Parameter(\n",
    "                    torch.randn(1, dim, grid_size[0], grid_size[1], grid_size[2])\n",
    "                )\n",
    "            else:\n",
    "                self.absolute_position_embeddings = get_3d_position_embeddings(dim, grid_size, config[\"patch_size\"])\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: torch.Tensor,\n",
    "        spacings: torch.Tensor,\n",
    "        mask_patches: torch.Tensor = None,\n",
    "        mask_token: torch.Tensor = None,\n",
    "    ):\n",
    "        # pixel_values: (b, c, z, y, x)\n",
    "\n",
    "        embeddings = self.patch_embeddings(pixel_values)\n",
    "        # (b, dim, num_tokens_z, num_tokens_y, num_tokens_x)\n",
    "        embeddings = rearrange(embeddings, \"b d nz ny nx -> b nz ny nx d\")\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = rearrange(embeddings, \"b nz ny nx d -> b d nz ny nx\")\n",
    "        # (b, dim, num_tokens_z, num_tokens_y, num_tokens_x)\n",
    "\n",
    "        if mask_patches is not None:\n",
    "            # mask_patches (binary mask): (b, num_tokens_z, num_tokens_y, num_tokens_x)\n",
    "            # mask_token: (1, dim, 1, 1, 1)\n",
    "            mask_patches = repeat(mask_patches, \"b z y x -> b d z y x\", d=embeddings.shape[1])\n",
    "            embeddings = (embeddings * (1 - mask_patches)) + (mask_patches * mask_token)\n",
    "\n",
    "        if self.absolute_position_embeddings is not None:\n",
    "            absolute_position_embeddings = self.absolute_position_embeddings.to(embeddings.device)\n",
    "            # (1, dim, num_tokens_z, num_tokens_y, num_tokens_x)\n",
    "            if self.config[\"embed_spacing_info\"]:\n",
    "                absolute_position_embeddings = embed_spacings_in_position_embeddings(\n",
    "                    absolute_position_embeddings, spacings\n",
    "                )\n",
    "                # (b, dim, num_tokens_z, num_tokens_y, num_tokens_x)\n",
    "\n",
    "            embeddings = embeddings + absolute_position_embeddings\n",
    "            # (b, dim, num_tokens_z, num_tokens_y, num_tokens_x)\n",
    "\n",
    "        embeddings = rearrange(embeddings, \"b d nz ny nx -> b (nz ny nx) d\")\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mViT3DEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mViT3DPatchEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m768\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4096\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"patch_size\": (8, 16, 16),\n",
    "    \"in_channels\": 1,\n",
    "    \"dim\": 768,\n",
    "    \"use_absolute_position_embeddings\": True,\n",
    "    \"learnable_absolute_position_embeddings\": False,\n",
    "    \"embed_spacing_info\": False,\n",
    "    \"image_size\": (32, 512, 512),\n",
    "}\n",
    "\n",
    "test = ViT3DEmbeddings(test_config)\n",
    "display(test)\n",
    "o = test(\n",
    "    torch.randn(2, 1, 32, 512, 512),\n",
    "    torch.randn(2, 3),\n",
    ")\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance of (0, 0, 0) with other coords\n",
      "(0, 0, 0) 0.0\n",
      "(0, 0, 1) 0.95885104\n",
      "(0, 1, 0) 0.95885104\n",
      "(0, 1, 1) 1.3560202\n",
      "(1, 0, 0) 0.95885104\n",
      "(1, 0, 1) 1.3560202\n",
      "(1, 1, 0) 1.3560202\n",
      "(1, 1, 1) 1.6607788\n"
     ]
    }
   ],
   "source": [
    "e = get_3d_position_embeddings(6, (2, 2, 2), (1, 1, 1))\n",
    "display(e.shape)\n",
    "\n",
    "print(\"Distance of (0, 0, 0) with other coords\")\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            print((i, j, k), np.linalg.norm(e[0, :, 0, 0, 0] - e[0, :, i, j, k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ViT3DModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings = ViT3DEmbeddings(config)\n",
    "        self.pos_drop = nn.Dropout(config.get(\"drop_prob\", 0.0))\n",
    "        self.num_class_tokens = config[\"num_class_tokens\"]\n",
    "        if self.num_class_tokens > 0:\n",
    "            self.class_tokens = nn.Parameter(torch.randn(1, config[\"num_class_tokens\"], config[\"dim\"]))\n",
    "        self.encoder = ViT3DEncoder(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: torch.Tensor,\n",
    "        spacings: torch.Tensor,\n",
    "        mask_patches: torch.Tensor = None,\n",
    "        mask_token: torch.Tensor = None,\n",
    "    ):\n",
    "        # pixel_values: (b, c, z, y, x)\n",
    "        # spacings: (b, 3)\n",
    "        # mask_patches: (num_tokens_z, num_tokens_y, num_tokens_x)\n",
    "\n",
    "        embeddings = self.embeddings(pixel_values, spacings, mask_patches, mask_token)\n",
    "        embeddings = self.pos_drop(embeddings)\n",
    "        # (b, num_tokens, dim)\n",
    "\n",
    "        class_tokens = None\n",
    "        if self.num_class_tokens > 0:\n",
    "            class_tokens = repeat(self.class_tokens, \"1 n d -> b n d\", b=embeddings.shape[0])\n",
    "            embeddings = torch.cat([class_tokens, embeddings], dim=1)\n",
    "            # (b, num_tokens + 1, dim)\n",
    "\n",
    "        encoded, layer_outputs = self.encoder(embeddings)\n",
    "        # encoded: (b, num_tokens (+ 1), dim)\n",
    "        # layer_outputs: list of (b, num_tokens (+ 1), dim)\n",
    "\n",
    "        if self.num_class_tokens > 0:\n",
    "            class_tokens = encoded[:, : self.num_class_tokens]\n",
    "            encoded = encoded[:, self.num_class_tokens :]\n",
    "\n",
    "        return class_tokens, encoded, layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mViT3DModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0membeddings\u001b[1m)\u001b[0m: \u001b[1;35mViT3DEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mViT3DPatchEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m768\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mpos_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mencoder\u001b[1m)\u001b[0m: \u001b[1;35mViT3DEncoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayers\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m4\u001b[0m x \u001b[1;35mViT3DEncoderLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mViT3DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mViT3DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1536\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1536\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4096\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4098\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4098\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4098\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4098\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"num_class_tokens\": 2,\n",
    "    \"attn_drop_prob\": 0.2,\n",
    "    \"dim\": 768,\n",
    "    \"drop_prob\": 0.2,\n",
    "    \"embed_spacing_info\": False,\n",
    "    \"encoder_depth\": 4,\n",
    "    \"image_size\": (32, 512, 512),\n",
    "    \"in_channels\": 1,\n",
    "    \"intermediate_ratio\": 2,\n",
    "    \"layer_norm_eps\": 1e-6,\n",
    "    \"learnable_absolute_position_embeddings\": False,\n",
    "    \"mlp_drop_prob\": 0.2,\n",
    "    \"num_heads\": 4,\n",
    "    \"patch_size\": (8, 16, 16),\n",
    "    \"proj_drop_prob\": 0.2,\n",
    "    \"use_absolute_position_embeddings\": True,\n",
    "}\n",
    "\n",
    "test = ViT3DModel(test_config)\n",
    "display(test)\n",
    "o = test(\n",
    "    torch.randn(2, 1, 32, 512, 512),\n",
    "    torch.randn(2, 3),\n",
    ")\n",
    "display((o[0].shape, o[1].shape, [x.shape for x in o[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Image Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ViT3DMIMDecoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_size = config[\"image_size\"]\n",
    "        self.in_channels = config[\"in_channels\"]\n",
    "        self.patch_size = config[\"patch_size\"]\n",
    "\n",
    "        dim = config[\"dim\"]\n",
    "        out_dim = np.prod(self.patch_size) * self.in_channels\n",
    "\n",
    "        self.decoder = nn.Linear(dim, out_dim)\n",
    "\n",
    "    def forward(self, encodings: torch.Tensor):\n",
    "        # encodings: (b, num_tokens, dim)\n",
    "\n",
    "        decoded = self.decoder(encodings)\n",
    "        # (b, num_tokens, new_dim)\n",
    "\n",
    "        decoded = rearrange(\n",
    "            decoded,\n",
    "            \"b (nz ny nx) (c pz py px) -> b c (nz pz) (ny py) (nx px)\",\n",
    "            c=self.in_channels,\n",
    "            pz=self.patch_size[0],\n",
    "            py=self.patch_size[1],\n",
    "            px=self.patch_size[2],\n",
    "            nz=self.image_size[0] // self.patch_size[0],\n",
    "            ny=self.image_size[1] // self.patch_size[1],\n",
    "            nx=self.image_size[2] // self.patch_size[2],\n",
    "        )\n",
    "        # (b, c, z, y, x)\n",
    "\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mViT3DMIMDecoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdecoder\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"dim\": 768,\n",
    "    \"image_size\": (32, 512, 512),\n",
    "    \"in_channels\": 1,\n",
    "    \"patch_size\": (8, 16, 16),\n",
    "}\n",
    "\n",
    "test = ViT3DMIMDecoder(test_config)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 4096, 768)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ViT3DMIM(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        assert config[\"num_class_tokens\"] == 0, \"MIM does not support class tokens\"\n",
    "\n",
    "        self.image_size = config[\"image_size\"]\n",
    "        self.patch_size = config[\"patch_size\"]\n",
    "        self.in_channels = config[\"in_channels\"]\n",
    "        self.mask_ratio = config[\"mask_ratio\"]\n",
    "\n",
    "        self.vit = ViT3DModel(config)\n",
    "        self.decoder = ViT3DMIMDecoder(config)\n",
    "\n",
    "        self.mask_token = nn.Parameter(torch.randn(1, config[\"dim\"], 1, 1, 1))\n",
    "\n",
    "    def mask_image(self, pixel_values: torch.Tensor):\n",
    "        b = pixel_values.shape[0]\n",
    "\n",
    "        mask_ratio = self.mask_ratio\n",
    "        grid_size = tuple([size // patch for size, patch in zip(self.image_size, self.patch_size)])\n",
    "        num_tokens = np.prod(grid_size)\n",
    "        mask_patches = []\n",
    "        for _ in range(b):\n",
    "            _mask_patches = torch.zeros(num_tokens, dtype=torch.int8, device=pixel_values.device)\n",
    "            _mask_patches[: int(mask_ratio * num_tokens)] = 1\n",
    "            _mask_patches = _mask_patches[torch.randperm(num_tokens)]\n",
    "            _mask_patches = rearrange(_mask_patches, \"(z y x) -> z y x\", z=grid_size[0], y=grid_size[1], x=grid_size[2])\n",
    "            mask_patches.append(_mask_patches)\n",
    "        mask_patches: torch.Tensor = torch.stack(mask_patches, dim=0)\n",
    "\n",
    "        return mask_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ViT3DSimMIM(ViT3DMIM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_fn(pred: torch.Tensor, target: torch.Tensor, reduction=\"mean\"):\n",
    "        return nn.functional.l1_loss(pred, target, reduction=reduction)\n",
    "\n",
    "    def forward(self, pixel_values: torch.Tensor, spacings: torch.Tensor):\n",
    "        mask_patches = self.mask_image(pixel_values)\n",
    "\n",
    "        _, encodings, _ = self.vit(pixel_values, spacings, mask_patches, self.mask_token)\n",
    "        decoded = self.decoder(encodings)\n",
    "\n",
    "        loss = self.loss_fn(decoded, pixel_values, reduction=\"none\")\n",
    "        mask = repeat(\n",
    "            mask_patches,\n",
    "            \"b z y x -> b (z pz) (y py) (x px)\",\n",
    "            pz=self.patch_size[0],\n",
    "            py=self.patch_size[1],\n",
    "            px=self.patch_size[2],\n",
    "        )\n",
    "        loss = (loss * mask).sum() / ((mask.sum() + 1e-5) * self.in_channels)\n",
    "\n",
    "        return decoded, loss, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mViT3DSimMIM\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mvit\u001b[1m)\u001b[0m: \u001b[1;35mViT3DModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0membeddings\u001b[1m)\u001b[0m: \u001b[1;35mViT3DEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mViT3DPatchEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m768\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mpos_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mencoder\u001b[1m)\u001b[0m: \u001b[1;35mViT3DEncoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayers\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m4\u001b[0m x \u001b[1;35mViT3DEncoderLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mViT3DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mViT3DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1536\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1536\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdecoder\u001b[1m)\u001b[0m: \u001b[1;35mViT3DMIMDecoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdecoder\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m3.5700\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDivBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"num_class_tokens\": 0,\n",
    "    \"attn_drop_prob\": 0.2,\n",
    "    \"dim\": 768,\n",
    "    \"drop_prob\": 0.2,\n",
    "    \"embed_spacing_info\": False,\n",
    "    \"encoder_depth\": 4,\n",
    "    \"image_size\": (32, 128, 128),\n",
    "    \"in_channels\": 1,\n",
    "    \"intermediate_ratio\": 2,\n",
    "    \"layer_norm_eps\": 1e-6,\n",
    "    \"learnable_absolute_position_embeddings\": False,\n",
    "    \"mlp_drop_prob\": 0.2,\n",
    "    \"num_heads\": 4,\n",
    "    \"patch_size\": (8, 16, 16),\n",
    "    \"proj_drop_prob\": 0.2,\n",
    "    \"use_absolute_position_embeddings\": True,\n",
    "    \"mask_ratio\": 0.8,\n",
    "}\n",
    "\n",
    "test = ViT3DSimMIM(test_config)\n",
    "display(test)\n",
    "o = test(\n",
    "    torch.randn(2, 1, 32, 128, 128),\n",
    "    torch.randn(2, 3),\n",
    ")\n",
    "display((o[0].shape, o[1], o[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c358044bb4b246c88a8e1abc10bda4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='z', max=31), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from neuro_utils.visualize import plot_scans\n",
    "\n",
    "plot_scans([o[0][0, 0].detach(), o[0][0, 0].detach() * (1 - o[2][0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some more tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m5523072\u001b[0m, \u001b[1;36m788480\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "sample_spacings = torch.tensor([[1, 0.1, 0.1], [2, 0.2, 0.2], [3, 0.3, 0.3], [4, 0.4, 0.4], [5, 0.5, 0.5]])\n",
    "sample_batch = torch.rand(3, 1, 16, 128, 128)\n",
    "sample_config = {\n",
    "    \"num_class_tokens\": 0,\n",
    "    \"attn_drop_prob\": 0.2,\n",
    "    \"dim\": 384,\n",
    "    \"drop_prob\": 0.2,\n",
    "    \"embed_spacing_info\": False,\n",
    "    \"encoder_depth\": 4,\n",
    "    \"image_size\": (16, 128, 128),\n",
    "    \"in_channels\": 1,\n",
    "    \"intermediate_ratio\": 2,\n",
    "    \"layer_norm_eps\": 1e-6,\n",
    "    \"learnable_absolute_position_embeddings\": False,\n",
    "    \"mlp_drop_prob\": 0.2,\n",
    "    \"num_heads\": 4,\n",
    "    \"patch_size\": (8, 16, 16),\n",
    "    \"proj_drop_prob\": 0.2,\n",
    "    \"use_absolute_position_embeddings\": True,\n",
    "    \"mask_ratio\": 0.8,\n",
    "}\n",
    "\n",
    "model = ViT3DSimMIM(sample_config)\n",
    "\n",
    "sum(x.numel() for x in model.vit.parameters()), sum(x.numel() for x in model.decoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 6,311,936\n",
      "+---------------------------------------------------------+------------+\n",
      "|                          Module                         | Parameters |\n",
      "+---------------------------------------------------------+------------+\n",
      "|                        mask_token                       |    384     |\n",
      "| vit.embeddings.patch_embeddings.patch_embeddings.weight |  786,432   |\n",
      "|  vit.embeddings.patch_embeddings.patch_embeddings.bias  |    384     |\n",
      "|             vit.embeddings.layer_norm.weight            |    384     |\n",
      "|              vit.embeddings.layer_norm.bias             |    384     |\n",
      "|           vit.encoder.layers.0.mhsa.W_q.weight          |  147,456   |\n",
      "|            vit.encoder.layers.0.mhsa.W_q.bias           |    384     |\n",
      "|           vit.encoder.layers.0.mhsa.W_k.weight          |  147,456   |\n",
      "|            vit.encoder.layers.0.mhsa.W_k.bias           |    384     |\n",
      "|           vit.encoder.layers.0.mhsa.W_v.weight          |  147,456   |\n",
      "|            vit.encoder.layers.0.mhsa.W_v.bias           |    384     |\n",
      "|          vit.encoder.layers.0.mhsa.proj.weight          |  147,456   |\n",
      "|           vit.encoder.layers.0.mhsa.proj.bias           |    384     |\n",
      "|          vit.encoder.layers.0.layernorm1.weight         |    384     |\n",
      "|           vit.encoder.layers.0.layernorm1.bias          |    384     |\n",
      "|          vit.encoder.layers.0.mlp.dense1.weight         |  294,912   |\n",
      "|           vit.encoder.layers.0.mlp.dense1.bias          |    768     |\n",
      "|          vit.encoder.layers.0.mlp.dense2.weight         |  294,912   |\n",
      "|           vit.encoder.layers.0.mlp.dense2.bias          |    384     |\n",
      "|          vit.encoder.layers.0.layernorm2.weight         |    384     |\n",
      "|           vit.encoder.layers.0.layernorm2.bias          |    384     |\n",
      "|           vit.encoder.layers.1.mhsa.W_q.weight          |  147,456   |\n",
      "|            vit.encoder.layers.1.mhsa.W_q.bias           |    384     |\n",
      "|           vit.encoder.layers.1.mhsa.W_k.weight          |  147,456   |\n",
      "|            vit.encoder.layers.1.mhsa.W_k.bias           |    384     |\n",
      "|           vit.encoder.layers.1.mhsa.W_v.weight          |  147,456   |\n",
      "|            vit.encoder.layers.1.mhsa.W_v.bias           |    384     |\n",
      "|          vit.encoder.layers.1.mhsa.proj.weight          |  147,456   |\n",
      "|           vit.encoder.layers.1.mhsa.proj.bias           |    384     |\n",
      "|          vit.encoder.layers.1.layernorm1.weight         |    384     |\n",
      "|           vit.encoder.layers.1.layernorm1.bias          |    384     |\n",
      "|          vit.encoder.layers.1.mlp.dense1.weight         |  294,912   |\n",
      "|           vit.encoder.layers.1.mlp.dense1.bias          |    768     |\n",
      "|          vit.encoder.layers.1.mlp.dense2.weight         |  294,912   |\n",
      "|           vit.encoder.layers.1.mlp.dense2.bias          |    384     |\n",
      "|          vit.encoder.layers.1.layernorm2.weight         |    384     |\n",
      "|           vit.encoder.layers.1.layernorm2.bias          |    384     |\n",
      "|           vit.encoder.layers.2.mhsa.W_q.weight          |  147,456   |\n",
      "|            vit.encoder.layers.2.mhsa.W_q.bias           |    384     |\n",
      "|           vit.encoder.layers.2.mhsa.W_k.weight          |  147,456   |\n",
      "|            vit.encoder.layers.2.mhsa.W_k.bias           |    384     |\n",
      "|           vit.encoder.layers.2.mhsa.W_v.weight          |  147,456   |\n",
      "|            vit.encoder.layers.2.mhsa.W_v.bias           |    384     |\n",
      "|          vit.encoder.layers.2.mhsa.proj.weight          |  147,456   |\n",
      "|           vit.encoder.layers.2.mhsa.proj.bias           |    384     |\n",
      "|          vit.encoder.layers.2.layernorm1.weight         |    384     |\n",
      "|           vit.encoder.layers.2.layernorm1.bias          |    384     |\n",
      "|          vit.encoder.layers.2.mlp.dense1.weight         |  294,912   |\n",
      "|           vit.encoder.layers.2.mlp.dense1.bias          |    768     |\n",
      "|          vit.encoder.layers.2.mlp.dense2.weight         |  294,912   |\n",
      "|           vit.encoder.layers.2.mlp.dense2.bias          |    384     |\n",
      "|          vit.encoder.layers.2.layernorm2.weight         |    384     |\n",
      "|           vit.encoder.layers.2.layernorm2.bias          |    384     |\n",
      "|           vit.encoder.layers.3.mhsa.W_q.weight          |  147,456   |\n",
      "|            vit.encoder.layers.3.mhsa.W_q.bias           |    384     |\n",
      "|           vit.encoder.layers.3.mhsa.W_k.weight          |  147,456   |\n",
      "|            vit.encoder.layers.3.mhsa.W_k.bias           |    384     |\n",
      "|           vit.encoder.layers.3.mhsa.W_v.weight          |  147,456   |\n",
      "|            vit.encoder.layers.3.mhsa.W_v.bias           |    384     |\n",
      "|          vit.encoder.layers.3.mhsa.proj.weight          |  147,456   |\n",
      "|           vit.encoder.layers.3.mhsa.proj.bias           |    384     |\n",
      "|          vit.encoder.layers.3.layernorm1.weight         |    384     |\n",
      "|           vit.encoder.layers.3.layernorm1.bias          |    384     |\n",
      "|          vit.encoder.layers.3.mlp.dense1.weight         |  294,912   |\n",
      "|           vit.encoder.layers.3.mlp.dense1.bias          |    768     |\n",
      "|          vit.encoder.layers.3.mlp.dense2.weight         |  294,912   |\n",
      "|           vit.encoder.layers.3.mlp.dense2.bias          |    384     |\n",
      "|          vit.encoder.layers.3.layernorm2.weight         |    384     |\n",
      "|           vit.encoder.layers.3.layernorm2.bias          |    384     |\n",
      "|                  decoder.decoder.weight                 |  786,432   |\n",
      "|                   decoder.decoder.bias                  |   2,048    |\n",
      "+---------------------------------------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from neuro_utils.describe import describe_model\n",
    "\n",
    "describe_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = sample_batch.cuda()\n",
    "sample_spacings = sample_spacings.cuda()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ee3db9979f4665afa918a2b8ff8b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.919111\tLR: 0.500000\n",
      "Loss: 5.556315\tLR: 0.500000\n",
      "Loss: 5.230718\tLR: 0.500000\n",
      "Loss: 4.387706\tLR: 0.500000\n",
      "Loss: 3.322755\tLR: 0.500000\n",
      "Loss: 3.008898\tLR: 0.450000\n",
      "Loss: 2.731296\tLR: 0.450000\n",
      "Loss: 2.617728\tLR: 0.450000\n",
      "Loss: 2.573124\tLR: 0.450000\n",
      "Loss: 2.502039\tLR: 0.450000\n",
      "Loss: 2.445077\tLR: 0.405000\n",
      "Loss: 2.315751\tLR: 0.405000\n",
      "Loss: 2.282412\tLR: 0.405000\n",
      "Loss: 2.257941\tLR: 0.405000\n",
      "Loss: 2.253362\tLR: 0.405000\n",
      "Loss: 2.232292\tLR: 0.364500\n",
      "Loss: 2.198282\tLR: 0.364500\n",
      "Loss: 2.189039\tLR: 0.364500\n",
      "Loss: 2.182271\tLR: 0.364500\n",
      "Loss: 2.170778\tLR: 0.364500\n",
      "Loss: 2.168752\tLR: 0.328050\n",
      "Loss: 2.147718\tLR: 0.328050\n",
      "Loss: 2.132563\tLR: 0.328050\n",
      "Loss: 2.137686\tLR: 0.328050\n",
      "Loss: 2.118437\tLR: 0.328050\n",
      "Loss: 2.124521\tLR: 0.295245\n",
      "Loss: 2.104215\tLR: 0.295245\n",
      "Loss: 2.107414\tLR: 0.295245\n",
      "Loss: 2.105642\tLR: 0.295245\n",
      "Loss: 2.102063\tLR: 0.295245\n",
      "Loss: 2.084438\tLR: 0.265721\n",
      "Loss: 2.084326\tLR: 0.265721\n",
      "Loss: 2.074746\tLR: 0.265721\n",
      "Loss: 2.079354\tLR: 0.265721\n",
      "Loss: 2.076055\tLR: 0.265721\n",
      "Loss: 2.069620\tLR: 0.239148\n",
      "Loss: 2.075294\tLR: 0.239148\n",
      "Loss: 2.063451\tLR: 0.239148\n",
      "Loss: 2.056569\tLR: 0.239148\n",
      "Loss: 2.059423\tLR: 0.239148\n",
      "Loss: 2.060127\tLR: 0.215234\n",
      "Loss: 2.055269\tLR: 0.215234\n",
      "Loss: 2.050938\tLR: 0.215234\n",
      "Loss: 2.050604\tLR: 0.215234\n",
      "Loss: 2.045208\tLR: 0.215234\n",
      "Loss: 2.032792\tLR: 0.193710\n",
      "Loss: 2.034186\tLR: 0.193710\n",
      "Loss: 2.033992\tLR: 0.193710\n",
      "Loss: 2.024920\tLR: 0.193710\n",
      "Loss: 2.031044\tLR: 0.193710\n",
      "Loss: 2.031886\tLR: 0.174339\n",
      "Loss: 2.032577\tLR: 0.174339\n",
      "Loss: 2.025427\tLR: 0.174339\n",
      "Loss: 2.021313\tLR: 0.174339\n",
      "Loss: 2.019067\tLR: 0.174339\n",
      "Loss: 2.019475\tLR: 0.156905\n",
      "Loss: 2.019548\tLR: 0.156905\n",
      "Loss: 2.014181\tLR: 0.156905\n",
      "Loss: 2.001774\tLR: 0.156905\n",
      "Loss: 2.013143\tLR: 0.156905\n",
      "Loss: 2.001132\tLR: 0.141215\n",
      "Loss: 2.004796\tLR: 0.141215\n",
      "Loss: 2.005072\tLR: 0.141215\n",
      "Loss: 2.005443\tLR: 0.141215\n",
      "Loss: 1.997255\tLR: 0.141215\n",
      "Loss: 1.992533\tLR: 0.127093\n",
      "Loss: 1.994111\tLR: 0.127093\n",
      "Loss: 1.998569\tLR: 0.127093\n",
      "Loss: 1.986455\tLR: 0.127093\n",
      "Loss: 1.996194\tLR: 0.127093\n",
      "Loss: 1.991648\tLR: 0.114384\n",
      "Loss: 1.990276\tLR: 0.114384\n",
      "Loss: 1.998308\tLR: 0.114384\n",
      "Loss: 1.984195\tLR: 0.114384\n",
      "Loss: 1.983984\tLR: 0.114384\n",
      "Loss: 1.982637\tLR: 0.102946\n",
      "Loss: 1.977230\tLR: 0.102946\n",
      "Loss: 1.982988\tLR: 0.102946\n",
      "Loss: 1.981674\tLR: 0.102946\n",
      "Loss: 1.973556\tLR: 0.102946\n",
      "Loss: 1.970991\tLR: 0.092651\n",
      "Loss: 1.965188\tLR: 0.092651\n",
      "Loss: 1.968449\tLR: 0.092651\n",
      "Loss: 1.970166\tLR: 0.092651\n",
      "Loss: 1.967231\tLR: 0.092651\n",
      "Loss: 1.970150\tLR: 0.083386\n",
      "Loss: 1.965402\tLR: 0.083386\n",
      "Loss: 1.971442\tLR: 0.083386\n",
      "Loss: 1.956437\tLR: 0.083386\n",
      "Loss: 1.967125\tLR: 0.083386\n",
      "Loss: 1.968728\tLR: 0.075047\n",
      "Loss: 1.956098\tLR: 0.075047\n",
      "Loss: 1.962775\tLR: 0.075047\n",
      "Loss: 1.956546\tLR: 0.075047\n",
      "Loss: 1.960474\tLR: 0.075047\n",
      "Loss: 1.964341\tLR: 0.067543\n",
      "Loss: 1.958726\tLR: 0.067543\n",
      "Loss: 1.951779\tLR: 0.067543\n",
      "Loss: 1.944302\tLR: 0.067543\n",
      "Loss: 1.949673\tLR: 0.067543\n",
      "Loss: 1.957226\tLR: 0.060788\n",
      "Loss: 1.956821\tLR: 0.060788\n",
      "Loss: 1.955331\tLR: 0.060788\n",
      "Loss: 1.950243\tLR: 0.060788\n",
      "Loss: 1.950193\tLR: 0.060788\n",
      "Loss: 1.952612\tLR: 0.054709\n",
      "Loss: 1.953505\tLR: 0.054709\n",
      "Loss: 1.949569\tLR: 0.054709\n",
      "Loss: 1.936255\tLR: 0.054709\n",
      "Loss: 1.942299\tLR: 0.054709\n",
      "Loss: 1.949592\tLR: 0.049239\n",
      "Loss: 1.946997\tLR: 0.049239\n",
      "Loss: 1.949026\tLR: 0.049239\n",
      "Loss: 1.939892\tLR: 0.049239\n",
      "Loss: 1.943905\tLR: 0.049239\n",
      "Loss: 1.934970\tLR: 0.044315\n",
      "Loss: 1.948108\tLR: 0.044315\n",
      "Loss: 1.935099\tLR: 0.044315\n",
      "Loss: 1.942968\tLR: 0.044315\n",
      "Loss: 1.943604\tLR: 0.044315\n",
      "Loss: 1.937467\tLR: 0.039883\n",
      "Loss: 1.942773\tLR: 0.039883\n",
      "Loss: 1.936954\tLR: 0.039883\n",
      "Loss: 1.936125\tLR: 0.039883\n",
      "Loss: 1.935703\tLR: 0.039883\n",
      "Loss: 1.938726\tLR: 0.035895\n",
      "Loss: 1.928708\tLR: 0.035895\n",
      "Loss: 1.938782\tLR: 0.035895\n",
      "Loss: 1.930080\tLR: 0.035895\n",
      "Loss: 1.937468\tLR: 0.035895\n",
      "Loss: 1.929314\tLR: 0.032305\n",
      "Loss: 1.932053\tLR: 0.032305\n",
      "Loss: 1.942560\tLR: 0.032305\n",
      "Loss: 1.932252\tLR: 0.032305\n",
      "Loss: 1.936576\tLR: 0.032305\n",
      "Loss: 1.933080\tLR: 0.029075\n",
      "Loss: 1.929929\tLR: 0.029075\n",
      "Loss: 1.929105\tLR: 0.029075\n",
      "Loss: 1.929163\tLR: 0.029075\n",
      "Loss: 1.929996\tLR: 0.029075\n",
      "Loss: 1.935867\tLR: 0.026167\n",
      "Loss: 1.931674\tLR: 0.026167\n",
      "Loss: 1.928428\tLR: 0.026167\n",
      "Loss: 1.936636\tLR: 0.026167\n",
      "Loss: 1.931828\tLR: 0.026167\n",
      "Loss: 1.926402\tLR: 0.023551\n",
      "Loss: 1.926566\tLR: 0.023551\n",
      "Loss: 1.931939\tLR: 0.023551\n",
      "Loss: 1.928128\tLR: 0.023551\n",
      "Loss: 1.925994\tLR: 0.023551\n",
      "Loss: 1.920844\tLR: 0.021196\n",
      "Loss: 1.927972\tLR: 0.021196\n",
      "Loss: 1.923928\tLR: 0.021196\n",
      "Loss: 1.918327\tLR: 0.021196\n",
      "Loss: 1.924483\tLR: 0.021196\n",
      "Loss: 1.925868\tLR: 0.019076\n",
      "Loss: 1.922845\tLR: 0.019076\n",
      "Loss: 1.924076\tLR: 0.019076\n",
      "Loss: 1.925438\tLR: 0.019076\n",
      "Loss: 1.923456\tLR: 0.019076\n",
      "Loss: 1.928099\tLR: 0.017168\n",
      "Loss: 1.924854\tLR: 0.017168\n",
      "Loss: 1.924536\tLR: 0.017168\n",
      "Loss: 1.929085\tLR: 0.017168\n",
      "Loss: 1.917317\tLR: 0.017168\n",
      "Loss: 1.920015\tLR: 0.015452\n",
      "Loss: 1.919684\tLR: 0.015452\n",
      "Loss: 1.922942\tLR: 0.015452\n",
      "Loss: 1.911016\tLR: 0.015452\n",
      "Loss: 1.916645\tLR: 0.015452\n",
      "Loss: 1.914686\tLR: 0.013906\n",
      "Loss: 1.926565\tLR: 0.013906\n",
      "Loss: 1.918193\tLR: 0.013906\n",
      "Loss: 1.917207\tLR: 0.013906\n",
      "Loss: 1.913152\tLR: 0.013906\n",
      "Loss: 1.920191\tLR: 0.012516\n",
      "Loss: 1.922728\tLR: 0.012516\n",
      "Loss: 1.919937\tLR: 0.012516\n",
      "Loss: 1.918613\tLR: 0.012516\n",
      "Loss: 1.922737\tLR: 0.012516\n",
      "Loss: 1.920702\tLR: 0.011264\n",
      "Loss: 1.915856\tLR: 0.011264\n",
      "Loss: 1.918221\tLR: 0.011264\n",
      "Loss: 1.921222\tLR: 0.011264\n",
      "Loss: 1.917957\tLR: 0.011264\n",
      "Loss: 1.913423\tLR: 0.010138\n",
      "Loss: 1.919258\tLR: 0.010138\n",
      "Loss: 1.921798\tLR: 0.010138\n",
      "Loss: 1.915001\tLR: 0.010138\n",
      "Loss: 1.917436\tLR: 0.010138\n",
      "Loss: 1.911983\tLR: 0.009124\n",
      "Loss: 1.920372\tLR: 0.009124\n",
      "Loss: 1.911207\tLR: 0.009124\n",
      "Loss: 1.915931\tLR: 0.009124\n",
      "Loss: 1.917165\tLR: 0.009124\n",
      "Loss: 1.917400\tLR: 0.008212\n",
      "Loss: 1.912201\tLR: 0.008212\n",
      "Loss: 1.919846\tLR: 0.008212\n",
      "Loss: 1.919008\tLR: 0.008212\n",
      "Loss: 1.912175\tLR: 0.008212\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(200)):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(sample_batch, sample_spacings)\n",
    "    print(f\"Loss: {output[1]:f}\\tLR: {scheduler.get_last_lr()[0]:f}\")\n",
    "    output[1].backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.grad is None:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
