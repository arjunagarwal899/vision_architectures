{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp swinv2_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from einops import rearrange, repeat\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def populate_and_validate_config(config: dict) -> dict:\n",
    "    assert config[\"stages\"][0][\"patch_merging\"] is None\n",
    "\n",
    "    # Prepare config based on provided values\n",
    "    dim = config[\"dim\"]\n",
    "    patch_size = config[\"patch_size\"]\n",
    "    # image_size = config[\"image_size\"]  # This may not be fixed while fine-tuning.\n",
    "    for i in range(len(config[\"stages\"])):\n",
    "        stage = config[\"stages\"][i]\n",
    "        stage[\"_in_dim\"] = dim\n",
    "        stage[\"_in_patch_size\"] = patch_size\n",
    "        # stage['_in\"grid_size'] = tuple([image // patch for image, patch in zip(image_size, patch_size)])\n",
    "        if stage[\"patch_merging\"] is not None:\n",
    "            dim *= stage[\"patch_merging\"][\"out_dim_ratio\"]\n",
    "            patch_size = tuple(\n",
    "                [patch * window for patch, window in zip(patch_size, stage[\"patch_merging\"][\"merge_window_size\"])]\n",
    "            )\n",
    "        stage[\"_out_dim\"] = dim\n",
    "        stage[\"_out_patch_size\"] = patch_size\n",
    "        # stage[\"_out_grid_size\"] = tuple([image // patch for image, patch in zip(image_size, patch_size)])\n",
    "\n",
    "    for stage in config[\"stages\"]:\n",
    "        assert stage[\"_out_dim\"] % stage[\"num_heads\"] == 0, stage\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'patch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'in_channels'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "    \u001b[32m'use_absolute_position_embeddings'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'learnable_absolute_position_embeddings'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'embed_spacing_info'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'image_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'dim'\u001b[0m: \u001b[1;36m36\u001b[0m,\n",
       "    \u001b[32m'stages'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'patch_merging'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[32m'depth'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "            \u001b[32m'num_heads'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'intermediate_ratio'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'layer_norm_eps'\u001b[0m: \u001b[1;36m1e-06\u001b[0m,\n",
       "            \u001b[32m'window_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'use_relative_position_bias'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "            \u001b[32m'_in_dim'\u001b[0m: \u001b[1;36m36\u001b[0m,\n",
       "            \u001b[32m'_in_patch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'_out_dim'\u001b[0m: \u001b[1;36m36\u001b[0m,\n",
       "            \u001b[32m'_out_patch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'patch_merging'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'merge_window_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'out_dim_ratio'\u001b[0m: \u001b[1;36m3\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'depth'\u001b[0m: \u001b[1;36m3\u001b[0m,\n",
       "            \u001b[32m'num_heads'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'intermediate_ratio'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'layer_norm_eps'\u001b[0m: \u001b[1;36m1e-06\u001b[0m,\n",
       "            \u001b[32m'window_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'use_relative_position_bias'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'_in_dim'\u001b[0m: \u001b[1;36m36\u001b[0m,\n",
       "            \u001b[32m'_in_patch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'_out_dim'\u001b[0m: \u001b[1;36m108\u001b[0m,\n",
       "            \u001b[32m'_out_patch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'patch_merging'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'merge_window_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'out_dim_ratio'\u001b[0m: \u001b[1;36m3\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'depth'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "            \u001b[32m'num_heads'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'intermediate_ratio'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'layer_norm_eps'\u001b[0m: \u001b[1;36m1e-06\u001b[0m,\n",
       "            \u001b[32m'window_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'use_relative_position_bias'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'_in_dim'\u001b[0m: \u001b[1;36m108\u001b[0m,\n",
       "            \u001b[32m'_in_patch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'_out_dim'\u001b[0m: \u001b[1;36m324\u001b[0m,\n",
       "            \u001b[32m'_out_patch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"patch_size\": (1, 8, 8),\n",
    "    \"in_channels\": 1,\n",
    "    \"use_absolute_position_embeddings\": True,\n",
    "    \"learnable_absolute_position_embeddings\": False,\n",
    "    \"embed_spacing_info\": False,\n",
    "    \"image_size\": (32, 512, 512),\n",
    "    \"dim\": 36,\n",
    "    \"stages\": [\n",
    "        {\n",
    "            \"patch_merging\": None,\n",
    "            \"depth\": 1,\n",
    "            \"num_heads\": 4,\n",
    "            \"intermediate_ratio\": 4,\n",
    "            \"layer_norm_eps\": 1e-6,\n",
    "            \"window_size\": (4, 4, 4),\n",
    "            \"use_relative_position_bias\": False,\n",
    "        },\n",
    "        {\n",
    "            \"patch_merging\": {\n",
    "                \"merge_window_size\": (2, 2, 2),\n",
    "                \"out_dim_ratio\": 3,\n",
    "            },\n",
    "            \"depth\": 3,\n",
    "            \"num_heads\": 4,\n",
    "            \"intermediate_ratio\": 4,\n",
    "            \"layer_norm_eps\": 1e-6,\n",
    "            \"window_size\": (4, 4, 4),\n",
    "            \"use_relative_position_bias\": True,\n",
    "        },\n",
    "        {\n",
    "            \"patch_merging\": {\n",
    "                \"merge_window_size\": (2, 2, 2),\n",
    "                \"out_dim_ratio\": 3,\n",
    "            },\n",
    "            \"depth\": 1,\n",
    "            \"num_heads\": 4,\n",
    "            \"intermediate_ratio\": 4,\n",
    "            \"layer_norm_eps\": 1e-6,\n",
    "            \"window_size\": (4, 4, 4),\n",
    "            \"use_relative_position_bias\": True,\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "populate_and_validate_config(test_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_coords_grid(grid_size):\n",
    "    d, h, w = grid_size\n",
    "\n",
    "    grid_d = torch.arange(d, dtype=torch.int32)\n",
    "    grid_h = torch.arange(h, dtype=torch.int32)\n",
    "    grid_w = torch.arange(w, dtype=torch.int32)\n",
    "\n",
    "    grid = torch.meshgrid(grid_w, grid_h, grid_d, indexing=\"ij\")\n",
    "    grid = torch.stack(grid, axis=0)\n",
    "    # (3, d, h, w)\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DMHSA(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        window_size,\n",
    "        use_relative_position_bias,\n",
    "        attn_drop_prob=0.0,\n",
    "        proj_drop_prob=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert dim % num_heads == 0, \"dimension must be divisible by number of heads\"\n",
    "\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.per_head_dim = int(dim // num_heads)\n",
    "\n",
    "        self.W_qkv = nn.Linear(dim, 3 * dim)\n",
    "        self.attn_drop = nn.Dropout(attn_drop_prob)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop_prob)\n",
    "\n",
    "        self.logit_scale = nn.Parameter(torch.log(10 * torch.ones((num_heads, 1, 1))))\n",
    "\n",
    "        # TODO: Add embed_spacing_info functionality\n",
    "        self.use_relative_position_bias = use_relative_position_bias\n",
    "        if use_relative_position_bias:\n",
    "            self.cpb_mlp = nn.Sequential(\n",
    "                nn.Linear(3, 512, bias=True), nn.ReLU(inplace=True), nn.Linear(512, num_heads, bias=False)\n",
    "            )\n",
    "\n",
    "            relative_limits = (2 * window_size[0] - 1, 2 * window_size[1] - 1, 2 * window_size[2] - 1)\n",
    "\n",
    "            # Relative coordinates table\n",
    "            relative_coords_table = get_coords_grid(relative_limits).float()\n",
    "            relative_coords_table[0] -= window_size[0] - 1\n",
    "            relative_coords_table[1] -= window_size[1] - 1\n",
    "            relative_coords_table[2] -= window_size[2] - 1\n",
    "            relative_coords_table = relative_coords_table.permute(1, 2, 3, 0).contiguous()\n",
    "            relative_coords_table[:, :, :, 0] /= self.window_size[0] - 1\n",
    "            relative_coords_table[:, :, :, 1] /= self.window_size[1] - 1\n",
    "            relative_coords_table[:, :, :, 2] /= self.window_size[2] - 1\n",
    "            relative_coords_table *= 8  # Normalize to -8, 8\n",
    "            relative_coords_table = (\n",
    "                torch.sign(relative_coords_table) * torch.log2(torch.abs(relative_coords_table) + 1.0) / np.log2(8)\n",
    "            )\n",
    "            # (window_size_z, window_size_y, window_size_x, 3)\n",
    "            # Allow moving this to and from cuda whenever required but don't save to state_dict\n",
    "            self.register_buffer(\"relative_coords_table\", relative_coords_table, persistent=False)\n",
    "\n",
    "            # Pair-wise relative position index for each token inside the window\n",
    "            coords = get_coords_grid(window_size)\n",
    "            coords_flatten = rearrange(\n",
    "                coords, \"three_dimensional d h w -> three_dimensional (d h w)\", three_dimensional=3\n",
    "            )\n",
    "            relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "            relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "            relative_coords[:, :, 0] += window_size[0] - 1\n",
    "            relative_coords[:, :, 1] += window_size[1] - 1\n",
    "            relative_coords[:, :, 2] += window_size[2] - 1\n",
    "            relative_position_index: torch.Tensor = (\n",
    "                relative_coords[:, :, 0] * relative_limits[1] * relative_limits[2]\n",
    "                + relative_coords[:, :, 1] * relative_limits[2]\n",
    "                + relative_coords[:, :, 2]\n",
    "            )\n",
    "            self.relative_position_index = relative_position_index.flatten()\n",
    "            # (num_patches, num_patches)\n",
    "\n",
    "    def calculate_relative_position_bias(self):\n",
    "        # (window_size_z, window_size_y, window_size_x, 3)\n",
    "        relative_position_bias_table = self.cpb_mlp(self.relative_coords_table)\n",
    "        # (window_size_z, window_size_y, window_size_x, num_heads)\n",
    "        relative_position_bias_table = relative_position_bias_table.reshape(-1, self.num_heads)\n",
    "        # (num_patches, num_heads)\n",
    "        relative_position_bias = relative_position_bias_table[self.relative_position_index]\n",
    "        # (num_patches * num_patches, num_heads)\n",
    "        relative_position_bias = rearrange(\n",
    "            relative_position_bias,\n",
    "            \"(num_patches1 num_patches2) num_heads -> num_heads num_patches1 num_patches2\",\n",
    "            num_patches1=np.prod(self.window_size),\n",
    "            num_patches2=np.prod(self.window_size),\n",
    "            num_heads=self.num_heads,\n",
    "        ).contiguous()\n",
    "        # (num_heads, num_patches, num_patches)\n",
    "        relative_position_bias = 16 * torch.sigmoid(relative_position_bias)\n",
    "        # (num_heads, num_patches, num_patches)\n",
    "        return relative_position_bias\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "        _, num_patches_z, num_patches_y, num_patches_x, _ = hidden_states.shape\n",
    "\n",
    "        query, key, value = rearrange(\n",
    "            self.W_qkv(hidden_states),\n",
    "            \"b nz ny nx (n num_heads d) -> n b num_heads (nz ny nx) d\",\n",
    "            n=3,\n",
    "            num_heads=self.num_heads,\n",
    "        )\n",
    "        # num_patches = window_size_z * window_size_y * window_size_x\n",
    "        # Each is (windowed_b, num_heads, num_patches, per_head_dim)\n",
    "\n",
    "        query = query\n",
    "        key_transpose = rearrange(key, \"b num_heads n d -> b num_heads d n\")\n",
    "\n",
    "        attention_scores = F.normalize(query, dim=-1) @ F.normalize(key_transpose, dim=-2)\n",
    "        logit_scale = torch.clamp(self.logit_scale, max=np.log(1.0 / 0.01)).exp()\n",
    "        attention_scores = attention_scores * logit_scale\n",
    "        # (windowed_b, num_heads, num_patches, num_patches)\n",
    "\n",
    "        if self.use_relative_position_bias:\n",
    "            relative_position_bias = self.calculate_relative_position_bias()\n",
    "            attention_scores = attention_scores + relative_position_bias\n",
    "\n",
    "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
    "        attention_probs = self.attn_drop(attention_probs)\n",
    "        # (windowed_b, num_heads, num_patches, num_patches)\n",
    "\n",
    "        context = attention_probs @ value\n",
    "        # (windowed_b, num_heads, num_patches, per_head_dim)\n",
    "        context = rearrange(\n",
    "            context,\n",
    "            \"b num_heads (num_patches_z num_patches_y num_patches_x) d -> \"\n",
    "            \"b num_patches_z num_patches_y num_patches_x (num_heads d)\",\n",
    "            num_patches_z=num_patches_z,\n",
    "            num_patches_y=num_patches_y,\n",
    "            num_patches_x=num_patches_x,\n",
    "        )\n",
    "        # (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "\n",
    "        context = self.proj(context)\n",
    "        context = self.proj_drop(context)\n",
    "        # (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m162\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m54\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = SwinV23DMHSA(54, 6, (4, 4, 4), True)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 4, 4, 4, 54)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DLayerMLP(nn.Module):\n",
    "    def __init__(self, dim, intermediate_ratio, dropout_prob=0.0):\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.Linear(dim, dim * intermediate_ratio)\n",
    "        self.act = nn.GELU()\n",
    "        self.dense2 = nn.Linear(dim * intermediate_ratio, dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "        hidden_states = self.dense1(hidden_states)\n",
    "        hidden_states = self.act(hidden_states)\n",
    "        hidden_states = self.dense2(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m16384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m16384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = SwinV23DLayerMLP(64, 256)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 4, 4, 4, 64)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        intermediate_ratio,\n",
    "        layer_norm_eps,\n",
    "        window_size,\n",
    "        use_relative_position_bias,\n",
    "        attn_drop_prob=0.0,\n",
    "        proj_drop_prob=0.0,\n",
    "        mlp_drop_prob=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.mhsa = SwinV23DMHSA(\n",
    "            dim, num_heads, window_size, use_relative_position_bias, attn_drop_prob, proj_drop_prob\n",
    "        )\n",
    "        self.layernorm1 = nn.LayerNorm(dim, eps=layer_norm_eps)\n",
    "        self.mlp = SwinV23DLayerMLP(dim, intermediate_ratio, mlp_drop_prob)\n",
    "        self.layernorm2 = nn.LayerNorm(dim, eps=layer_norm_eps)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "        _, num_patches_z, num_patches_y, num_patches_x, _ = hidden_states.shape\n",
    "\n",
    "        # Perform windowing\n",
    "        window_size_z, window_size_y, window_size_x = self.window_size\n",
    "        num_windows_z, num_windows_y, num_windows_x = (\n",
    "            num_patches_z // window_size_z,\n",
    "            num_patches_y // window_size_y,\n",
    "            num_patches_x // window_size_x,\n",
    "        )\n",
    "        hidden_states = rearrange(\n",
    "            hidden_states,\n",
    "            \"b (num_windows_z window_size_z) (num_windows_y window_size_y) (num_windows_x window_size_x) dim -> \"\n",
    "            \"(b num_windows_z num_windows_y num_windows_x) window_size_z window_size_y window_size_x dim \",\n",
    "            num_windows_z=num_windows_z,\n",
    "            num_windows_y=num_windows_y,\n",
    "            num_windows_x=num_windows_x,\n",
    "            window_size_z=window_size_z,\n",
    "            window_size_y=window_size_y,\n",
    "            window_size_x=window_size_x,\n",
    "        )\n",
    "\n",
    "        res_connection1 = hidden_states\n",
    "        # (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "\n",
    "        hidden_states = self.mhsa(hidden_states)\n",
    "        hidden_states = self.layernorm1(hidden_states)\n",
    "        # (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "\n",
    "        res_connection2 = hidden_states + res_connection1\n",
    "        # (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "\n",
    "        hidden_states = self.mlp(res_connection2)\n",
    "        hidden_states = self.layernorm2(hidden_states)\n",
    "        # (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "\n",
    "        hidden_states = hidden_states + res_connection2\n",
    "        # (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "\n",
    "        # Undo windowing\n",
    "        output = rearrange(\n",
    "            hidden_states,\n",
    "            \"(b num_windows_z num_windows_y num_windows_x) window_size_z window_size_y window_size_x dim -> \"\n",
    "            \"b (num_windows_z window_size_z) (num_windows_y window_size_y) (num_windows_x window_size_x) dim\",\n",
    "            num_windows_z=num_windows_z,\n",
    "            num_windows_y=num_windows_y,\n",
    "            num_windows_x=num_windows_x,\n",
    "            window_size_z=window_size_z,\n",
    "            window_size_y=window_size_y,\n",
    "            window_size_x=window_size_x,\n",
    "        )\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m16384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m16384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = SwinV23DLayer(64, 4, 256, 1e-6, (2, 2, 2), True)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 4, 4, 4, 64)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DBlock(nn.Module):\n",
    "    def __init__(self, stage_config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stage_config = stage_config\n",
    "        self.w_layer = SwinV23DLayer(\n",
    "            stage_config[\"_out_dim\"],\n",
    "            stage_config[\"num_heads\"],\n",
    "            stage_config[\"intermediate_ratio\"],\n",
    "            stage_config[\"layer_norm_eps\"],\n",
    "            stage_config[\"window_size\"],\n",
    "            stage_config[\"use_relative_position_bias\"],\n",
    "            stage_config.get(\"attn_drop_prob\", 0.0),\n",
    "            stage_config.get(\"proj_drop_prob\", 0.0),\n",
    "            stage_config.get(\"mlp_drop_prob\", 0.0),\n",
    "        )\n",
    "        self.sw_layer = SwinV23DLayer(\n",
    "            stage_config[\"_out_dim\"],\n",
    "            stage_config[\"num_heads\"],\n",
    "            stage_config[\"intermediate_ratio\"],\n",
    "            stage_config[\"layer_norm_eps\"],\n",
    "            stage_config[\"window_size\"],\n",
    "            stage_config[\"use_relative_position_bias\"],\n",
    "            stage_config.get(\"attn_drop_prob\", 0.0),\n",
    "            stage_config.get(\"proj_drop_prob\", 0.0),\n",
    "            stage_config.get(\"mlp_drop_prob\", 0.0),\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        layer_outputs = []\n",
    "\n",
    "        # First layer\n",
    "        hidden_states = self.w_layer(hidden_states)\n",
    "        # (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        layer_outputs.append(hidden_states)\n",
    "\n",
    "        # Shift windows\n",
    "        window_size_z, window_size_y, window_size_x = self.stage_config[\"window_size\"]\n",
    "        shifts = (window_size_z // 2, window_size_y // 2, window_size_x // 2)\n",
    "        hidden_states = torch.roll(hidden_states, shifts=shifts, dims=(1, 2, 3))\n",
    "        # (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        # Second layer\n",
    "        hidden_states = self.sw_layer(hidden_states)\n",
    "        # (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        # Reverse window shift\n",
    "        shifts = tuple(-shift for shift in shifts)\n",
    "        hidden_states = torch.roll(hidden_states, shifts=shifts, dims=(1, 2, 3))\n",
    "        # (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        layer_outputs.append(hidden_states)\n",
    "\n",
    "        return hidden_states, layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_stage_config = {\n",
    "    \"depth\": 4,\n",
    "    \"_out_dim\": 64,\n",
    "    \"num_heads\": 4,\n",
    "    \"intermediate_ratio\": 4,\n",
    "    \"layer_norm_eps\": 1e-6,\n",
    "    \"window_size\": (4, 4, 4),\n",
    "    \"use_relative_position_bias\": True,\n",
    "}\n",
    "\n",
    "test = SwinV23DBlock(test_stage_config)\n",
    "display(test)\n",
    "o = test(torch.randn(2, 4, 4, 4, 64))\n",
    "display((o[0].shape, (o[1][0].shape, o[1][1].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DPatchMerging(nn.Module):\n",
    "    def __init__(self, merge_window_size, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.merge_window_size = merge_window_size\n",
    "\n",
    "        in_dim = in_dim * np.prod(merge_window_size)\n",
    "        self.layer_norm = nn.LayerNorm(in_dim)\n",
    "        self.proj = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        window_size_z, window_size_y, window_size_x = self.merge_window_size\n",
    "\n",
    "        hidden_states = rearrange(\n",
    "            hidden_states,\n",
    "            \"b (new_num_patches_z window_size_z) (new_num_patches_y window_size_y) (new_num_patches_x window_size_x) dim -> \"\n",
    "            \"b new_num_patches_z new_num_patches_y new_num_patches_x (window_size_z window_size_y window_size_x dim)\",\n",
    "            window_size_z=window_size_z,\n",
    "            window_size_y=window_size_y,\n",
    "            window_size_x=window_size_x,\n",
    "        )\n",
    "\n",
    "        hidden_states = self.layer_norm(hidden_states)\n",
    "        hidden_states = self.proj(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DPatchMerging\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m192\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_stage_config = {\n",
    "    \"_in_dim\": 64,\n",
    "    \"_out_dim\": 64 * 3,\n",
    "    \"patch_merging\": {\n",
    "        \"merge_window_size\": (2, 2, 2),\n",
    "        \"out_dim_ratio\": 3,\n",
    "    },\n",
    "    \"depth\": 4,\n",
    "    \"num_heads\": 4,\n",
    "    \"intermediate_size\": 256,\n",
    "    \"layer_norm_eps\": 1e-6,\n",
    "    \"window_size\": (4, 4, 4),\n",
    "    \"use_relative_position_bias\": True,\n",
    "}\n",
    "\n",
    "test = SwinV23DPatchMerging(\n",
    "    test_stage_config[\"patch_merging\"][\"merge_window_size\"],\n",
    "    test_stage_config[\"_in_dim\"],\n",
    "    test_stage_config[\"_out_dim\"],\n",
    ")\n",
    "display(test)\n",
    "display(test(torch.randn(2, 4, 4, 4, 64)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DStage(nn.Module):\n",
    "    def __init__(self, stage_config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = stage_config\n",
    "\n",
    "        self.patch_merging = None\n",
    "        if stage_config[\"patch_merging\"] is not None:\n",
    "            self.patch_merging = SwinV23DPatchMerging(\n",
    "                stage_config[\"patch_merging\"][\"merge_window_size\"],\n",
    "                stage_config[\"_in_dim\"],\n",
    "                stage_config[\"_out_dim\"],\n",
    "            )\n",
    "\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [SwinV23DBlock(stage_config) for _ in range(stage_config[\"depth\"])],\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        if self.patch_merging:\n",
    "            hidden_states = self.patch_merging(hidden_states)\n",
    "            # (b, new_num_patches_z, new_num_patches_y, new_num_patches_x, new_dim)\n",
    "\n",
    "        layer_outputs = []\n",
    "        for layer_module in self.blocks:\n",
    "            hidden_states, _layer_outputs = layer_module(hidden_states)\n",
    "            # (b, new_num_patches_z, new_num_patches_y, new_num_patches_x, new_dim)\n",
    "            layer_outputs.extend(_layer_outputs)\n",
    "\n",
    "        return hidden_states, layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mpatch_merging\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchMerging\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m2\u001b[0m x \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m144\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m576\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m576\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m144\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m144\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m576\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m576\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m144\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m144\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m144\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m144\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m144\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m144\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_stage_config = {\n",
    "    \"patch_merging\": {\n",
    "        \"merge_window_size\": (2, 2, 2),\n",
    "        \"out_dim_ratio\": 3,\n",
    "    },\n",
    "    \"depth\": 2,\n",
    "    \"_in_dim\": 48,\n",
    "    \"_out_dim\": 48 * 3,\n",
    "    \"num_heads\": 4,\n",
    "    \"intermediate_ratio\": 4,\n",
    "    \"layer_norm_eps\": 1e-6,\n",
    "    \"window_size\": (4, 4, 4),\n",
    "    \"use_relative_position_bias\": True,\n",
    "}\n",
    "\n",
    "test = SwinV23DStage(test_stage_config)\n",
    "display(test)\n",
    "o = test(torch.randn(2, 8, 8, 8, 48))\n",
    "display((o[0].shape, [x.shape for x in o[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stages = nn.ModuleList([SwinV23DStage(stage_config) for stage_config in config[\"stages\"]])\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        stage_outputs, layer_outputs = [], []\n",
    "        for stage_module in self.stages:\n",
    "            hidden_states, _layer_outputs = stage_module(hidden_states)\n",
    "            # (b, new_num_patches_z, new_num_patches_y, new_num_patches_x, dim)\n",
    "\n",
    "            stage_outputs.append(hidden_states)\n",
    "            layer_outputs.extend(_layer_outputs)\n",
    "\n",
    "        return hidden_states, stage_outputs, layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DEncoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mstages\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mpatch_merging\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchMerging\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m3\u001b[0m x \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m288\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m96\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m96\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m288\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m96\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m96\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"stages\": [\n",
    "        {\n",
    "            \"patch_merging\": None,\n",
    "            \"_in_dim\": 32,\n",
    "            \"_out_dim\": 32,\n",
    "            \"depth\": 1,\n",
    "            \"num_heads\": 4,\n",
    "            \"intermediate_ratio\": 4,\n",
    "            \"layer_norm_eps\": 1e-6,\n",
    "            \"window_size\": (4, 4, 4),\n",
    "            \"use_relative_position_bias\": False,\n",
    "        },\n",
    "        {\n",
    "            \"patch_merging\": {\n",
    "                \"merge_window_size\": (2, 2, 2),\n",
    "                \"out_dim_ratio\": 3,\n",
    "            },\n",
    "            \"_in_dim\": 32,\n",
    "            \"_out_dim\": 32 * 3,\n",
    "            \"depth\": 3,\n",
    "            \"num_heads\": 4,\n",
    "            \"intermediate_ratio\": 4,\n",
    "            \"layer_norm_eps\": 1e-6,\n",
    "            \"window_size\": (4, 4, 4),\n",
    "            \"use_relative_position_bias\": True,\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "test = SwinV23DEncoder(test_config)\n",
    "display(test)\n",
    "o = test(torch.randn(2, 16, 16, 16, 32))\n",
    "display((o[0].shape, [x.shape for x in o[1]], [x.shape for x in o[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DPatchEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        patch_size = config[\"patch_size\"]\n",
    "        num_channels = config[\"in_channels\"]\n",
    "        dim = config[\"dim\"]\n",
    "\n",
    "        self.patch_embeddings = nn.Conv3d(\n",
    "            in_channels=num_channels,\n",
    "            out_channels=dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=patch_size,\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values: torch.Tensor):\n",
    "        # pixel_values: (b, c, z, y, x)\n",
    "\n",
    "        embeddings = self.patch_embeddings(pixel_values)\n",
    "        # (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DPatchEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"patch_size\": (1, 8, 8),\n",
    "    \"in_channels\": 1,\n",
    "    \"dim\": 12,\n",
    "}\n",
    "\n",
    "test = SwinV23DPatchEmbeddings(test_config)\n",
    "display(test)\n",
    "o = test(torch.randn(2, 1, 32, 512, 512))\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_3d_position_embeddings(embedding_size, grid_size, patch_size=(1, 1, 1)):\n",
    "    if embedding_size % 6 != 0:\n",
    "        raise ValueError(\"embed_dim must be divisible by 6\")\n",
    "\n",
    "    grid = get_coords_grid(grid_size)\n",
    "    # (3, d, h, w)\n",
    "\n",
    "    grid = rearrange(grid, \"x d h w -> x 1 d h w\")\n",
    "    # (3, 1, d, h, w)\n",
    "\n",
    "    omega = torch.arange(embedding_size // 6, dtype=torch.float32)\n",
    "    omega /= embedding_size / 6.0\n",
    "    omega = 1.0 / 10000**omega\n",
    "    # (d // 6)\n",
    "\n",
    "    patch_multiplier = torch.Tensor(patch_size) / min(patch_size)\n",
    "\n",
    "    position_embeddings = []\n",
    "    for i, grid_subset in enumerate(grid):\n",
    "        grid_subset = grid_subset.reshape(-1)\n",
    "        out = torch.einsum(\"m,d->md\", grid_subset, omega)\n",
    "\n",
    "        emb_sin = torch.sin(out)\n",
    "        emb_cos = torch.cos(out)\n",
    "\n",
    "        emb = torch.cat([emb_sin, emb_cos], axis=1) * patch_multiplier[i]\n",
    "        position_embeddings.append(emb)\n",
    "\n",
    "    position_embeddings = torch.cat(position_embeddings, axis=1)\n",
    "    # (embedding_size, d * h * w)\n",
    "    d, h, w = grid_size\n",
    "    position_embeddings = rearrange(position_embeddings, \"(d h w) e -> 1 e d h w\", d=d, h=h, w=w)\n",
    "    # (1, embedding_size, d, h, w)\n",
    "\n",
    "    return position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def embed_spacings_in_position_embeddings(embeddings: torch.Tensor, spacings: torch.Tensor):\n",
    "    assert spacings.ndim == 2, \"Please provide spacing information for each batch element\"\n",
    "    _, embedding_size, _, _, _ = embeddings.shape\n",
    "    assert embedding_size % 3 == 0, \"To embed spacing info, the embedding size must be divisible by 3\"\n",
    "    embeddings = embeddings * repeat(spacings, f\"B S -> B (S {int(embedding_size / 3)}) 1 1 1\", S=3)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        dim = config[\"dim\"]\n",
    "\n",
    "        self.patch_embeddings = SwinV23DPatchEmbeddings(config)\n",
    "        self.layer_norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.absolute_position_embeddings = None\n",
    "        if config[\"use_absolute_position_embeddings\"]:\n",
    "            grid_size = (\n",
    "                config[\"image_size\"][0] // config[\"patch_size\"][0],\n",
    "                config[\"image_size\"][1] // config[\"patch_size\"][1],\n",
    "                config[\"image_size\"][2] // config[\"patch_size\"][2],\n",
    "            )\n",
    "            if config[\"learnable_absolute_position_embeddings\"]:\n",
    "                self.absolute_position_embeddings = nn.Parameter(\n",
    "                    torch.randn(1, dim, grid_size[0], grid_size[1], grid_size[2])\n",
    "                )\n",
    "            else:\n",
    "                self.absolute_position_embeddings = get_3d_position_embeddings(dim, grid_size, config[\"patch_size\"])\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: torch.Tensor,\n",
    "        spacings: torch.Tensor,\n",
    "        mask_patches: torch.Tensor = None,\n",
    "        mask_token: torch.Tensor = None,\n",
    "    ):\n",
    "        # pixel_values: (b, c, z, y, x)\n",
    "\n",
    "        embeddings = self.patch_embeddings(pixel_values)\n",
    "        # (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "        embeddings = rearrange(embeddings, \"b d nz ny nx -> b nz ny nx d\")\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = rearrange(embeddings, \"b nz ny nx d -> b d nz ny nx\")\n",
    "        # (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        if mask_patches is not None:\n",
    "            # mask_patches (binary mask): (b, num_patches_z, num_patches_y, num_patches_x)\n",
    "            # mask_token: (1, dim, 1, 1, 1)\n",
    "            mask_patches = repeat(mask_patches, \"b z y x -> b d z y x\", d=embeddings.shape[1])\n",
    "            embeddings = (embeddings * (1 - mask_patches)) + (mask_patches * mask_token)\n",
    "\n",
    "        if self.absolute_position_embeddings is not None:\n",
    "            absolute_position_embeddings = self.absolute_position_embeddings.to(embeddings.device)\n",
    "            # (1, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "            if self.config[\"embed_spacing_info\"]:\n",
    "                absolute_position_embeddings = embed_spacings_in_position_embeddings(\n",
    "                    absolute_position_embeddings, spacings\n",
    "                )\n",
    "                # (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "            embeddings = embeddings + absolute_position_embeddings\n",
    "            # (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"patch_size\": (1, 8, 8),\n",
    "    \"in_channels\": 1,\n",
    "    \"dim\": 36,\n",
    "    \"use_absolute_position_embeddings\": True,\n",
    "    \"learnable_absolute_position_embeddings\": False,\n",
    "    \"embed_spacing_info\": False,\n",
    "    \"image_size\": (32, 512, 512),\n",
    "}\n",
    "\n",
    "test = SwinV23DEmbeddings(test_config)\n",
    "display(test)\n",
    "o = test(\n",
    "    torch.randn(2, 1, 32, 512, 512),\n",
    "    torch.randn(2, 3),\n",
    ")\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance of (0, 0, 0) with other coords\n",
      "(0, 0, 0) 0.0\n",
      "(0, 0, 1) 0.95885104\n",
      "(0, 1, 0) 0.95885104\n",
      "(0, 1, 1) 1.3560202\n",
      "(1, 0, 0) 0.95885104\n",
      "(1, 0, 1) 1.3560202\n",
      "(1, 1, 0) 1.3560202\n",
      "(1, 1, 1) 1.6607788\n"
     ]
    }
   ],
   "source": [
    "e = get_3d_position_embeddings(6, (2, 2, 2), (1, 1, 1))\n",
    "display(e.shape)\n",
    "\n",
    "print(\"Distance of (0, 0, 0) with other coords\")\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            print((i, j, k), np.linalg.norm(e[0, :, 0, 0, 0] - e[0, :, i, j, k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings = SwinV23DEmbeddings(config)\n",
    "        self.pos_drop = nn.Dropout(config.get(\"drop_prob\", 0.0))\n",
    "        self.encoder = SwinV23DEncoder(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: torch.Tensor,\n",
    "        spacings: torch.Tensor,\n",
    "        mask_patches: torch.Tensor = None,\n",
    "        mask_token: torch.Tensor = None,\n",
    "    ):\n",
    "        # pixel_values: (b, c, z, y, x)\n",
    "        # spacings: (b, 3)\n",
    "        # mask_patches: (num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        embeddings = self.embeddings(pixel_values, spacings, mask_patches, mask_token)\n",
    "        embeddings = self.pos_drop(embeddings)\n",
    "        # (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        embeddings = rearrange(embeddings, \"b e nz ny nx -> b nz ny nx e\")\n",
    "        # (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        encoded, stage_outputs, layer_outputs = self.encoder(embeddings)\n",
    "        # encoded: (b, new_num_patches_z, new_num_patches_y, new_num_patches_x, dim)\n",
    "        # stage_outputs, layer_outputs: list of (b, some_num_patches_z, some_num_patches_y, some_num_patches_x, dim)\n",
    "\n",
    "        encoded = rearrange(encoded, \"b nz ny nx d -> b d nz ny nx\")\n",
    "        # (b, dim, new_num_patches_z, new_num_patches_y, new_num_patches_x)\n",
    "\n",
    "        for i in range(len(stage_outputs)):\n",
    "            stage_outputs[i] = rearrange(stage_outputs[i], \"b nz ny nx d -> b d nz ny nx\")\n",
    "            # (b, dim, some_num_patches_z, some_num_patches_y, some_num_patches_x)\n",
    "\n",
    "        for i in range(len(layer_outputs)):\n",
    "            layer_outputs[i] = rearrange(layer_outputs[i], \"b nz ny nx d -> b d nz ny nx\")\n",
    "            # (b, dim, some_num_patches_z, some_num_patches_y, some_num_patches_x)\n",
    "\n",
    "        return encoded, stage_outputs, layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0membeddings\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mpos_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mencoder\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DEncoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mstages\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mpatch_merging\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchMerging\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m288\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m288\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m3\u001b[0m x \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mpatch_merging\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchMerging\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m864\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m864\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m972\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m324\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1296\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1296\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m324\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m972\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m324\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1296\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1296\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m324\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m324\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m324\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m324\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m324\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = populate_and_validate_config(\n",
    "    {\n",
    "        \"patch_size\": (1, 8, 8),\n",
    "        \"in_channels\": 1,\n",
    "        \"use_absolute_position_embeddings\": True,\n",
    "        \"learnable_absolute_position_embeddings\": False,\n",
    "        \"embed_spacing_info\": False,\n",
    "        \"image_size\": (32, 512, 512),\n",
    "        \"dim\": 36,\n",
    "        \"drop_prob\": 0.2,\n",
    "        \"stages\": [\n",
    "            {\n",
    "                \"patch_merging\": None,\n",
    "                \"depth\": 1,\n",
    "                \"num_heads\": 4,\n",
    "                \"intermediate_ratio\": 4,\n",
    "                \"layer_norm_eps\": 1e-6,\n",
    "                \"window_size\": (4, 4, 4),\n",
    "                \"use_relative_position_bias\": False,\n",
    "                \"attn_drop_prob\": 0.2,\n",
    "                \"proj_drop_prob\": 0.2,\n",
    "                \"mlp_drop_prob\": 0.2,\n",
    "            },\n",
    "            {\n",
    "                \"patch_merging\": {\n",
    "                    \"merge_window_size\": (2, 2, 2),\n",
    "                    \"out_dim_ratio\": 3,\n",
    "                },\n",
    "                \"depth\": 3,\n",
    "                \"num_heads\": 4,\n",
    "                \"intermediate_ratio\": 4,\n",
    "                \"layer_norm_eps\": 1e-6,\n",
    "                \"window_size\": (4, 4, 4),\n",
    "                \"use_relative_position_bias\": True,\n",
    "                \"attn_drop_prob\": 0.2,\n",
    "                \"proj_drop_prob\": 0.2,\n",
    "                \"mlp_drop_prob\": 0.2,\n",
    "            },\n",
    "            {\n",
    "                \"patch_merging\": {\n",
    "                    \"merge_window_size\": (2, 2, 2),\n",
    "                    \"out_dim_ratio\": 3,\n",
    "                },\n",
    "                \"depth\": 1,\n",
    "                \"num_heads\": 4,\n",
    "                \"intermediate_ratio\": 4,\n",
    "                \"layer_norm_eps\": 1e-6,\n",
    "                \"window_size\": (4, 4, 4),\n",
    "                \"use_relative_position_bias\": True,\n",
    "                \"attn_drop_prob\": 0.2,\n",
    "                \"proj_drop_prob\": 0.2,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "test = SwinV23DModel(test_config)\n",
    "display(test)\n",
    "o = test(\n",
    "    torch.randn(2, 1, 32, 512, 512),\n",
    "    torch.randn(2, 3),\n",
    ")\n",
    "display((o[0].shape, [x.shape for x in o[1]], [x.shape for x in o[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Image Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DReconstructionDecoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = config[\"in_channels\"]\n",
    "\n",
    "        dim = config[\"dim\"]\n",
    "        patch_size = config[\"patch_size\"]\n",
    "\n",
    "        out_dim = np.prod(patch_size) * self.in_channels\n",
    "        self.final_patch_size = patch_size\n",
    "\n",
    "        self.decoder = nn.Conv3d(dim, out_dim, kernel_size=1)\n",
    "\n",
    "    def forward(self, encodings: torch.Tensor):\n",
    "        # encodings: (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        decoded = self.decoder(encodings)\n",
    "        # (b, new_dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        decoded = rearrange(\n",
    "            decoded,\n",
    "            \"b (c pz py px) nz ny nx -> b c (nz pz) (ny py) (nx px)\",\n",
    "            c=self.in_channels,\n",
    "            pz=self.final_patch_size[0],\n",
    "            py=self.final_patch_size[1],\n",
    "            px=self.final_patch_size[2],\n",
    "        )\n",
    "        # (b, c, z, y, x)\n",
    "\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DReconstructionDecoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdecoder\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"dim\": 108,\n",
    "    \"patch_size\": (2, 16, 16),\n",
    "    \"in_channels\": 1,\n",
    "}\n",
    "\n",
    "test = SwinV23DReconstructionDecoder(test_config)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 108, 16, 32, 32)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DMIM(nn.Module):\n",
    "    def __init__(self, swin_config, decoder_config, mim_config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.swin_config = swin_config\n",
    "        self.decoder_config = decoder_config\n",
    "        self.mim_config = mim_config\n",
    "\n",
    "        self.swin = SwinV23DModel(swin_config)\n",
    "        self.decoder = SwinV23DReconstructionDecoder(decoder_config)\n",
    "\n",
    "        self.mask_token = nn.Parameter(torch.randn(1, swin_config[\"dim\"], 1, 1, 1))\n",
    "\n",
    "    def mask_image(self, pixel_values: torch.Tensor):\n",
    "        b = pixel_values.shape[0]\n",
    "\n",
    "        mask_ratio = self.mim_config[\"mask_ratio\"]\n",
    "        mask_grid_size = self.mim_config[\"mask_grid_size\"]\n",
    "        num_patches = np.prod(mask_grid_size)\n",
    "        mask_patches = []\n",
    "        for _ in range(b):\n",
    "            _mask_patches = torch.zeros(num_patches, dtype=torch.int8, device=pixel_values.device)\n",
    "            _mask_patches[: int(mask_ratio * num_patches)] = 1\n",
    "            _mask_patches = _mask_patches[torch.randperm(num_patches)]\n",
    "            _mask_patches = rearrange(\n",
    "                _mask_patches, \"(z y x) -> z y x\", z=mask_grid_size[0], y=mask_grid_size[1], x=mask_grid_size[2]\n",
    "            )\n",
    "            mask_patches.append(_mask_patches)\n",
    "        mask_patches: torch.Tensor = torch.stack(mask_patches, dim=0)\n",
    "\n",
    "        grid_size = tuple(\n",
    "            [size // patch for size, patch in zip(self.swin_config[\"image_size\"], self.swin_config[\"patch_size\"])]\n",
    "        )\n",
    "        assert all(\n",
    "            [x % y == 0 for x, y in zip(grid_size, mask_grid_size)]\n",
    "        ), \"Mask grid size must divide image grid size\"\n",
    "        mask_patches = repeat(\n",
    "            mask_patches,\n",
    "            \"b z y x -> b (z gz) (y gy) (x gx)\",\n",
    "            gz=grid_size[0] // mask_grid_size[0],\n",
    "            gy=grid_size[1] // mask_grid_size[1],\n",
    "            gx=grid_size[2] // mask_grid_size[2],\n",
    "        )\n",
    "\n",
    "        return mask_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DSimMIM(SwinV23DMIM):\n",
    "    def __init__(self, swin_config, decoder_config, mim_config):\n",
    "        super().__init__(swin_config, decoder_config, mim_config)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_fn(pred: torch.Tensor, target: torch.Tensor, reduction=\"mean\"):\n",
    "        return nn.functional.l1_loss(pred, target, reduction=reduction)\n",
    "\n",
    "    def forward(self, pixel_values: torch.Tensor, spacings: torch.Tensor):\n",
    "        mask_patches = self.mask_image(pixel_values)\n",
    "\n",
    "        encodings, _, _ = self.swin(pixel_values, spacings, mask_patches, self.mask_token)\n",
    "\n",
    "        decoded = self.decoder(encodings)\n",
    "\n",
    "        loss = self.loss_fn(decoded, pixel_values, reduction=\"none\")\n",
    "        mask = repeat(\n",
    "            mask_patches,\n",
    "            \"b z y x -> b (z pz) (y py) (x px)\",\n",
    "            pz=self.swin_config[\"patch_size\"][0],\n",
    "            py=self.swin_config[\"patch_size\"][1],\n",
    "            px=self.swin_config[\"patch_size\"][2],\n",
    "        )\n",
    "        print(loss.shape, mask.shape)\n",
    "        loss = (loss * mask).sum() / ((mask.sum() + 1e-5) * self.swin_config[\"in_channels\"])\n",
    "\n",
    "        return decoded, loss, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DSimMIM\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mswin\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0membeddings\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mpos_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mencoder\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DEncoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mstages\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m2\u001b[0m x \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mpatch_merging\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchMerging\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m288\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m288\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m6\u001b[0m x \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdecoder\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DReconstructionDecoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdecoder\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 32, 512, 512]) torch.Size([2, 32, 512, 512])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m5.2103\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDivBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"swin\": populate_and_validate_config(\n",
    "        {\n",
    "            \"dim\": 36,\n",
    "            \"patch_size\": (1, 8, 8),\n",
    "            \"in_channels\": 1,\n",
    "            \"use_absolute_position_embeddings\": True,\n",
    "            \"learnable_absolute_position_embeddings\": False,\n",
    "            \"embed_spacing_info\": False,\n",
    "            \"image_size\": (32, 512, 512),\n",
    "            \"stages\": [\n",
    "                {\n",
    "                    \"patch_merging\": None,\n",
    "                    \"depth\": 2,\n",
    "                    \"num_heads\": 4,\n",
    "                    \"intermediate_ratio\": 4,\n",
    "                    \"layer_norm_eps\": 1e-6,\n",
    "                    \"window_size\": (4, 4, 4),\n",
    "                    \"use_relative_position_bias\": False,\n",
    "                },\n",
    "                {\n",
    "                    \"patch_merging\": {\n",
    "                        \"merge_window_size\": (2, 2, 2),\n",
    "                        \"out_dim_ratio\": 3,\n",
    "                    },\n",
    "                    \"depth\": 6,\n",
    "                    \"num_heads\": 4,\n",
    "                    \"intermediate_ratio\": 4,\n",
    "                    \"layer_norm_eps\": 1e-6,\n",
    "                    \"window_size\": (4, 4, 4),\n",
    "                    \"use_relative_position_bias\": True,\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ),\n",
    "    \"mim\": {\n",
    "        \"mask_ratio\": 0.8,\n",
    "        \"mask_grid_size\": (8, 8, 8),\n",
    "    },\n",
    "}\n",
    "test_config[\"decoder\"] = {\n",
    "    \"dim\": test_config[\"swin\"][\"stages\"][-1][\"_out_dim\"],\n",
    "    \"patch_size\": test_config[\"swin\"][\"stages\"][-1][\"_out_patch_size\"],\n",
    "    \"in_channels\": test_config[\"swin\"][\"in_channels\"],\n",
    "}\n",
    "\n",
    "test = SwinV23DSimMIM(test_config[\"swin\"], test_config[\"decoder\"], test_config[\"mim\"])\n",
    "display(test)\n",
    "o = test(\n",
    "    torch.randn(2, 1, 32, 512, 512),\n",
    "    torch.randn(2, 3),\n",
    ")\n",
    "display((o[0].shape, o[1], o[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe60fd0801fb4b0998a7fd7a5b7e7be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='z', max=31), Output()), _dom_classes=('widget-interact',"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from neuro_utils.visualize import plot_scans\n",
    "\n",
    "plot_scans([o[0][0, 0].detach(), o[0][0, 0].detach() * (1 - o[2][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DVAEMIM(SwinV23DMIM):\n",
    "    def __init__(self, swin_config, decoder_config, mim_config):\n",
    "        super().__init__(swin_config, decoder_config, mim_config)\n",
    "\n",
    "        self.mu_layer = nn.Conv3d(swin_config[\"stages\"][-1][\"_out_dim\"], decoder_config[\"dim\"], kernel_size=1)\n",
    "        self.logvar_layer = nn.Conv3d(swin_config[\"stages\"][-1][\"_out_dim\"], decoder_config[\"dim\"], kernel_size=1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        return mu + torch.randn_like(logvar) * torch.exp(0.5 * logvar)\n",
    "\n",
    "    @staticmethod\n",
    "    def reconstruction_loss_fn(pred: torch.Tensor, target: torch.Tensor, loss_type: str = \"l2\", reduction=\"mean\"):\n",
    "        loss = ...\n",
    "        if loss_type == \"l2\":\n",
    "            loss = nn.functional.mse_loss(pred, target, reduction=reduction)\n",
    "        elif loss_type == \"l1\":\n",
    "            loss = nn.functional.l1_loss(pred, target, reduction=reduction)\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def kl_divergence_loss_fn(mu: torch.Tensor, logvar: torch.Tensor):\n",
    "        return torch.mean(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: torch.Tensor,\n",
    "        spacings: torch.Tensor,\n",
    "        reconstruction_loss_type: str = \"l2\",\n",
    "        lambda_reconstruction_loss: float = 1.0,\n",
    "        lambda_kl_loss: float = 1.0,\n",
    "    ):\n",
    "        mask_patches = self.mask_image(pixel_values)\n",
    "\n",
    "        encodings, _, _ = self.swin(pixel_values, spacings, mask_patches, self.mask_token)\n",
    "\n",
    "        mu = self.mu_layer(encodings)\n",
    "        logvar = self.logvar_layer(encodings)\n",
    "        kl_loss = self.kl_divergence_loss_fn(mu, logvar)\n",
    "\n",
    "        sampled = self.reparameterize(mu, logvar)\n",
    "        decoded = self.decoder(sampled)\n",
    "\n",
    "        reconstruction_loss = self.reconstruction_loss_fn(decoded, pixel_values, reconstruction_loss_type)\n",
    "\n",
    "        mask = repeat(\n",
    "            mask_patches,\n",
    "            \"b z y x -> b (z pz) (y py) (x px)\",\n",
    "            pz=self.swin_config[\"patch_size\"][0],\n",
    "            py=self.swin_config[\"patch_size\"][1],\n",
    "            px=self.swin_config[\"patch_size\"][2],\n",
    "        )\n",
    "\n",
    "        loss = lambda_reconstruction_loss * reconstruction_loss + lambda_kl_loss * kl_loss\n",
    "\n",
    "        return decoded, loss, mask, [reconstruction_loss, kl_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DVAEMIM\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mswin\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0membeddings\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mpos_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mencoder\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DEncoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mstages\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m2\u001b[0m x \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mpatch_merging\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchMerging\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m288\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m288\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m6\u001b[0m x \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdecoder\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DReconstructionDecoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdecoder\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmu_layer\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlogvar_layer\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1662.3784\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mAddBackward0\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m32\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m512\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m11.4383\u001b[0m\u001b[39m, \u001b[0m\u001b[33mgrad_fn\u001b[0m\u001b[39m=<MseLossBackward0>\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m, \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m1650.9402\u001b[0m\u001b[39m, \u001b[0m\u001b[33mgrad_fn\u001b[0m\u001b[39m=<MeanBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"swin\": populate_and_validate_config(\n",
    "        {\n",
    "            \"dim\": 36,\n",
    "            \"patch_size\": (1, 8, 8),\n",
    "            \"in_channels\": 1,\n",
    "            \"use_absolute_position_embeddings\": True,\n",
    "            \"learnable_absolute_position_embeddings\": False,\n",
    "            \"embed_spacing_info\": False,\n",
    "            \"image_size\": (32, 512, 512),\n",
    "            \"stages\": [\n",
    "                {\n",
    "                    \"patch_merging\": None,\n",
    "                    \"depth\": 2,\n",
    "                    \"num_heads\": 4,\n",
    "                    \"intermediate_ratio\": 4,\n",
    "                    \"layer_norm_eps\": 1e-6,\n",
    "                    \"window_size\": (4, 4, 4),\n",
    "                    \"use_relative_position_bias\": False,\n",
    "                },\n",
    "                {\n",
    "                    \"patch_merging\": {\n",
    "                        \"merge_window_size\": (2, 2, 2),\n",
    "                        \"out_dim_ratio\": 3,\n",
    "                    },\n",
    "                    \"depth\": 6,\n",
    "                    \"num_heads\": 4,\n",
    "                    \"intermediate_ratio\": 4,\n",
    "                    \"layer_norm_eps\": 1e-6,\n",
    "                    \"window_size\": (4, 4, 4),\n",
    "                    \"use_relative_position_bias\": True,\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ),\n",
    "    \"mim\": {\n",
    "        \"mask_ratio\": 0.8,\n",
    "        \"mask_grid_size\": (8, 8, 8),\n",
    "    },\n",
    "}\n",
    "test_config[\"decoder\"] = {\n",
    "    \"dim\": test_config[\"swin\"][\"stages\"][-1][\"_out_dim\"],\n",
    "    \"patch_size\": test_config[\"swin\"][\"stages\"][-1][\"_out_patch_size\"],\n",
    "    \"in_channels\": test_config[\"swin\"][\"in_channels\"],\n",
    "}\n",
    "\n",
    "test = SwinV23DVAEMIM(test_config[\"swin\"], test_config[\"decoder\"], test_config[\"mim\"])\n",
    "display(test)\n",
    "o = test(\n",
    "    torch.randn(2, 1, 32, 512, 512),\n",
    "    torch.randn(2, 3),\n",
    ")\n",
    "display((o[0].shape, o[1], o[2].shape, o[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some more tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m1183892\u001b[0m, \u001b[1;36m197632\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "sample_spacings = torch.tensor([[1, 0.1, 0.1], [2, 0.2, 0.2], [3, 0.3, 0.3], [4, 0.4, 0.4], [5, 0.5, 0.5]])\n",
    "sample_batch = torch.rand(3, 1, 16, 128, 128)\n",
    "sample_config = {\n",
    "    \"swin\": populate_and_validate_config(\n",
    "        {\n",
    "            \"patch_size\": (1, 4, 4),\n",
    "            \"dim\": 12,\n",
    "            \"in_channels\": 1,\n",
    "            \"use_absolute_position_embeddings\": True,\n",
    "            \"learnable_absolute_position_embeddings\": False,\n",
    "            \"embed_spacing_info\": False,\n",
    "            \"image_size\": (16, 128, 128),\n",
    "            \"drop_prob\": 0.2,\n",
    "            \"stages\": [\n",
    "                {\n",
    "                    \"patch_merging\": None,\n",
    "                    \"depth\": 1,\n",
    "                    \"num_heads\": 4,\n",
    "                    \"intermediate_ratio\": 4,\n",
    "                    \"layer_norm_eps\": 1e-6,\n",
    "                    \"window_size\": (4, 4, 4),\n",
    "                    \"use_relative_position_bias\": True,\n",
    "                    \"attn_drop_prob\": 0.2,\n",
    "                    \"proj_drop_prob\": 0.2,\n",
    "                    \"mlp_drop_prob\": 0.2,\n",
    "                },\n",
    "                {\n",
    "                    \"patch_merging\": {\n",
    "                        \"merge_window_size\": (2, 2, 2),\n",
    "                        \"out_dim_ratio\": 4,\n",
    "                    },\n",
    "                    \"depth\": 3,\n",
    "                    \"num_heads\": 4,\n",
    "                    \"intermediate_ratio\": 4,\n",
    "                    \"layer_norm_eps\": 1e-6,\n",
    "                    \"window_size\": (4, 4, 4),\n",
    "                    \"use_relative_position_bias\": True,\n",
    "                },\n",
    "                {\n",
    "                    \"patch_merging\": {\n",
    "                        \"merge_window_size\": (2, 2, 2),\n",
    "                        \"out_dim_ratio\": 4,\n",
    "                    },\n",
    "                    \"depth\": 1,\n",
    "                    \"num_heads\": 4,\n",
    "                    \"intermediate_ratio\": 4,\n",
    "                    \"layer_norm_eps\": 1e-6,\n",
    "                    \"window_size\": (4, 4, 4),\n",
    "                    \"use_relative_position_bias\": True,\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ),\n",
    "    \"mim\": {\n",
    "        \"mask_ratio\": 0.7,\n",
    "        \"mask_grid_size\": (8, 8, 8),\n",
    "    },\n",
    "}\n",
    "sample_config[\"decoder\"] = {\n",
    "    \"dim\": sample_config[\"swin\"][\"stages\"][-1][\"_out_dim\"],\n",
    "    \"patch_size\": sample_config[\"swin\"][\"stages\"][-1][\"_out_patch_size\"],\n",
    "    \"in_channels\": sample_config[\"swin\"][\"in_channels\"],\n",
    "}\n",
    "\n",
    "model = SwinV23DSimMIM(sample_config['swin'], sample_config['decoder'], sample_config['mim'])\n",
    "\n",
    "sum(x.numel() for x in model.swin.parameters()), sum(x.numel() for x in model.decoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 1,381,536\n",
      "+---------------------------------------------------------------+------------+\n",
      "|                             Module                            | Parameters |\n",
      "+---------------------------------------------------------------+------------+\n",
      "|                           mask_token                          |     12     |\n",
      "|    swin.embeddings.patch_embeddings.patch_embeddings.weight   |    192     |\n",
      "|     swin.embeddings.patch_embeddings.patch_embeddings.bias    |     12     |\n",
      "|               swin.embeddings.layer_norm.weight               |     12     |\n",
      "|                swin.embeddings.layer_norm.bias                |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mhsa.W_qkv.weight   |    432     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mhsa.W_qkv.bias    |     36     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mhsa.proj.weight    |    144     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mhsa.proj.bias     |     12     |\n",
      "|  swin.encoder.stages.0.blocks.0.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.0.blocks.0.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.0.blocks.0.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.layernorm1.weight   |     12     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.layernorm1.bias    |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mlp.dense1.weight   |    576     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mlp.dense1.bias    |     48     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mlp.dense2.weight   |    576     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mlp.dense2.bias    |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.layernorm2.weight   |     12     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.layernorm2.bias    |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.mhsa.W_qkv.weight   |    432     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mhsa.W_qkv.bias    |     36     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mhsa.proj.weight   |    144     |\n",
      "|     swin.encoder.stages.0.blocks.0.sw_layer.mhsa.proj.bias    |     12     |\n",
      "| swin.encoder.stages.0.blocks.0.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.0.blocks.0.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.0.blocks.0.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.layernorm1.weight   |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.layernorm1.bias    |     12     |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense1.weight   |    576     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense1.bias    |     48     |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense2.weight   |    576     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense2.bias    |     12     |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.layernorm2.weight   |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.layernorm2.bias    |     12     |\n",
      "|     swin.encoder.stages.1.patch_merging.layer_norm.weight     |     96     |\n",
      "|      swin.encoder.stages.1.patch_merging.layer_norm.bias      |     96     |\n",
      "|        swin.encoder.stages.1.patch_merging.proj.weight        |   4,608    |\n",
      "|         swin.encoder.stages.1.patch_merging.proj.bias         |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mhsa.proj.weight    |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mhsa.proj.bias     |     48     |\n",
      "|  swin.encoder.stages.1.blocks.0.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.1.blocks.0.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.1.blocks.0.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.layernorm1.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.layernorm1.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mlp.dense1.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mlp.dense1.bias    |    192     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mlp.dense2.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mlp.dense2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.layernorm2.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mhsa.proj.weight   |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.0.sw_layer.mhsa.proj.bias    |     48     |\n",
      "| swin.encoder.stages.1.blocks.0.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.1.blocks.0.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.1.blocks.0.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.layernorm1.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.layernorm1.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense1.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense1.bias    |    192     |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense2.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense2.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.layernorm2.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mhsa.proj.weight    |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mhsa.proj.bias     |     48     |\n",
      "|  swin.encoder.stages.1.blocks.1.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.1.blocks.1.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.1.blocks.1.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.layernorm1.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.layernorm1.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mlp.dense1.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mlp.dense1.bias    |    192     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mlp.dense2.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mlp.dense2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.layernorm2.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mhsa.proj.weight   |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.1.sw_layer.mhsa.proj.bias    |     48     |\n",
      "| swin.encoder.stages.1.blocks.1.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.1.blocks.1.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.1.blocks.1.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.layernorm1.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.layernorm1.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense1.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense1.bias    |    192     |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense2.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense2.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.layernorm2.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mhsa.proj.weight    |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mhsa.proj.bias     |     48     |\n",
      "|  swin.encoder.stages.1.blocks.2.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.1.blocks.2.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.1.blocks.2.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.layernorm1.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.layernorm1.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mlp.dense1.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mlp.dense1.bias    |    192     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mlp.dense2.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mlp.dense2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.layernorm2.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mhsa.proj.weight   |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.2.sw_layer.mhsa.proj.bias    |     48     |\n",
      "| swin.encoder.stages.1.blocks.2.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.1.blocks.2.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.1.blocks.2.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.layernorm1.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.layernorm1.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense1.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense1.bias    |    192     |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense2.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense2.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.layernorm2.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.layernorm2.bias    |     48     |\n",
      "|     swin.encoder.stages.2.patch_merging.layer_norm.weight     |    384     |\n",
      "|      swin.encoder.stages.2.patch_merging.layer_norm.bias      |    384     |\n",
      "|        swin.encoder.stages.2.patch_merging.proj.weight        |   73,728   |\n",
      "|         swin.encoder.stages.2.patch_merging.proj.bias         |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mhsa.W_qkv.weight   |  110,592   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mhsa.W_qkv.bias    |    576     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mhsa.proj.weight    |   36,864   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mhsa.proj.bias     |    192     |\n",
      "|  swin.encoder.stages.2.blocks.0.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.2.blocks.0.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.2.blocks.0.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.layernorm1.weight   |    192     |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.layernorm1.bias    |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mlp.dense1.weight   |  147,456   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mlp.dense1.bias    |    768     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mlp.dense2.weight   |  147,456   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mlp.dense2.bias    |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.layernorm2.weight   |    192     |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.layernorm2.bias    |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.mhsa.W_qkv.weight   |  110,592   |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mhsa.W_qkv.bias    |    576     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mhsa.proj.weight   |   36,864   |\n",
      "|     swin.encoder.stages.2.blocks.0.sw_layer.mhsa.proj.bias    |    192     |\n",
      "| swin.encoder.stages.2.blocks.0.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.2.blocks.0.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.2.blocks.0.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.layernorm1.weight   |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.layernorm1.bias    |    192     |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense1.weight   |  147,456   |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense1.bias    |    768     |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense2.weight   |  147,456   |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense2.bias    |    192     |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.layernorm2.weight   |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.layernorm2.bias    |    192     |\n",
      "|                     decoder.decoder.weight                    |  196,608   |\n",
      "|                      decoder.decoder.bias                     |   1,024    |\n",
      "+---------------------------------------------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from neuro_utils.describe import describe_model\n",
    "\n",
    "describe_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = sample_batch.cuda()\n",
    "sample_spacings = sample_spacings.cuda()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd62f183760f4f059f88c0dd1ed6a3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 3.335559\tLR: 0.500000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 3.543763\tLR: 0.500000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 3.827474\tLR: 0.500000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 3.516118\tLR: 0.500000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 3.291771\tLR: 0.500000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 3.193243\tLR: 0.450000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 3.189499\tLR: 0.450000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 2.785329\tLR: 0.450000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 2.240405\tLR: 0.450000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 2.349389\tLR: 0.450000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.962779\tLR: 0.405000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 2.390502\tLR: 0.405000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 2.099174\tLR: 0.405000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.818396\tLR: 0.405000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.556686\tLR: 0.405000\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.688425\tLR: 0.364500\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.518436\tLR: 0.364500\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.544053\tLR: 0.364500\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.650775\tLR: 0.364500\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.314335\tLR: 0.364500\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.627260\tLR: 0.328050\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.048685\tLR: 0.328050\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.149758\tLR: 0.328050\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.282214\tLR: 0.328050\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.115559\tLR: 0.328050\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.179437\tLR: 0.295245\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.063967\tLR: 0.295245\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.140042\tLR: 0.295245\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.164236\tLR: 0.295245\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.176924\tLR: 0.295245\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.086051\tLR: 0.265721\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.006318\tLR: 0.265721\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.983622\tLR: 0.265721\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.008187\tLR: 0.265721\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.021014\tLR: 0.265721\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 1.012891\tLR: 0.239148\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.917297\tLR: 0.239148\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.883221\tLR: 0.239148\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.874098\tLR: 0.239148\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.874419\tLR: 0.239148\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.875220\tLR: 0.215234\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.841063\tLR: 0.215234\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.815915\tLR: 0.215234\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.804772\tLR: 0.215234\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.795047\tLR: 0.215234\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.789943\tLR: 0.193710\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.775293\tLR: 0.193710\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.768027\tLR: 0.193710\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.764444\tLR: 0.193710\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.761639\tLR: 0.193710\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.760635\tLR: 0.174339\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.758826\tLR: 0.174339\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.758022\tLR: 0.174339\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.757735\tLR: 0.174339\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.757582\tLR: 0.174339\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.757193\tLR: 0.156905\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.756752\tLR: 0.156905\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.756320\tLR: 0.156905\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755996\tLR: 0.156905\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.756468\tLR: 0.156905\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755669\tLR: 0.141215\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.756124\tLR: 0.141215\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755918\tLR: 0.141215\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.756077\tLR: 0.141215\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755660\tLR: 0.141215\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755627\tLR: 0.127093\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754830\tLR: 0.127093\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755432\tLR: 0.127093\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755670\tLR: 0.127093\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755283\tLR: 0.127093\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755211\tLR: 0.114384\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755041\tLR: 0.114384\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755688\tLR: 0.114384\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755197\tLR: 0.114384\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755276\tLR: 0.114384\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755127\tLR: 0.102946\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.755068\tLR: 0.102946\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754508\tLR: 0.102946\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754257\tLR: 0.102946\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754959\tLR: 0.102946\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754549\tLR: 0.092651\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754139\tLR: 0.092651\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753943\tLR: 0.092651\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754401\tLR: 0.092651\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754145\tLR: 0.092651\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754532\tLR: 0.083386\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754506\tLR: 0.083386\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754527\tLR: 0.083386\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754669\tLR: 0.083386\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754241\tLR: 0.083386\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754303\tLR: 0.075047\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754081\tLR: 0.075047\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753934\tLR: 0.075047\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754785\tLR: 0.075047\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754298\tLR: 0.075047\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754126\tLR: 0.067543\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754080\tLR: 0.067543\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753718\tLR: 0.067543\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753911\tLR: 0.067543\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753845\tLR: 0.067543\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753965\tLR: 0.060788\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753842\tLR: 0.060788\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753831\tLR: 0.060788\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753729\tLR: 0.060788\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753806\tLR: 0.060788\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753995\tLR: 0.054709\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753923\tLR: 0.054709\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753565\tLR: 0.054709\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753966\tLR: 0.054709\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753642\tLR: 0.054709\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753570\tLR: 0.049239\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753785\tLR: 0.049239\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753343\tLR: 0.049239\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753460\tLR: 0.049239\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753589\tLR: 0.049239\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753832\tLR: 0.044315\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753685\tLR: 0.044315\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753424\tLR: 0.044315\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753736\tLR: 0.044315\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753499\tLR: 0.044315\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753663\tLR: 0.039883\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753520\tLR: 0.039883\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.754205\tLR: 0.039883\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753705\tLR: 0.039883\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753680\tLR: 0.039883\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753554\tLR: 0.035895\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753375\tLR: 0.035895\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753740\tLR: 0.035895\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753262\tLR: 0.035895\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753454\tLR: 0.035895\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753665\tLR: 0.032305\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753620\tLR: 0.032305\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753154\tLR: 0.032305\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753552\tLR: 0.032305\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753374\tLR: 0.032305\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753742\tLR: 0.029075\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753185\tLR: 0.029075\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753202\tLR: 0.029075\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753317\tLR: 0.029075\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753647\tLR: 0.029075\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753685\tLR: 0.026167\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753370\tLR: 0.026167\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753435\tLR: 0.026167\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753452\tLR: 0.026167\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753419\tLR: 0.026167\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753506\tLR: 0.023551\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753539\tLR: 0.023551\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753474\tLR: 0.023551\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753451\tLR: 0.023551\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753141\tLR: 0.023551\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753220\tLR: 0.021196\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753297\tLR: 0.021196\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.752953\tLR: 0.021196\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753209\tLR: 0.021196\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753459\tLR: 0.021196\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753305\tLR: 0.019076\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753308\tLR: 0.019076\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753618\tLR: 0.019076\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753340\tLR: 0.019076\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753443\tLR: 0.019076\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753329\tLR: 0.017168\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753125\tLR: 0.017168\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753143\tLR: 0.017168\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753313\tLR: 0.017168\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753044\tLR: 0.017168\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753478\tLR: 0.015452\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753307\tLR: 0.015452\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753439\tLR: 0.015452\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753386\tLR: 0.015452\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.752977\tLR: 0.015452\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753159\tLR: 0.013906\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753333\tLR: 0.013906\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753121\tLR: 0.013906\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753693\tLR: 0.013906\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753012\tLR: 0.013906\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753208\tLR: 0.012516\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753260\tLR: 0.012516\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753240\tLR: 0.012516\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753048\tLR: 0.012516\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753010\tLR: 0.012516\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753136\tLR: 0.011264\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753268\tLR: 0.011264\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753263\tLR: 0.011264\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753138\tLR: 0.011264\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.752996\tLR: 0.011264\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753087\tLR: 0.010138\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753169\tLR: 0.010138\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753430\tLR: 0.010138\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753128\tLR: 0.010138\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753265\tLR: 0.010138\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753126\tLR: 0.009124\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753492\tLR: 0.009124\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753141\tLR: 0.009124\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.752828\tLR: 0.009124\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753043\tLR: 0.009124\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753714\tLR: 0.008212\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753138\tLR: 0.008212\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.752841\tLR: 0.008212\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.752924\tLR: 0.008212\n",
      "torch.Size([3, 1, 16, 128, 128]) torch.Size([3, 16, 128, 128])\n",
      "Loss: 0.753389\tLR: 0.008212\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(200)):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(sample_batch, sample_spacings)\n",
    "    print(f\"Loss: {output[1]:f}\\tLR: {scheduler.get_last_lr()[0]:f}\")\n",
    "    output[1].backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.grad is None:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m1183892\u001b[0m, \u001b[1;36m197632\u001b[0m, \u001b[1;36m74112\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SwinV23DVAEMIM(sample_config['swin'], sample_config['decoder'], sample_config['mim'])\n",
    "\n",
    "encoder_params = sum(x.numel() for x in model.swin.parameters())\n",
    "decoder_params = sum(x.numel() for x in model.decoder.parameters())\n",
    "sampling_params = sum(x.numel() for x in model.mu_layer.parameters()) + sum(\n",
    "    x.numel() for x in model.logvar_layer.parameters()\n",
    ")\n",
    "encoder_params, decoder_params, sampling_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 1,455,648\n",
      "+---------------------------------------------------------------+------------+\n",
      "|                             Module                            | Parameters |\n",
      "+---------------------------------------------------------------+------------+\n",
      "|                           mask_token                          |     12     |\n",
      "|    swin.embeddings.patch_embeddings.patch_embeddings.weight   |    192     |\n",
      "|     swin.embeddings.patch_embeddings.patch_embeddings.bias    |     12     |\n",
      "|               swin.embeddings.layer_norm.weight               |     12     |\n",
      "|                swin.embeddings.layer_norm.bias                |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mhsa.W_qkv.weight   |    432     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mhsa.W_qkv.bias    |     36     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mhsa.proj.weight    |    144     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mhsa.proj.bias     |     12     |\n",
      "|  swin.encoder.stages.0.blocks.0.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.0.blocks.0.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.0.blocks.0.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.layernorm1.weight   |     12     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.layernorm1.bias    |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mlp.dense1.weight   |    576     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mlp.dense1.bias    |     48     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mlp.dense2.weight   |    576     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mlp.dense2.bias    |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.layernorm2.weight   |     12     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.layernorm2.bias    |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.mhsa.W_qkv.weight   |    432     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mhsa.W_qkv.bias    |     36     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mhsa.proj.weight   |    144     |\n",
      "|     swin.encoder.stages.0.blocks.0.sw_layer.mhsa.proj.bias    |     12     |\n",
      "| swin.encoder.stages.0.blocks.0.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.0.blocks.0.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.0.blocks.0.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.layernorm1.weight   |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.layernorm1.bias    |     12     |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense1.weight   |    576     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense1.bias    |     48     |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense2.weight   |    576     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense2.bias    |     12     |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.layernorm2.weight   |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.layernorm2.bias    |     12     |\n",
      "|     swin.encoder.stages.1.patch_merging.layer_norm.weight     |     96     |\n",
      "|      swin.encoder.stages.1.patch_merging.layer_norm.bias      |     96     |\n",
      "|        swin.encoder.stages.1.patch_merging.proj.weight        |   4,608    |\n",
      "|         swin.encoder.stages.1.patch_merging.proj.bias         |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mhsa.proj.weight    |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mhsa.proj.bias     |     48     |\n",
      "|  swin.encoder.stages.1.blocks.0.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.1.blocks.0.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.1.blocks.0.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.layernorm1.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.layernorm1.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mlp.dense1.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mlp.dense1.bias    |    192     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mlp.dense2.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mlp.dense2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.layernorm2.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mhsa.proj.weight   |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.0.sw_layer.mhsa.proj.bias    |     48     |\n",
      "| swin.encoder.stages.1.blocks.0.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.1.blocks.0.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.1.blocks.0.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.layernorm1.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.layernorm1.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense1.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense1.bias    |    192     |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense2.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense2.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.layernorm2.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mhsa.proj.weight    |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mhsa.proj.bias     |     48     |\n",
      "|  swin.encoder.stages.1.blocks.1.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.1.blocks.1.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.1.blocks.1.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.layernorm1.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.layernorm1.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mlp.dense1.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mlp.dense1.bias    |    192     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mlp.dense2.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mlp.dense2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.layernorm2.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mhsa.proj.weight   |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.1.sw_layer.mhsa.proj.bias    |     48     |\n",
      "| swin.encoder.stages.1.blocks.1.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.1.blocks.1.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.1.blocks.1.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.layernorm1.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.layernorm1.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense1.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense1.bias    |    192     |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense2.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense2.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.layernorm2.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mhsa.proj.weight    |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mhsa.proj.bias     |     48     |\n",
      "|  swin.encoder.stages.1.blocks.2.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.1.blocks.2.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.1.blocks.2.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.layernorm1.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.layernorm1.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mlp.dense1.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mlp.dense1.bias    |    192     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mlp.dense2.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mlp.dense2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.layernorm2.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mhsa.proj.weight   |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.2.sw_layer.mhsa.proj.bias    |     48     |\n",
      "| swin.encoder.stages.1.blocks.2.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.1.blocks.2.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.1.blocks.2.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.layernorm1.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.layernorm1.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense1.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense1.bias    |    192     |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense2.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense2.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.layernorm2.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.layernorm2.bias    |     48     |\n",
      "|     swin.encoder.stages.2.patch_merging.layer_norm.weight     |    384     |\n",
      "|      swin.encoder.stages.2.patch_merging.layer_norm.bias      |    384     |\n",
      "|        swin.encoder.stages.2.patch_merging.proj.weight        |   73,728   |\n",
      "|         swin.encoder.stages.2.patch_merging.proj.bias         |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mhsa.W_qkv.weight   |  110,592   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mhsa.W_qkv.bias    |    576     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mhsa.proj.weight    |   36,864   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mhsa.proj.bias     |    192     |\n",
      "|  swin.encoder.stages.2.blocks.0.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.2.blocks.0.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.2.blocks.0.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.layernorm1.weight   |    192     |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.layernorm1.bias    |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mlp.dense1.weight   |  147,456   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mlp.dense1.bias    |    768     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mlp.dense2.weight   |  147,456   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mlp.dense2.bias    |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.layernorm2.weight   |    192     |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.layernorm2.bias    |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.mhsa.W_qkv.weight   |  110,592   |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mhsa.W_qkv.bias    |    576     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mhsa.proj.weight   |   36,864   |\n",
      "|     swin.encoder.stages.2.blocks.0.sw_layer.mhsa.proj.bias    |    192     |\n",
      "| swin.encoder.stages.2.blocks.0.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.2.blocks.0.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.2.blocks.0.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.layernorm1.weight   |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.layernorm1.bias    |    192     |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense1.weight   |  147,456   |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense1.bias    |    768     |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense2.weight   |  147,456   |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense2.bias    |    192     |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.layernorm2.weight   |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.layernorm2.bias    |    192     |\n",
      "|                     decoder.decoder.weight                    |  196,608   |\n",
      "|                      decoder.decoder.bias                     |   1,024    |\n",
      "|                        mu_layer.weight                        |   36,864   |\n",
      "|                         mu_layer.bias                         |    192     |\n",
      "|                      logvar_layer.weight                      |   36,864   |\n",
      "|                       logvar_layer.bias                       |    192     |\n",
      "+---------------------------------------------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "describe_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = sample_batch.cuda()\n",
    "sample_spacings = sample_spacings.cuda()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e51d1b9fe4742ea9ba45e790b2a0e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 236.236252\tLR: 0.000100\n",
      "Loss: 209.686127\tLR: 0.000100\n",
      "Loss: 228.695587\tLR: 0.000100\n",
      "Loss: 137.420471\tLR: 0.000100\n",
      "Loss: 53.959602\tLR: 0.000100\n",
      "Loss: 27.037453\tLR: 0.000090\n",
      "Loss: 18.891754\tLR: 0.000090\n",
      "Loss: 15.650254\tLR: 0.000090\n",
      "Loss: 13.397776\tLR: 0.000090\n",
      "Loss: 11.778725\tLR: 0.000090\n",
      "Loss: 10.515678\tLR: 0.000081\n",
      "Loss: 9.551185\tLR: 0.000081\n",
      "Loss: 8.842248\tLR: 0.000081\n",
      "Loss: 8.199405\tLR: 0.000081\n",
      "Loss: 7.661325\tLR: 0.000081\n",
      "Loss: 7.186827\tLR: 0.000073\n",
      "Loss: 6.817303\tLR: 0.000073\n",
      "Loss: 6.507324\tLR: 0.000073\n",
      "Loss: 6.185542\tLR: 0.000073\n",
      "Loss: 5.912452\tLR: 0.000073\n",
      "Loss: 5.713943\tLR: 0.000066\n",
      "Loss: 5.474517\tLR: 0.000066\n",
      "Loss: 5.297525\tLR: 0.000066\n",
      "Loss: 5.150573\tLR: 0.000066\n",
      "Loss: 4.981664\tLR: 0.000066\n",
      "Loss: 4.836497\tLR: 0.000059\n",
      "Loss: 4.708388\tLR: 0.000059\n",
      "Loss: 4.542289\tLR: 0.000059\n",
      "Loss: 4.435099\tLR: 0.000059\n",
      "Loss: 4.348423\tLR: 0.000059\n",
      "Loss: 4.285788\tLR: 0.000053\n",
      "Loss: 4.165879\tLR: 0.000053\n",
      "Loss: 4.100969\tLR: 0.000053\n",
      "Loss: 4.028058\tLR: 0.000053\n",
      "Loss: 3.923163\tLR: 0.000053\n",
      "Loss: 3.860737\tLR: 0.000048\n",
      "Loss: 3.795660\tLR: 0.000048\n",
      "Loss: 3.750948\tLR: 0.000048\n",
      "Loss: 3.709826\tLR: 0.000048\n",
      "Loss: 3.689042\tLR: 0.000048\n",
      "Loss: 3.582428\tLR: 0.000043\n",
      "Loss: 3.566294\tLR: 0.000043\n",
      "Loss: 3.490999\tLR: 0.000043\n",
      "Loss: 3.478334\tLR: 0.000043\n",
      "Loss: 3.443775\tLR: 0.000043\n",
      "Loss: 3.382829\tLR: 0.000039\n",
      "Loss: 3.374636\tLR: 0.000039\n",
      "Loss: 3.312087\tLR: 0.000039\n",
      "Loss: 3.285243\tLR: 0.000039\n",
      "Loss: 3.251989\tLR: 0.000039\n",
      "Loss: 3.211434\tLR: 0.000035\n",
      "Loss: 3.206838\tLR: 0.000035\n",
      "Loss: 3.156419\tLR: 0.000035\n",
      "Loss: 3.150970\tLR: 0.000035\n",
      "Loss: 3.121180\tLR: 0.000035\n",
      "Loss: 3.095324\tLR: 0.000031\n",
      "Loss: 3.073972\tLR: 0.000031\n",
      "Loss: 3.059440\tLR: 0.000031\n",
      "Loss: 3.006991\tLR: 0.000031\n",
      "Loss: 3.032623\tLR: 0.000031\n",
      "Loss: 2.971329\tLR: 0.000028\n",
      "Loss: 2.963609\tLR: 0.000028\n",
      "Loss: 2.956972\tLR: 0.000028\n",
      "Loss: 2.955063\tLR: 0.000028\n",
      "Loss: 2.938945\tLR: 0.000028\n",
      "Loss: 2.907053\tLR: 0.000025\n",
      "Loss: 2.901462\tLR: 0.000025\n",
      "Loss: 2.864373\tLR: 0.000025\n",
      "Loss: 2.884242\tLR: 0.000025\n",
      "Loss: 2.830652\tLR: 0.000025\n",
      "Loss: 2.858800\tLR: 0.000023\n",
      "Loss: 2.817538\tLR: 0.000023\n",
      "Loss: 2.799972\tLR: 0.000023\n",
      "Loss: 2.768160\tLR: 0.000023\n",
      "Loss: 2.803670\tLR: 0.000023\n",
      "Loss: 2.778532\tLR: 0.000021\n",
      "Loss: 2.765845\tLR: 0.000021\n",
      "Loss: 2.774324\tLR: 0.000021\n",
      "Loss: 2.737444\tLR: 0.000021\n",
      "Loss: 2.766645\tLR: 0.000021\n",
      "Loss: 2.706521\tLR: 0.000019\n",
      "Loss: 2.711686\tLR: 0.000019\n",
      "Loss: 2.696232\tLR: 0.000019\n",
      "Loss: 2.686254\tLR: 0.000019\n",
      "Loss: 2.668623\tLR: 0.000019\n",
      "Loss: 2.680764\tLR: 0.000017\n",
      "Loss: 2.658039\tLR: 0.000017\n",
      "Loss: 2.673320\tLR: 0.000017\n",
      "Loss: 2.654513\tLR: 0.000017\n",
      "Loss: 2.637508\tLR: 0.000017\n",
      "Loss: 2.661033\tLR: 0.000015\n",
      "Loss: 2.616197\tLR: 0.000015\n",
      "Loss: 2.629002\tLR: 0.000015\n",
      "Loss: 2.608535\tLR: 0.000015\n",
      "Loss: 2.623999\tLR: 0.000015\n",
      "Loss: 2.638899\tLR: 0.000014\n",
      "Loss: 2.623391\tLR: 0.000014\n",
      "Loss: 2.584496\tLR: 0.000014\n",
      "Loss: 2.604817\tLR: 0.000014\n",
      "Loss: 2.574590\tLR: 0.000014\n",
      "Loss: 2.563909\tLR: 0.000012\n",
      "Loss: 2.587591\tLR: 0.000012\n",
      "Loss: 2.588511\tLR: 0.000012\n",
      "Loss: 2.587717\tLR: 0.000012\n",
      "Loss: 2.571204\tLR: 0.000012\n",
      "Loss: 2.555122\tLR: 0.000011\n",
      "Loss: 2.591530\tLR: 0.000011\n",
      "Loss: 2.533947\tLR: 0.000011\n",
      "Loss: 2.554164\tLR: 0.000011\n",
      "Loss: 2.540016\tLR: 0.000011\n",
      "Loss: 2.523275\tLR: 0.000010\n",
      "Loss: 2.556436\tLR: 0.000010\n",
      "Loss: 2.539542\tLR: 0.000010\n",
      "Loss: 2.524057\tLR: 0.000010\n",
      "Loss: 2.552296\tLR: 0.000010\n",
      "Loss: 2.528906\tLR: 0.000009\n",
      "Loss: 2.541144\tLR: 0.000009\n",
      "Loss: 2.518325\tLR: 0.000009\n",
      "Loss: 2.477296\tLR: 0.000009\n",
      "Loss: 2.514399\tLR: 0.000009\n",
      "Loss: 2.500704\tLR: 0.000008\n",
      "Loss: 2.501021\tLR: 0.000008\n",
      "Loss: 2.502025\tLR: 0.000008\n",
      "Loss: 2.493479\tLR: 0.000008\n",
      "Loss: 2.487500\tLR: 0.000008\n",
      "Loss: 2.474373\tLR: 0.000007\n",
      "Loss: 2.476691\tLR: 0.000007\n",
      "Loss: 2.465851\tLR: 0.000007\n",
      "Loss: 2.498227\tLR: 0.000007\n",
      "Loss: 2.474284\tLR: 0.000007\n",
      "Loss: 2.453968\tLR: 0.000006\n",
      "Loss: 2.471606\tLR: 0.000006\n",
      "Loss: 2.467323\tLR: 0.000006\n",
      "Loss: 2.476240\tLR: 0.000006\n",
      "Loss: 2.473200\tLR: 0.000006\n",
      "Loss: 2.445772\tLR: 0.000006\n",
      "Loss: 2.478038\tLR: 0.000006\n",
      "Loss: 2.475778\tLR: 0.000006\n",
      "Loss: 2.464940\tLR: 0.000006\n",
      "Loss: 2.475509\tLR: 0.000006\n",
      "Loss: 2.442849\tLR: 0.000005\n",
      "Loss: 2.445904\tLR: 0.000005\n",
      "Loss: 2.460748\tLR: 0.000005\n",
      "Loss: 2.451113\tLR: 0.000005\n",
      "Loss: 2.462426\tLR: 0.000005\n",
      "Loss: 2.444238\tLR: 0.000005\n",
      "Loss: 2.456285\tLR: 0.000005\n",
      "Loss: 2.437168\tLR: 0.000005\n",
      "Loss: 2.435200\tLR: 0.000005\n",
      "Loss: 2.453028\tLR: 0.000005\n",
      "Loss: 2.433527\tLR: 0.000004\n",
      "Loss: 2.436052\tLR: 0.000004\n",
      "Loss: 2.434978\tLR: 0.000004\n",
      "Loss: 2.437025\tLR: 0.000004\n",
      "Loss: 2.415954\tLR: 0.000004\n",
      "Loss: 2.412647\tLR: 0.000004\n",
      "Loss: 2.441822\tLR: 0.000004\n",
      "Loss: 2.433858\tLR: 0.000004\n",
      "Loss: 2.401469\tLR: 0.000004\n",
      "Loss: 2.433157\tLR: 0.000004\n",
      "Loss: 2.416196\tLR: 0.000003\n",
      "Loss: 2.424877\tLR: 0.000003\n",
      "Loss: 2.403023\tLR: 0.000003\n",
      "Loss: 2.411084\tLR: 0.000003\n",
      "Loss: 2.411903\tLR: 0.000003\n",
      "Loss: 2.421289\tLR: 0.000003\n",
      "Loss: 2.398142\tLR: 0.000003\n",
      "Loss: 2.387163\tLR: 0.000003\n",
      "Loss: 2.416895\tLR: 0.000003\n",
      "Loss: 2.420624\tLR: 0.000003\n",
      "Loss: 2.414285\tLR: 0.000003\n",
      "Loss: 2.403826\tLR: 0.000003\n",
      "Loss: 2.414363\tLR: 0.000003\n",
      "Loss: 2.406610\tLR: 0.000003\n",
      "Loss: 2.425284\tLR: 0.000003\n",
      "Loss: 2.393809\tLR: 0.000003\n",
      "Loss: 2.414559\tLR: 0.000003\n",
      "Loss: 2.400356\tLR: 0.000003\n",
      "Loss: 2.410529\tLR: 0.000003\n",
      "Loss: 2.394456\tLR: 0.000003\n",
      "Loss: 2.383519\tLR: 0.000002\n",
      "Loss: 2.375899\tLR: 0.000002\n",
      "Loss: 2.389275\tLR: 0.000002\n",
      "Loss: 2.388064\tLR: 0.000002\n",
      "Loss: 2.419722\tLR: 0.000002\n",
      "Loss: 2.402449\tLR: 0.000002\n",
      "Loss: 2.388027\tLR: 0.000002\n",
      "Loss: 2.419906\tLR: 0.000002\n",
      "Loss: 2.384717\tLR: 0.000002\n",
      "Loss: 2.382853\tLR: 0.000002\n",
      "Loss: 2.413897\tLR: 0.000002\n",
      "Loss: 2.385797\tLR: 0.000002\n",
      "Loss: 2.386430\tLR: 0.000002\n",
      "Loss: 2.408625\tLR: 0.000002\n",
      "Loss: 2.378230\tLR: 0.000002\n",
      "Loss: 2.389242\tLR: 0.000002\n",
      "Loss: 2.381745\tLR: 0.000002\n",
      "Loss: 2.401704\tLR: 0.000002\n",
      "Loss: 2.399031\tLR: 0.000002\n",
      "Loss: 2.382019\tLR: 0.000002\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(200)):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(sample_batch, sample_spacings)\n",
    "    print(f\"Loss: {output[1]:f}\\tLR: {scheduler.get_last_lr()[0]:f}\")\n",
    "    # print(output[-1])\n",
    "    output[1].backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.grad is None:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough work"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "coords_h = torch.arange(4)\n",
    "coords_w = torch.arange(4)\n",
    "coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing=\"ij\"))\n",
    "coords_flatten = torch.flatten(coords, 1)\n",
    "relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "relative_coords[:, :, 0] += 4 - 1\n",
    "relative_coords[:, :, 1] += 4 - 1\n",
    "relative_coords[:, :, 0] *= 2 * 4 - 1\n",
    "relative_position_index = relative_coords.sum(-1)\n",
    "\n",
    "relative_position_index.min(), relative_position_index.max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "window_size = (4, 4, 4)\n",
    "relative_limits = (7, 7, 7)\n",
    "\n",
    "coords = get_coords_grid(window_size)\n",
    "coords_flatten = rearrange(coords, \"three_dimensional d h w -> three_dimensional (d h w)\", three_dimensional=3)\n",
    "relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "relative_coords[:, :, 0] += window_size[0] - 1\n",
    "relative_coords[:, :, 1] += window_size[1] - 1\n",
    "relative_coords[:, :, 2] += window_size[2] - 1\n",
    "relative_position_index: torch.Tensor = (\n",
    "    relative_coords[:, :, 0] * relative_limits[1] * relative_limits[2]\n",
    "    + relative_coords[:, :, 1] * relative_limits[2]\n",
    "    + relative_coords[:, :, 2]\n",
    ")\n",
    "\n",
    "relative_position_index.min(), relative_position_index.max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "window_size = (2, 2, 2)\n",
    "relative_limits = (2 * window_size[0] - 1, 2 * window_size[1] - 1, 2 * window_size[2] - 1)\n",
    "\n",
    "relative_coords_table = get_coords_grid(relative_limits)\n",
    "relative_coords_table[0] -= window_size[0] - 1\n",
    "relative_coords_table[1] -= window_size[1] - 1\n",
    "relative_coords_table[2] -= window_size[2] - 1\n",
    "relative_coords_table = relative_coords_table.permute(1, 2, 3, 0).contiguous()\n",
    "relative_coords_table[0, 2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
