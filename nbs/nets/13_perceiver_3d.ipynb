{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp nets/perceiver_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import torch\n",
    "from einops import rearrange, repeat\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from torch import nn\n",
    "\n",
    "from vision_architectures.layers.attention import Attention1DWithMLP, Attention1DWithMLPConfig\n",
    "from vision_architectures.layers.embeddings import AbsolutePositionEmbeddings3D\n",
    "from vision_architectures.utils.activation_checkpointing import ActivationCheckpointing\n",
    "from vision_architectures.utils.custom_base_model import CustomBaseModel, model_validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Perceiver3DChannelMappingConfig(CustomBaseModel):\n",
    "    in_channels: int | set[int]\n",
    "    out_channels: int\n",
    "\n",
    "\n",
    "class Perceiver3DEncoderEncodeConfig(Attention1DWithMLPConfig):\n",
    "    dim: int\n",
    "    num_latent_tokens: int\n",
    "    num_layers: int\n",
    "\n",
    "\n",
    "class Perceiver3DEncoderProcessConfig(Attention1DWithMLPConfig):\n",
    "    dim: int\n",
    "    num_layers: int\n",
    "\n",
    "\n",
    "class Perceiver3DEncoderConfig(CustomBaseModel):\n",
    "    encode: Perceiver3DEncoderEncodeConfig\n",
    "    process: Perceiver3DEncoderProcessConfig\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self.encode.dim\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate(self):\n",
    "        super().validate()\n",
    "        assert self.encode.dim == self.process.dim, \"encode and process dims must be equal\"\n",
    "        return self\n",
    "\n",
    "\n",
    "class Perceiver3DDecoderConfig(Attention1DWithMLPConfig):\n",
    "    dim: int\n",
    "    num_layers: int\n",
    "    out_channels: int\n",
    "\n",
    "\n",
    "class Perceiver3DConfig(Perceiver3DEncoderConfig):\n",
    "    decode: Perceiver3DDecoderConfig\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate(self):\n",
    "        super().validate()\n",
    "        assert self.encode.dim == self.decode.dim, \"encode and decode dims must be equal\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;36m384\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_config = Perceiver3DConfig.model_validate(\n",
    "    {\n",
    "        \"encode\": {\n",
    "            \"dim\": 384,\n",
    "            \"num_latent_tokens\": 1024,\n",
    "            \"num_layers\": 1,\n",
    "            \"num_heads\": 16,\n",
    "        },\n",
    "        \"process\": {\n",
    "            \"dim\": 384,\n",
    "            \"num_layers\": 3,\n",
    "            \"num_heads\": 16,\n",
    "        },\n",
    "        \"decode\": {\n",
    "            \"dim\": 384,\n",
    "            \"out_channels\": 1,\n",
    "            \"num_layers\": 3,\n",
    "            \"num_heads\": 16,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "test_config.dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def unfold_with_rollover_1d(x: torch.Tensor, window_size: int | None, stride: int | None):\n",
    "    # x: (b, T, dim)\n",
    "    if window_size is None or stride is None:\n",
    "        return x.unsqueeze(0)\n",
    "    total_len = x.shape[1]\n",
    "    num_windows = (total_len + stride - 1) // stride  # Number of windows needed\n",
    "    pad_len = max(0, window_size + (num_windows - 1) * stride - total_len)  # How many elements are missing\n",
    "    if pad_len > 0:\n",
    "        x = torch.cat([x, x[:, :pad_len]], dim=1)  # Rollover padding\n",
    "    x = x.unfold(1, window_size, stride)\n",
    "    x = rearrange(x, \"b num_windows dim window_size -> num_windows b window_size dim\")\n",
    "    # (num_windows, b, window_size, dim)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,\n",
       "          \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n",
       "          \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\n",
       "\n",
       "        \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m,\n",
       "          \u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m,\n",
       "          \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4).reshape(1, 4, 1)\n",
    "unfolded = unfold_with_rollover_1d(x, 3, 2)\n",
    "unfolded.shape, unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def unfold_with_rollover_3d_with_mask(\n",
    "    x: torch.Tensor, window_size: tuple[int, int, int] | None, stride: tuple[int, int, int] | None\n",
    "):\n",
    "    if window_size is None or stride is None:\n",
    "        return x.unsqueeze(0)\n",
    "\n",
    "    b, c, d, h, w = x.shape\n",
    "    w_d, w_h, w_w = window_size\n",
    "    s_d, s_h, s_w = stride\n",
    "\n",
    "    # Calculate number of windows and required padding\n",
    "    n_d = (d + s_d - 1) // s_d\n",
    "    n_h = (h + s_h - 1) // s_h\n",
    "    n_w = (w + s_w - 1) // s_w\n",
    "\n",
    "    # Calculate padding with rollover\n",
    "    pad_d = max(0, w_d + (n_d - 1) * s_d - d)\n",
    "    pad_h = max(0, w_h + (n_h - 1) * s_h - h)\n",
    "    pad_w = max(0, w_w + (n_w - 1) * s_w - w)\n",
    "\n",
    "    # Apply rollover padding efficiently\n",
    "    if pad_d > 0:\n",
    "        x = torch.cat([x, x[:, :, :pad_d]], dim=2)\n",
    "    if pad_h > 0:\n",
    "        x = torch.cat([x, x[:, :, :, :pad_h]], dim=3)\n",
    "    if pad_w > 0:\n",
    "        x = torch.cat([x, x[:, :, :, :, :pad_w]], dim=4)\n",
    "\n",
    "    # Extract patches using stride tricks\n",
    "    # This approach avoids creating intermediate tensors\n",
    "    patches = x.unfold(2, w_d, s_d).unfold(3, w_h, s_h).unfold(4, w_w, s_w)\n",
    "\n",
    "    # Rearrange dimensions using einops for clarity and efficiency\n",
    "    patches = rearrange(\n",
    "        patches, \"b c d_windows h_windows w_windows w_d w_h w_w -> (d_windows h_windows w_windows) b c w_d w_h w_w\"\n",
    "    )\n",
    "\n",
    "    # Padded shape\n",
    "    padded_d, padded_h, padded_w = x.shape[2], x.shape[3], x.shape[4]\n",
    "\n",
    "    # Generate positional information for each fold\n",
    "    # Create meshgrid for all window positions\n",
    "    d_indices = torch.arange(n_d, device=x.device)\n",
    "    h_indices = torch.arange(n_h, device=x.device)\n",
    "    w_indices = torch.arange(n_w, device=x.device)\n",
    "\n",
    "    # Calculate starting indices for each window\n",
    "    d_starts = d_indices * s_d\n",
    "    h_starts = h_indices * s_h\n",
    "    w_starts = w_indices * s_w\n",
    "\n",
    "    # Generate all possible window starting positions\n",
    "    d_pos, h_pos, w_pos = torch.meshgrid(d_starts, h_starts, w_starts, indexing=\"ij\")\n",
    "    positions = torch.stack([d_pos, h_pos, w_pos], dim=-1).reshape(-1, 3)\n",
    "\n",
    "    # Generate usage count mask\n",
    "    usage_mask = torch.zeros(padded_d, padded_h, padded_w, device=x.device)\n",
    "\n",
    "    # For each position, increment the count for all pixels in that window\n",
    "    for pos in positions:\n",
    "        pos_d, pos_h, pos_w = pos\n",
    "        # Handle potential out-of-bounds for the last window\n",
    "        end_d = min(pos_d + w_d, padded_d)\n",
    "        end_h = min(pos_h + w_h, padded_h)\n",
    "        end_w = min(pos_w + w_w, padded_w)\n",
    "\n",
    "        usage_mask[pos_d:end_d, pos_h:end_h, pos_w:end_w] += 1\n",
    "\n",
    "    # Crop usage_mask back to original dimensions (without padding)\n",
    "    usage_mask = usage_mask[:d, :h, :w]\n",
    "\n",
    "    # Repeat usage mask for batch and channel dimensions\n",
    "    usage_mask = usage_mask.expand(b, c, d, h, w)\n",
    "\n",
    "    return patches, positions, usage_mask\n",
    "\n",
    "\n",
    "def fold_back_3d(\n",
    "    patches: torch.Tensor,\n",
    "    positions: torch.Tensor,\n",
    "    usage_mask: torch.Tensor,\n",
    "    output_shape: tuple,\n",
    "    window_size: tuple[int, int, int],\n",
    "    aggregation_mode: str = \"mean\",\n",
    "):\n",
    "    b, c, d, h, w = output_shape\n",
    "    w_d, w_h, w_w = window_size\n",
    "\n",
    "    # Initialize output tensor\n",
    "    output = torch.zeros(output_shape, dtype=patches.dtype, device=patches.device)\n",
    "\n",
    "    # Handle case where we want sum instead of mean\n",
    "    if aggregation_mode == \"sum\":\n",
    "        usage_mask = torch.ones_like(usage_mask)\n",
    "\n",
    "    # Fold each patch back to its position\n",
    "    for i, pos in enumerate(positions):\n",
    "        pos_d, pos_h, pos_w = pos\n",
    "        # Get the patch\n",
    "        patch = patches[i]\n",
    "\n",
    "        # Handle window dimensions (might be smaller at edges)\n",
    "        valid_w_d = min(w_d, d - pos_d) if pos_d < d else 0\n",
    "        valid_w_h = min(w_h, h - pos_h) if pos_h < h else 0\n",
    "        valid_w_w = min(w_w, w - pos_w) if pos_w < w else 0\n",
    "\n",
    "        if valid_w_d <= 0 or valid_w_h <= 0 or valid_w_w <= 0:\n",
    "            continue\n",
    "\n",
    "        # Only add the valid portion of the patch\n",
    "        output[:, :, pos_d : pos_d + valid_w_d, pos_h : pos_h + valid_w_h, pos_w : pos_w + valid_w_w] += patch[\n",
    "            :, :, :valid_w_d, :valid_w_h, :valid_w_w\n",
    "        ]\n",
    "\n",
    "    # Average according to usage count\n",
    "    if aggregation_mode == \"mean\":\n",
    "        # Avoid division by zero\n",
    "        mask = (usage_mask > 0).float()\n",
    "        output = output / (usage_mask + (1 - mask))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Perceiver3DChannelMapping(nn.Module):\n",
    "    def __init__(self, config: Perceiver3DChannelMappingConfig = {}, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = Perceiver3DChannelMappingConfig.model_validate(config | kwargs)\n",
    "\n",
    "        self.in_channels = self.config.in_channels\n",
    "        self.out_channels = self.config.out_channels\n",
    "\n",
    "        if isinstance(self.in_channels, int):\n",
    "            self.in_channels = {self.in_channels}\n",
    "\n",
    "        self.mappers = nn.ModuleDict()\n",
    "        for in_channels in self.in_channels:\n",
    "            self.mappers[str(in_channels)] = nn.Conv3d(in_channels, self.out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (b, in_channels, z, y, x)\n",
    "\n",
    "        in_channels = x.shape[1]\n",
    "        if in_channels not in self.in_channels:\n",
    "            raise ValueError(f\"Input channels {in_channels} not in {self.in_channels}\")\n",
    "\n",
    "        mapper = self.mappers[str(in_channels)]\n",
    "        x = mapper(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 4, 4, 4])\n",
      "torch.Size([1, 24, 4, 4, 4])\n",
      "torch.Size([1, 24, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "test = Perceiver3DChannelMapping(in_channels={12, 24, 48}, out_channels=24)\n",
    "for in_channels in [12, 24, 48]:\n",
    "    x = torch.randn(1, in_channels, 4, 4, 4)\n",
    "    print(test(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Perceiver3DEncoderEncode(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Perceiver3DEncoderEncodeConfig | Perceiver3DEncoderConfig = {},\n",
    "        channel_mapping: Perceiver3DChannelMapping | None = None,\n",
    "        checkpointing_level: int = 0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if isinstance(config, Perceiver3DEncoderConfig):\n",
    "            config = config.encode\n",
    "        if \"encode\" in config:\n",
    "            config = config[\"encode\"]\n",
    "\n",
    "        self.config = Perceiver3DEncoderEncodeConfig.model_validate(config | kwargs)\n",
    "\n",
    "        dim = self.config.dim\n",
    "        num_latent_tokens = self.config.num_latent_tokens\n",
    "        num_layers = self.config.num_layers\n",
    "\n",
    "        self.latent_tokens = nn.Parameter(torch.empty(num_latent_tokens, dim), requires_grad=True)\n",
    "        nn.init.xavier_uniform_(self.latent_tokens)\n",
    "\n",
    "        self.channel_mapping = channel_mapping\n",
    "\n",
    "        self.cross_attention = nn.ModuleList(\n",
    "            [\n",
    "                Attention1DWithMLP(self.config.model_dump(), checkpointing_level=checkpointing_level)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.checkpointing_level1 = ActivationCheckpointing(1, checkpointing_level)\n",
    "        self.checkpointing_level4 = ActivationCheckpointing(4, checkpointing_level)\n",
    "\n",
    "    def _forward(\n",
    "        self,\n",
    "        x: torch.Tensor | list[torch.Tensor],\n",
    "        sliding_window: int | None = None,\n",
    "        sliding_stride: int | None = None,\n",
    "        return_all: bool = False,\n",
    "    ) -> torch.Tensor | dict[str, torch.Tensor]:\n",
    "        # x: [(b, in_channels, z, y, x), ...]\n",
    "\n",
    "        # Prepare keys and values\n",
    "        def prepare_keys_values(x: torch.Tensor | list[torch.Tensor]):\n",
    "            if not isinstance(x, list):\n",
    "                x = [x]\n",
    "            # x is now a list of tensors\n",
    "            if self.channel_mapping is None:\n",
    "                kv = x\n",
    "            else:\n",
    "                kv = []\n",
    "                for i in range(len(x)):\n",
    "                    mapped = self.channel_mapping(x[i])  # modifying in-place leads to errors when checkpointing\n",
    "                    mapped = rearrange(mapped, \"b d z y x -> b (z y x) d\")\n",
    "                    kv.append(mapped)\n",
    "            kv = torch.cat(kv, dim=1)\n",
    "            return kv\n",
    "\n",
    "        kv = self.checkpointing_level1(prepare_keys_values, x)\n",
    "        # (b, num_kv_tokens, dim)\n",
    "\n",
    "        # Prepare queries\n",
    "        b = kv.shape[0]\n",
    "        q = repeat(self.latent_tokens, \"t d -> b t d\", b=b)\n",
    "        # (b, num_latent_tokens, dim)\n",
    "\n",
    "        # Prepare sliding window\n",
    "        kv_windows = unfold_with_rollover_1d(kv, sliding_window, sliding_stride)\n",
    "        # (num_windows, b, window_size, dim)\n",
    "\n",
    "        # Perform attention\n",
    "        embeddings = []\n",
    "        for cross_attention_layer in self.cross_attention:\n",
    "            embedding = torch.zeros_like(q)\n",
    "            for kv_window in kv_windows:\n",
    "                embedding_window = cross_attention_layer(q, kv_window, kv_window)\n",
    "                embedding = embedding + embedding_window\n",
    "            q = embedding  # To pass to the next layer\n",
    "            embeddings.append(embedding)\n",
    "        # (b, num_latent_tokens, dim)\n",
    "\n",
    "        return_value = embeddings[-1]\n",
    "        if return_all:\n",
    "            return_value = {\n",
    "                \"embeddings\": return_value,\n",
    "                \"all_embeddings\": embeddings,\n",
    "            }\n",
    "        return return_value\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor | list[torch.Tensor],\n",
    "        sliding_window: int | None = None,  # Sliding window may be beneficial during inference time\n",
    "        sliding_stride: int | None = None,\n",
    "        return_all: bool = False,\n",
    "    ):\n",
    "        return self.checkpointing_level4(self._forward, x, sliding_window, sliding_stride, return_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mPerceiver3DEncoderEncode\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mchannel_mapping\u001b[1m)\u001b[0m: \u001b[1;35mPerceiver3DChannelMapping\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmappers\u001b[1m)\u001b[0m: \u001b[1;35mModuleDict\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m384\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mcross_attention\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAttention1DWithMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mattn\u001b[1m)\u001b[0m: \u001b[1;35mAttention1D\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mAttention1DMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1536\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1536\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1024\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 s, sys: 859 ms, total: 2.07 s\n",
      "Wall time: 71 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test = Perceiver3DEncoderEncode(test_config, Perceiver3DChannelMapping(in_channels=512, out_channels=384))\n",
    "display(test)\n",
    "o = test(torch.randn(2, 512, 4, 4, 4))\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1024\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.63 s, sys: 1.01 s, total: 4.64 s\n",
      "Wall time: 76.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test.eval()\n",
    "with torch.no_grad():\n",
    "    o = test(torch.randn(2, 512, 4, 4, 4), sliding_window=8, sliding_stride=8)\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Perceiver3DEncoderProcess(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Perceiver3DEncoderProcessConfig | Perceiver3DEncoderConfig = {},\n",
    "        checkpointing_level: int = 0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if isinstance(config, Perceiver3DEncoderConfig):\n",
    "            config = config.process\n",
    "        if \"process\" in config:\n",
    "            config = config[\"process\"]\n",
    "\n",
    "        self.config = Perceiver3DEncoderProcessConfig.model_validate(config | kwargs)\n",
    "\n",
    "        num_layers = self.config.num_layers\n",
    "\n",
    "        self.self_attention = nn.ModuleList(\n",
    "            [\n",
    "                Attention1DWithMLP(self.config.model_dump(), checkpointing_level=checkpointing_level)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.checkpointing_level4 = ActivationCheckpointing(4, checkpointing_level)\n",
    "\n",
    "    def _forward(self, qkv, return_all: bool = False) -> torch.Tensor | dict[str, torch.Tensor]:\n",
    "        # qkv: (b, num_tokens, dim)\n",
    "\n",
    "        embeddings = []\n",
    "        for self_attention_layer in self.self_attention:\n",
    "            embedding = self_attention_layer(qkv, qkv, qkv)\n",
    "            qkv = embedding  # To pass to the next layer\n",
    "            embeddings.append(embedding)\n",
    "        # (b, num_tokens, dim)\n",
    "\n",
    "        return_value = embeddings[-1]\n",
    "        if return_all:\n",
    "            return_value = {\n",
    "                \"embeddings\": return_value,\n",
    "                \"all_embeddings\": embeddings,\n",
    "            }\n",
    "\n",
    "        return return_value\n",
    "\n",
    "    def forward(self, q: torch.Tensor, return_all: bool = False):\n",
    "        return self.checkpointing_level4(self._forward, q, return_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mPerceiver3DEncoderProcess\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mself_attention\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m2\u001b[0m x \u001b[1;35mAttention1DWithMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mattn\u001b[1m)\u001b[0m: \u001b[1;35mAttention1D\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1024\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mAttention1DMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4096\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m4096\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1024\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m1024\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = Perceiver3DEncoderProcess(dim=1024, num_heads=16, num_layers=2)\n",
    "display(test)\n",
    "o = test(torch.randn(2, 512, 1024))\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Perceiver3DEncoder(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Perceiver3DEncoderConfig = {},\n",
    "        channel_mapping: Perceiver3DChannelMapping | None = None,\n",
    "        checkpointing_level: int = 0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = Perceiver3DEncoderConfig.model_validate(config | kwargs)\n",
    "\n",
    "        self.encode = Perceiver3DEncoderEncode(config.encode, channel_mapping, checkpointing_level)\n",
    "        self.process = Perceiver3DEncoderProcess(config.process, checkpointing_level)\n",
    "\n",
    "        self.checkpointing_level5 = ActivationCheckpointing(5, checkpointing_level)\n",
    "\n",
    "    def _forward(\n",
    "        self,\n",
    "        x,\n",
    "        sliding_window: int | None = None,\n",
    "        sliding_stride: int | None = None,\n",
    "        return_all: bool = False,\n",
    "    ) -> torch.Tensor | dict[str, torch.Tensor]:\n",
    "        # x: (b, in_channels, z, y, x)\n",
    "\n",
    "        return_value = {}\n",
    "\n",
    "        encode_embeddings = self.encode(x, sliding_window, sliding_stride, return_all=True)[\"all_embeddings\"]\n",
    "        return_value[\"encode_embeddings\"] = encode_embeddings\n",
    "        embeddings = encode_embeddings[-1]\n",
    "        # (b, num_tokens, dim)\n",
    "\n",
    "        process_embeddings = self.process(embeddings, return_all=True)[\"all_embeddings\"]\n",
    "        return_value[\"process_embeddings\"] = process_embeddings\n",
    "        embeddings = process_embeddings[-1]\n",
    "\n",
    "        return_value[\"embeddings\"] = embeddings\n",
    "\n",
    "        if not return_all:\n",
    "            return_value = embeddings\n",
    "\n",
    "        return return_value\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        sliding_window: int | None = None,\n",
    "        sliding_stride: int | None = None,\n",
    "        return_all: bool = False,\n",
    "    ):\n",
    "        return self.checkpointing_level5(self._forward, x, sliding_window, sliding_stride, return_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mPerceiver3DEncoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mencode\u001b[1m)\u001b[0m: \u001b[1;35mPerceiver3DEncoderEncode\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mchannel_mapping\u001b[1m)\u001b[0m: \u001b[1;35mPerceiver3DChannelMapping\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmappers\u001b[1m)\u001b[0m: \u001b[1;35mModuleDict\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m384\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m, \u001b[1;36m384\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mcross_attention\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAttention1DWithMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mattn\u001b[1m)\u001b[0m: \u001b[1;35mAttention1D\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mAttention1DMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1536\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1536\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mprocess\u001b[1m)\u001b[0m: \u001b[1;35mPerceiver3DEncoderProcess\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mself_attention\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m3\u001b[0m x \u001b[1;35mAttention1DWithMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mattn\u001b[1m)\u001b[0m: \u001b[1;35mAttention1D\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mAttention1DMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1536\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1536\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1024\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = Perceiver3DEncoder(test_config, Perceiver3DChannelMapping(in_channels={512, 256}, out_channels=384))\n",
    "display(test)\n",
    "o = test(torch.randn(2, 256, 4, 4, 4))\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Perceiver3DDecoder(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Perceiver3DDecoderConfig | Perceiver3DConfig = {},\n",
    "        position_embeddings: AbsolutePositionEmbeddings3D = None,\n",
    "        checkpointing_level: int = 0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if isinstance(config, Perceiver3DConfig):\n",
    "            config = config.decode\n",
    "        if \"decode\" in config:\n",
    "            config = config[\"decode\"]\n",
    "\n",
    "        self.config = Perceiver3DDecoderConfig.model_validate(config | kwargs)\n",
    "\n",
    "        dim = self.config.dim\n",
    "        num_layers = self.config.num_layers\n",
    "\n",
    "        self.empty_token = nn.Parameter(torch.randn(dim, 1) * 0.02, requires_grad=True)\n",
    "        # Initialized with gaussian for robust training stability\n",
    "\n",
    "        self.position_embeddings = position_embeddings\n",
    "\n",
    "        self.cross_attention = nn.ModuleList(\n",
    "            [\n",
    "                Attention1DWithMLP(config.model_dump(), checkpointing_level=checkpointing_level)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.channel_mapping = Perceiver3DChannelMapping(in_channels=dim, out_channels=self.config.out_channels)\n",
    "\n",
    "        self.checkpointing_level4 = ActivationCheckpointing(4, checkpointing_level)\n",
    "\n",
    "    #     # Prepare sliding windows\n",
    "    #     q_windows, positions, usage_mask = unfold_with_rollover_3d_with_mask(q, sliding_window, sliding_stride)\n",
    "    #     # (num_windows, b, dim, window_size_z, window_size_y, window_size_x)\n",
    "\n",
    "    #     # Perform attention\n",
    "    #     outputs = []\n",
    "    #     for cross_attention_layer in self.cross_attention:\n",
    "    #         output = torch.zeros_like(q)\n",
    "    #         for q_window in q_windows:\n",
    "    #             output_window = cross_attention_layer(q_window, kv, kv)\n",
    "    #             output = output + output_window\n",
    "    #     q = rearrange(q, \"b d z y x -> b (z y x) d\")\n",
    "    #     # (b, num_output_tokens, dim)\n",
    "    #     outputs = [q]\n",
    "    #     for cross_attention_layer in self.cross_attention:\n",
    "    #         q = outputs[-1]\n",
    "    #         outputs.append(cross_attention_layer(q, kv, kv))\n",
    "    #     # (b, num_output_tokens, dim)\n",
    "\n",
    "    #     output = outputs[-1]\n",
    "    #     output = rearrange(\n",
    "    #         output,\n",
    "    #         \"b (z y x) d -> b d z y x\",\n",
    "    #         z=out_shape[0],\n",
    "    #         y=out_shape[1],\n",
    "    #         x=out_shape[2],\n",
    "    #     )\n",
    "    #     # (b, dim, z, y, x)\n",
    "\n",
    "    #     output = self.channel_mapping(output)\n",
    "    #     # (b, out_channels, z, y, x)\n",
    "\n",
    "    #     return_value = output\n",
    "    #     if return_all:\n",
    "    #         return_value = {\n",
    "    #             \"output\": output,\n",
    "    #             \"all_outputs\": outputs,\n",
    "    #         }\n",
    "\n",
    "    #     return return_value\n",
    "\n",
    "    def _forward(\n",
    "        self,\n",
    "        kv,\n",
    "        out_shape: tuple[int, int, int],\n",
    "        sliding_window: tuple[int, int, int] | None = None,\n",
    "        sliding_stride: tuple[int, int, int] | None = None,\n",
    "        return_all: bool = False,\n",
    "    ) -> torch.Tensor | dict[str, torch.Tensor]:\n",
    "        # kv: (b, num_tokens, dim)\n",
    "\n",
    "        b = kv.shape[0]\n",
    "\n",
    "        q = repeat(\n",
    "            self.empty_token,\n",
    "            \"d 1 -> b d z y x\",\n",
    "            b=b,\n",
    "            z=out_shape[0],\n",
    "            y=out_shape[1],\n",
    "            x=out_shape[2],\n",
    "        )\n",
    "        # (b, dim, z, y, x)\n",
    "\n",
    "        if self.position_embeddings is not None:\n",
    "            q = q + self.position_embeddings(batch_size=b, grid_size=out_shape, device=q.device)\n",
    "\n",
    "        # Conditional execution based on sliding window parameters\n",
    "        if sliding_window is not None and sliding_stride is not None:\n",
    "            # Apply sliding window processing\n",
    "            q_windows, positions, usage_mask = unfold_with_rollover_3d_with_mask(q, sliding_window, sliding_stride)\n",
    "            # q_windows: (num_windows, b, dim, window_size_z, window_size_y, window_size_x)\n",
    "\n",
    "            # Process each window with attention\n",
    "            num_windows = q_windows.shape[0]\n",
    "            window_shape = q_windows.shape[-3:]  # (window_size_z, window_size_y, window_size_x)\n",
    "\n",
    "            # Initialize output tensor for each layer's output\n",
    "            outputs = []\n",
    "            current_windows = q_windows\n",
    "\n",
    "            # Apply cross-attention to each window sequentially through all layers\n",
    "            for layer_idx, cross_attention_layer in enumerate(self.cross_attention):\n",
    "                processed_windows = torch.zeros_like(current_windows)\n",
    "\n",
    "                for window_idx in range(num_windows):\n",
    "                    # Extract current window\n",
    "                    window = current_windows[window_idx]  # (b, dim, w_z, w_y, w_x)\n",
    "\n",
    "                    # Reshape for attention operation\n",
    "                    flat_window = rearrange(window, \"b d z y x -> b (z y x) d\")\n",
    "\n",
    "                    # Apply cross-attention\n",
    "                    attended_window = cross_attention_layer(flat_window, kv, kv)\n",
    "\n",
    "                    # Reshape back to 3D\n",
    "                    processed_window = rearrange(\n",
    "                        attended_window,\n",
    "                        \"b (z y x) d -> b d z y x\",\n",
    "                        z=window_shape[0],\n",
    "                        y=window_shape[1],\n",
    "                        x=window_shape[2],\n",
    "                    )\n",
    "\n",
    "                    # Store processed window\n",
    "                    processed_windows[window_idx] = processed_window\n",
    "\n",
    "                # Update current windows for next layer\n",
    "                current_windows = processed_windows\n",
    "\n",
    "                # Fold windows back to full volume for this layer's output\n",
    "                folded_output = fold_back_3d(\n",
    "                    processed_windows, positions, usage_mask, (b, q.shape[1], out_shape[0], out_shape[1], out_shape[2])\n",
    "                )\n",
    "\n",
    "                # Store layer output for return_all\n",
    "                flat_output = rearrange(\n",
    "                    folded_output, \"b d z y x -> b (z y x) d\", z=out_shape[0], y=out_shape[1], x=out_shape[2]\n",
    "                )\n",
    "                outputs.append(flat_output)\n",
    "\n",
    "            # Final output is from the last layer\n",
    "            output = folded_output\n",
    "\n",
    "        else:\n",
    "            # Original processing without sliding windows\n",
    "            q = rearrange(q, \"b d z y x -> b (z y x) d\")\n",
    "            # (b, num_output_tokens, dim)\n",
    "            outputs = [q]\n",
    "            for cross_attention_layer in self.cross_attention:\n",
    "                q = outputs[-1]\n",
    "                outputs.append(cross_attention_layer(q, kv, kv))\n",
    "            # (b, num_output_tokens, dim)\n",
    "\n",
    "            output = outputs[-1]\n",
    "            output = rearrange(\n",
    "                output,\n",
    "                \"b (z y x) d -> b d z y x\",\n",
    "                z=out_shape[0],\n",
    "                y=out_shape[1],\n",
    "                x=out_shape[2],\n",
    "            )\n",
    "            # (b, dim, z, y, x)\n",
    "\n",
    "        # Apply channel mapping to get final output\n",
    "        output = self.channel_mapping(output)\n",
    "        # (b, out_channels, z, y, x)\n",
    "\n",
    "        return_value = output\n",
    "        if return_all:\n",
    "            return_value = {\n",
    "                \"output\": output,\n",
    "                \"all_outputs\": outputs,\n",
    "            }\n",
    "\n",
    "        return return_value\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        kv: torch.Tensor,\n",
    "        out_shape: tuple[int, int, int],\n",
    "        return_all: bool = False,\n",
    "    ):\n",
    "        return self.checkpointing_level4(self._forward, kv, out_shape, return_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mPerceiver3DDecoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mposition_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mAbsolutePositionEmbeddings3D\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mcross_attention\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m3\u001b[0m x \u001b[1;35mAttention1DWithMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mattn\u001b[1m)\u001b[0m: \u001b[1;35mAttention1D\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mW_q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mW_k\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mW_v\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mAttention1DMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1536\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1536\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mchannel_mapping\u001b[1m)\u001b[0m: \u001b[1;35mPerceiver3DChannelMapping\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmappers\u001b[1m)\u001b[0m: \u001b[1;35mModuleDict\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>test = Perceiver3DDecoder(test_config, AbsolutePositionEmbeddings3D(dim=test_config.dim)     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>display(test)                                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>3 o = test(torch.randn(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1024</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">384</span>), (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span>))                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>display(o.shape)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1736</span> in          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_wrapped_call_impl</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1733 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compiled_call_impl <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1734 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compiled_call_impl(*args, **kwargs)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[misc]</span>        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1735 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1736 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call_impl(*args, **kwargs)                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1737 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1738 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># torchrec tests the code consistency with the following code</span>                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1739 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># fmt: off</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1747</span> in          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1744 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1745 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1746 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1747 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1748 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1749 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>result = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1750 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>called_always_called_hooks = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">set</span>()                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">189</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">186 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>out_shape: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>],                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">187 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>return_all: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">bool</span> = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">188 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>):                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>189 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.checkpointing_level4(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward, kv, out_shape, return_all)         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">190 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/projects/vision_architectures/vision_architectures/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">activation_checkpointing.p</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">30</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn: Callable, *fn_args, use_reentrant: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">bool</span> = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, **fn_kwargs)    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.perform_checkpointing:                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> checkpoint(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span>: fn(*fn_args, **fn_kwargs), use_reentrant=use_reent    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>30 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(*fn_args, **fn_kwargs)                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_forward</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">151</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">148 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> cross_attention_layer <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cross_attention:                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">149 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>output = torch.zeros_like(q)                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">150 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> q_window <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> q_windows:                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>151 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>output_window = cross_attention_layer(q_window, kv, kv)                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">152 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>output = output + output_window                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">153 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>q = rearrange(q, <span style=\"color: #808000; text-decoration-color: #808000\">\"b d z y x -&gt; b (z y x) d\"</span>)                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">154 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># (b, num_output_tokens, dim)</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1736</span> in          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_wrapped_call_impl</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1733 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compiled_call_impl <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1734 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compiled_call_impl(*args, **kwargs)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[misc]</span>        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1735 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1736 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call_impl(*args, **kwargs)                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1737 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1738 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># torchrec tests the code consistency with the following code</span>                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1739 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># fmt: off</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1747</span> in          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1744 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1745 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1746 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1747 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1748 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1749 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>result = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1750 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>called_always_called_hooks = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">set</span>()                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/projects/vision_architectures/vision_architectures/layers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">attention.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">427</span> in       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">424 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> hidden_states                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">425 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">426 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor):        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>427 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.checkpointing_level3(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward, query, key, value)                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">428 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">429 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">430 # %% ../../nbs/layers/01_attention.ipynb 16</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/projects/vision_architectures/vision_architectures/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">activation_checkpointing.p</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">30</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn: Callable, *fn_args, use_reentrant: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">bool</span> = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, **fn_kwargs)    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.perform_checkpointing:                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> checkpoint(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span>: fn(*fn_args, **fn_kwargs), use_reentrant=use_reent    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>30 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(*fn_args, **fn_kwargs)                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/projects/vision_architectures/vision_architectures/layers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">attention.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">399</span> in       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_forward</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">396 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.layernorm1(value)                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">397 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># (b, T, dim)</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">398 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>399 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>hidden_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attn(query, key, value)                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">400 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># (b, T, dim)</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">401 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">402 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.norm_location == <span style=\"color: #808000; text-decoration-color: #808000\">\"post\"</span>:                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1736</span> in          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_wrapped_call_impl</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1733 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compiled_call_impl <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1734 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compiled_call_impl(*args, **kwargs)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[misc]</span>        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1735 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1736 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call_impl(*args, **kwargs)                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1737 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1738 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># torchrec tests the code consistency with the following code</span>                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1739 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># fmt: off</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1747</span> in          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1744 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1745 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1746 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1747 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1748 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1749 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>result = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1750 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>called_always_called_hooks = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">set</span>()                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/projects/vision_architectures/vision_architectures/layers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">attention.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">243</span> in       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">240 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> output                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">241 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">242 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor):        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>243 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.checkpointing_level2(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward, query, key, value)                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">244 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">245 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">246 # %% ../../nbs/layers/01_attention.ipynb 8</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/projects/vision_architectures/vision_architectures/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">activation_checkpointing.p</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">30</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn: Callable, *fn_args, use_reentrant: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">bool</span> = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, **fn_kwargs)    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.perform_checkpointing:                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> checkpoint(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span>: fn(*fn_args, **fn_kwargs), use_reentrant=use_reent    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>30 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(*fn_args, **fn_kwargs)                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/projects/vision_architectures/vision_architectures/layers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">attention.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">196</span> in       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_forward</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">194 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> query_normalized_and_scaled, key_normalized, value                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>196 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>query_normalized_and_scaled, key_normalized, value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.checkpointing_level1(    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>get_final_query_key_value, query, key, value                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/projects/vision_architectures/vision_architectures/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">activation_checkpointing.p</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">30</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn: Callable, *fn_args, use_reentrant: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">bool</span> = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, **fn_kwargs)    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.perform_checkpointing:                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> checkpoint(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span>: fn(*fn_args, **fn_kwargs), use_reentrant=use_reent    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>30 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(*fn_args, **fn_kwargs)                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/projects/vision_architectures/vision_architectures/layers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">attention.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">172</span> in       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_final_query_key_value</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">      </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_final_query_key_value</span>(query, key, value):                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>172 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>query = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.W_q(query)                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>key = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.W_k(key)                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.W_v(value)                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1736</span> in          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_wrapped_call_impl</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1733 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compiled_call_impl <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1734 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compiled_call_impl(*args, **kwargs)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[misc]</span>        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1735 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1736 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call_impl(*args, **kwargs)                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1737 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1738 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># torchrec tests the code consistency with the following code</span>                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1739 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># fmt: off</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1747</span> in          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1744 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1745 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1746 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1747 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1748 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1749 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>result = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1750 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>called_always_called_hooks = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">set</span>()                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">linear.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">125</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>init.uniform_(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias, -bound, bound)                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>125 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.linear(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias)                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">126 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">extra_repr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #808000; text-decoration-color: #808000\">f\"in_features={</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.in_features<span style=\"color: #808000; text-decoration-color: #808000\">}, out_features={</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.out_features<span style=\"color: #808000; text-decoration-color: #808000\">}, bias=</span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>mat1 and mat2 shapes cannot be multiplied <span style=\"font-weight: bold\">(</span>30720<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x20</span> and 384x384<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1 \u001b[0mtest = Perceiver3DDecoder(test_config, AbsolutePositionEmbeddings3D(dim=test_config.dim)     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2 \u001b[0mdisplay(test)                                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m3 o = test(torch.randn(\u001b[94m2\u001b[0m, \u001b[94m1024\u001b[0m, \u001b[94m384\u001b[0m), (\u001b[94m20\u001b[0m, \u001b[94m20\u001b[0m, \u001b[94m20\u001b[0m))                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m4 \u001b[0mdisplay(o.shape)                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m5 \u001b[0m                                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1736\u001b[0m in          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_wrapped_call_impl\u001b[0m                                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1733 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1734 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl(*args, **kwargs)  \u001b[2m# type: ignore[misc]\u001b[0m        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1735 \u001b[0m\u001b[2m      \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1736 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._call_impl(*args, **kwargs)                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1737 \u001b[0m\u001b[2m   \u001b[0m                                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1738 \u001b[0m\u001b[2m   \u001b[0m\u001b[2m# torchrec tests the code consistency with the following code\u001b[0m                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1739 \u001b[0m\u001b[2m   \u001b[0m\u001b[2m# fmt: off\u001b[0m                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1747\u001b[0m in          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1744 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1745 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1746 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1747 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1748 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1749 \u001b[0m\u001b[2m      \u001b[0mresult = \u001b[94mNone\u001b[0m                                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1750 \u001b[0m\u001b[2m      \u001b[0mcalled_always_called_hooks = \u001b[96mset\u001b[0m()                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92mforward\u001b[0m:\u001b[94m189\u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m186 \u001b[0m\u001b[2m      \u001b[0mout_shape: \u001b[96mtuple\u001b[0m[\u001b[96mint\u001b[0m, \u001b[96mint\u001b[0m, \u001b[96mint\u001b[0m],                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m187 \u001b[0m\u001b[2m      \u001b[0mreturn_all: \u001b[96mbool\u001b[0m = \u001b[94mFalse\u001b[0m,                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m188 \u001b[0m\u001b[2m   \u001b[0m):                                                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m189 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.checkpointing_level4(\u001b[96mself\u001b[0m._forward, kv, out_shape, return_all)         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m190 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/projects/vision_architectures/vision_architectures/utils/\u001b[0m\u001b[1;33mactivation_checkpointing.p\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m30\u001b[0m in \u001b[92m__call__\u001b[0m                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m27 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, fn: Callable, *fn_args, use_reentrant: \u001b[96mbool\u001b[0m = \u001b[94mFalse\u001b[0m, **fn_kwargs)    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m28 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.perform_checkpointing:                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m29 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m checkpoint(\u001b[94mlambda\u001b[0m: fn(*fn_args, **fn_kwargs), use_reentrant=use_reent    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m30 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m fn(*fn_args, **fn_kwargs)                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m31 \u001b[0m                                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m_forward\u001b[0m:\u001b[94m151\u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m148 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mfor\u001b[0m cross_attention_layer \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.cross_attention:                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m149 \u001b[0m\u001b[2m         \u001b[0moutput = torch.zeros_like(q)                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m150 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mfor\u001b[0m q_window \u001b[95min\u001b[0m q_windows:                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m151 \u001b[2m            \u001b[0moutput_window = cross_attention_layer(q_window, kv, kv)                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m            \u001b[0moutput = output + output_window                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m      \u001b[0mq = rearrange(q, \u001b[33m\"\u001b[0m\u001b[33mb d z y x -> b (z y x) d\u001b[0m\u001b[33m\"\u001b[0m)                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# (b, num_output_tokens, dim)\u001b[0m                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1736\u001b[0m in          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_wrapped_call_impl\u001b[0m                                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1733 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1734 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl(*args, **kwargs)  \u001b[2m# type: ignore[misc]\u001b[0m        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1735 \u001b[0m\u001b[2m      \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1736 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._call_impl(*args, **kwargs)                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1737 \u001b[0m\u001b[2m   \u001b[0m                                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1738 \u001b[0m\u001b[2m   \u001b[0m\u001b[2m# torchrec tests the code consistency with the following code\u001b[0m                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1739 \u001b[0m\u001b[2m   \u001b[0m\u001b[2m# fmt: off\u001b[0m                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1747\u001b[0m in          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1744 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1745 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1746 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1747 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1748 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1749 \u001b[0m\u001b[2m      \u001b[0mresult = \u001b[94mNone\u001b[0m                                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1750 \u001b[0m\u001b[2m      \u001b[0mcalled_always_called_hooks = \u001b[96mset\u001b[0m()                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/projects/vision_architectures/vision_architectures/layers/\u001b[0m\u001b[1;33mattention.py\u001b[0m:\u001b[94m427\u001b[0m in       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m424 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m hidden_states                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m425 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m426 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor):        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m427 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.checkpointing_level3(\u001b[96mself\u001b[0m._forward, query, key, value)                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m428 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m429 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m430 \u001b[0m\u001b[2m# %% ../../nbs/layers/01_attention.ipynb 16\u001b[0m                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/projects/vision_architectures/vision_architectures/utils/\u001b[0m\u001b[1;33mactivation_checkpointing.p\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m30\u001b[0m in \u001b[92m__call__\u001b[0m                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m27 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, fn: Callable, *fn_args, use_reentrant: \u001b[96mbool\u001b[0m = \u001b[94mFalse\u001b[0m, **fn_kwargs)    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m28 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.perform_checkpointing:                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m29 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m checkpoint(\u001b[94mlambda\u001b[0m: fn(*fn_args, **fn_kwargs), use_reentrant=use_reent    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m30 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m fn(*fn_args, **fn_kwargs)                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m31 \u001b[0m                                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/projects/vision_architectures/vision_architectures/layers/\u001b[0m\u001b[1;33mattention.py\u001b[0m:\u001b[94m399\u001b[0m in       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_forward\u001b[0m                                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m396 \u001b[0m\u001b[2m         \u001b[0mvalue = \u001b[96mself\u001b[0m.layernorm1(value)                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m397 \u001b[0m\u001b[2m         \u001b[0m\u001b[2m# (b, T, dim)\u001b[0m                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m398 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m399 \u001b[2m      \u001b[0mhidden_states = \u001b[96mself\u001b[0m.attn(query, key, value)                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m400 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# (b, T, dim)\u001b[0m                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m401 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m402 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.config.norm_location == \u001b[33m\"\u001b[0m\u001b[33mpost\u001b[0m\u001b[33m\"\u001b[0m:                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1736\u001b[0m in          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_wrapped_call_impl\u001b[0m                                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1733 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1734 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl(*args, **kwargs)  \u001b[2m# type: ignore[misc]\u001b[0m        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1735 \u001b[0m\u001b[2m      \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1736 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._call_impl(*args, **kwargs)                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1737 \u001b[0m\u001b[2m   \u001b[0m                                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1738 \u001b[0m\u001b[2m   \u001b[0m\u001b[2m# torchrec tests the code consistency with the following code\u001b[0m                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1739 \u001b[0m\u001b[2m   \u001b[0m\u001b[2m# fmt: off\u001b[0m                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1747\u001b[0m in          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1744 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1745 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1746 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1747 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1748 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1749 \u001b[0m\u001b[2m      \u001b[0mresult = \u001b[94mNone\u001b[0m                                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1750 \u001b[0m\u001b[2m      \u001b[0mcalled_always_called_hooks = \u001b[96mset\u001b[0m()                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/projects/vision_architectures/vision_architectures/layers/\u001b[0m\u001b[1;33mattention.py\u001b[0m:\u001b[94m243\u001b[0m in       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m240 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m output                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m241 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m242 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor):        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m243 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.checkpointing_level2(\u001b[96mself\u001b[0m._forward, query, key, value)                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m244 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m245 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m246 \u001b[0m\u001b[2m# %% ../../nbs/layers/01_attention.ipynb 8\u001b[0m                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/projects/vision_architectures/vision_architectures/utils/\u001b[0m\u001b[1;33mactivation_checkpointing.p\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m30\u001b[0m in \u001b[92m__call__\u001b[0m                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m27 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, fn: Callable, *fn_args, use_reentrant: \u001b[96mbool\u001b[0m = \u001b[94mFalse\u001b[0m, **fn_kwargs)    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m28 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.perform_checkpointing:                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m29 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m checkpoint(\u001b[94mlambda\u001b[0m: fn(*fn_args, **fn_kwargs), use_reentrant=use_reent    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m30 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m fn(*fn_args, **fn_kwargs)                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m31 \u001b[0m                                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/projects/vision_architectures/vision_architectures/layers/\u001b[0m\u001b[1;33mattention.py\u001b[0m:\u001b[94m196\u001b[0m in       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_forward\u001b[0m                                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m193 \u001b[0m\u001b[2m         \u001b[0m                                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m194 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m query_normalized_and_scaled, key_normalized, value                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m195 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m196 \u001b[2m      \u001b[0mquery_normalized_and_scaled, key_normalized, value = \u001b[96mself\u001b[0m.checkpointing_level1(    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m         \u001b[0mget_final_query_key_value, query, key, value                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m      \u001b[0m)                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m199 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/projects/vision_architectures/vision_architectures/utils/\u001b[0m\u001b[1;33mactivation_checkpointing.p\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m30\u001b[0m in \u001b[92m__call__\u001b[0m                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m27 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, fn: Callable, *fn_args, use_reentrant: \u001b[96mbool\u001b[0m = \u001b[94mFalse\u001b[0m, **fn_kwargs)    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m28 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.perform_checkpointing:                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m29 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m checkpoint(\u001b[94mlambda\u001b[0m: fn(*fn_args, **fn_kwargs), use_reentrant=use_reent    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m30 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m fn(*fn_args, **fn_kwargs)                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m31 \u001b[0m                                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/projects/vision_architectures/vision_architectures/layers/\u001b[0m\u001b[1;33mattention.py\u001b[0m:\u001b[94m172\u001b[0m in       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92mget_final_query_key_value\u001b[0m                                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2;33m      \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m170 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m171 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_final_query_key_value\u001b[0m(query, key, value):                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m172 \u001b[2m         \u001b[0mquery = \u001b[96mself\u001b[0m.W_q(query)                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m         \u001b[0mkey = \u001b[96mself\u001b[0m.W_k(key)                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m         \u001b[0mvalue = \u001b[96mself\u001b[0m.W_v(value)                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m175 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1736\u001b[0m in          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_wrapped_call_impl\u001b[0m                                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1733 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1734 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl(*args, **kwargs)  \u001b[2m# type: ignore[misc]\u001b[0m        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1735 \u001b[0m\u001b[2m      \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1736 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._call_impl(*args, **kwargs)                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1737 \u001b[0m\u001b[2m   \u001b[0m                                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1738 \u001b[0m\u001b[2m   \u001b[0m\u001b[2m# torchrec tests the code consistency with the following code\u001b[0m                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1739 \u001b[0m\u001b[2m   \u001b[0m\u001b[2m# fmt: off\u001b[0m                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1747\u001b[0m in          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1744 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1745 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1746 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1747 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1748 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1749 \u001b[0m\u001b[2m      \u001b[0mresult = \u001b[94mNone\u001b[0m                                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1750 \u001b[0m\u001b[2m      \u001b[0mcalled_always_called_hooks = \u001b[96mset\u001b[0m()                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mlinear.py\u001b[0m:\u001b[94m125\u001b[0m in \u001b[92mforward\u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m         \u001b[0minit.uniform_(\u001b[96mself\u001b[0m.bias, -bound, bound)                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m125 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m F.linear(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.bias)                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m126 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m127 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mextra_repr\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[96mstr\u001b[0m:                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m128 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33min_features=\u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.in_features\u001b[33m}\u001b[0m\u001b[33m, out_features=\u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.out_features\u001b[33m}\u001b[0m\u001b[33m, bias=\u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mmat1 and mat2 shapes cannot be multiplied \u001b[1m(\u001b[0m30720\u001b[1;36m0x20\u001b[0m and 384x384\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = Perceiver3DDecoder(test_config, AbsolutePositionEmbeddings3D(dim=test_config.dim))\n",
    "display(test)\n",
    "o = test(torch.randn(2, 1024, 384), (20, 20, 20))\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
