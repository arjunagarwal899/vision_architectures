{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp nets/swinv2_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def populate_and_validate_config(config: dict) -> dict:\n",
    "    assert config[\"stages\"][0][\"patch_merging\"] is None\n",
    "\n",
    "    # Prepare config based on provided values\n",
    "    dim = config[\"dim\"]\n",
    "    patch_size = config[\"patch_size\"]\n",
    "    # image_size = config[\"image_size\"]  # This may not be fixed while fine-tuning.\n",
    "    for i in range(len(config[\"stages\"])):\n",
    "        stage = config[\"stages\"][i]\n",
    "        stage[\"_in_dim\"] = dim\n",
    "        stage[\"_in_patch_size\"] = patch_size\n",
    "        # stage['_in\"grid_size'] = tuple([image // patch for image, patch in zip(image_size, patch_size)])\n",
    "        if stage[\"patch_merging\"] is not None:\n",
    "            dim *= stage[\"patch_merging\"][\"out_dim_ratio\"]\n",
    "            patch_size = tuple(\n",
    "                [patch * window for patch, window in zip(patch_size, stage[\"patch_merging\"][\"merge_window_size\"])]\n",
    "            )\n",
    "        stage[\"_out_dim\"] = dim\n",
    "        stage[\"_out_patch_size\"] = patch_size\n",
    "        # stage[\"_out_grid_size\"] = tuple([image // patch for image, patch in zip(image_size, patch_size)])\n",
    "\n",
    "    for stage in config[\"stages\"]:\n",
    "        assert stage[\"_out_dim\"] % stage[\"num_heads\"] == 0, stage\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'patch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'in_channels'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "    \u001b[32m'use_absolute_position_embeddings'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'learnable_absolute_position_embeddings'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'embed_spacing_info'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'image_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'dim'\u001b[0m: \u001b[1;36m36\u001b[0m,\n",
       "    \u001b[32m'stages'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'patch_merging'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[32m'depth'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "            \u001b[32m'num_heads'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'intermediate_ratio'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'layer_norm_eps'\u001b[0m: \u001b[1;36m1e-06\u001b[0m,\n",
       "            \u001b[32m'window_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'use_relative_position_bias'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "            \u001b[32m'_in_dim'\u001b[0m: \u001b[1;36m36\u001b[0m,\n",
       "            \u001b[32m'_in_patch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'_out_dim'\u001b[0m: \u001b[1;36m36\u001b[0m,\n",
       "            \u001b[32m'_out_patch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'patch_merging'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'merge_window_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'out_dim_ratio'\u001b[0m: \u001b[1;36m3\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'depth'\u001b[0m: \u001b[1;36m3\u001b[0m,\n",
       "            \u001b[32m'num_heads'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'intermediate_ratio'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'layer_norm_eps'\u001b[0m: \u001b[1;36m1e-06\u001b[0m,\n",
       "            \u001b[32m'window_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'use_relative_position_bias'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'_in_dim'\u001b[0m: \u001b[1;36m36\u001b[0m,\n",
       "            \u001b[32m'_in_patch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'_out_dim'\u001b[0m: \u001b[1;36m108\u001b[0m,\n",
       "            \u001b[32m'_out_patch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'patch_merging'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'merge_window_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'out_dim_ratio'\u001b[0m: \u001b[1;36m3\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'depth'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "            \u001b[32m'num_heads'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'intermediate_ratio'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'layer_norm_eps'\u001b[0m: \u001b[1;36m1e-06\u001b[0m,\n",
       "            \u001b[32m'window_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'use_relative_position_bias'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'_in_dim'\u001b[0m: \u001b[1;36m108\u001b[0m,\n",
       "            \u001b[32m'_in_patch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'_out_dim'\u001b[0m: \u001b[1;36m324\u001b[0m,\n",
       "            \u001b[32m'_out_patch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"patch_size\": (1, 8, 8),\n",
    "    \"in_channels\": 1,\n",
    "    \"use_absolute_position_embeddings\": True,\n",
    "    \"learnable_absolute_position_embeddings\": False,\n",
    "    \"embed_spacing_info\": False,\n",
    "    \"image_size\": (32, 512, 512),\n",
    "    \"dim\": 36,\n",
    "    \"stages\": [\n",
    "        {\n",
    "            \"patch_merging\": None,\n",
    "            \"depth\": 1,\n",
    "            \"num_heads\": 4,\n",
    "            \"intermediate_ratio\": 4,\n",
    "            \"layer_norm_eps\": 1e-6,\n",
    "            \"window_size\": (4, 4, 4),\n",
    "            \"use_relative_position_bias\": False,\n",
    "        },\n",
    "        {\n",
    "            \"patch_merging\": {\n",
    "                \"merge_window_size\": (2, 2, 2),\n",
    "                \"out_dim_ratio\": 3,\n",
    "            },\n",
    "            \"depth\": 3,\n",
    "            \"num_heads\": 4,\n",
    "            \"intermediate_ratio\": 4,\n",
    "            \"layer_norm_eps\": 1e-6,\n",
    "            \"window_size\": (4, 4, 4),\n",
    "            \"use_relative_position_bias\": True,\n",
    "        },\n",
    "        {\n",
    "            \"patch_merging\": {\n",
    "                \"merge_window_size\": (2, 2, 2),\n",
    "                \"out_dim_ratio\": 3,\n",
    "            },\n",
    "            \"depth\": 1,\n",
    "            \"num_heads\": 4,\n",
    "            \"intermediate_ratio\": 4,\n",
    "            \"layer_norm_eps\": 1e-6,\n",
    "            \"window_size\": (4, 4, 4),\n",
    "            \"use_relative_position_bias\": True,\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "populate_and_validate_config(test_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_coords_grid(grid_size):\n",
    "    d, h, w = grid_size\n",
    "\n",
    "    grid_d = torch.arange(d, dtype=torch.int32)\n",
    "    grid_h = torch.arange(h, dtype=torch.int32)\n",
    "    grid_w = torch.arange(w, dtype=torch.int32)\n",
    "\n",
    "    grid = torch.meshgrid(grid_w, grid_h, grid_d, indexing=\"ij\")\n",
    "    grid = torch.stack(grid, axis=0)\n",
    "    # (3, d, h, w)\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DMHSA(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        window_size,\n",
    "        use_relative_position_bias,\n",
    "        attn_drop_prob=0.0,\n",
    "        proj_drop_prob=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert dim % num_heads == 0, \"dimension must be divisible by number of heads\"\n",
    "\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.per_head_dim = int(dim // num_heads)\n",
    "\n",
    "        self.W_qkv = nn.Linear(dim, 3 * dim)\n",
    "        self.attn_drop_prob = attn_drop_prob\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop_prob)\n",
    "\n",
    "        self.logit_scale = nn.Parameter(torch.log(10 * torch.ones((num_heads, 1, 1))))\n",
    "\n",
    "        # TODO: Add embed_spacing_info functionality\n",
    "        self.use_relative_position_bias = use_relative_position_bias\n",
    "        if use_relative_position_bias:\n",
    "            self.cpb_mlp = nn.Sequential(\n",
    "                nn.Linear(3, 512, bias=True), nn.ReLU(inplace=True), nn.Linear(512, num_heads, bias=False)\n",
    "            )\n",
    "\n",
    "            relative_limits = (2 * window_size[0] - 1, 2 * window_size[1] - 1, 2 * window_size[2] - 1)\n",
    "\n",
    "            # Relative coordinates table\n",
    "            relative_coords_table = get_coords_grid(relative_limits).float()\n",
    "            relative_coords_table[0] -= window_size[0] - 1\n",
    "            relative_coords_table[1] -= window_size[1] - 1\n",
    "            relative_coords_table[2] -= window_size[2] - 1\n",
    "            relative_coords_table = relative_coords_table.permute(1, 2, 3, 0).contiguous()\n",
    "            relative_coords_table[:, :, :, 0] /= self.window_size[0] - 1\n",
    "            relative_coords_table[:, :, :, 1] /= self.window_size[1] - 1\n",
    "            relative_coords_table[:, :, :, 2] /= self.window_size[2] - 1\n",
    "            relative_coords_table *= 8  # Normalize to -8, 8\n",
    "            relative_coords_table = (\n",
    "                torch.sign(relative_coords_table) * torch.log2(torch.abs(relative_coords_table) + 1.0) / np.log2(8)\n",
    "            )\n",
    "            # (window_size_z, window_size_y, window_size_x, 3)\n",
    "            # Allow moving this to and from cuda whenever required but don't save to state_dict\n",
    "            self.register_buffer(\"relative_coords_table\", relative_coords_table, persistent=False)\n",
    "\n",
    "            # Pair-wise relative position index for each token inside the window\n",
    "            coords = get_coords_grid(window_size)\n",
    "            coords_flatten = rearrange(\n",
    "                coords, \"three_dimensional d h w -> three_dimensional (d h w)\", three_dimensional=3\n",
    "            )\n",
    "            relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "            relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "            relative_coords[:, :, 0] += window_size[0] - 1\n",
    "            relative_coords[:, :, 1] += window_size[1] - 1\n",
    "            relative_coords[:, :, 2] += window_size[2] - 1\n",
    "            relative_position_index: torch.Tensor = (\n",
    "                relative_coords[:, :, 0] * relative_limits[1] * relative_limits[2]\n",
    "                + relative_coords[:, :, 1] * relative_limits[2]\n",
    "                + relative_coords[:, :, 2]\n",
    "            )\n",
    "            self.relative_position_index = relative_position_index.flatten()\n",
    "            # (num_patches, num_patches)\n",
    "\n",
    "    def calculate_relative_position_bias(self):\n",
    "        # (window_size_z, window_size_y, window_size_x, 3)\n",
    "        relative_position_bias_table = self.cpb_mlp(self.relative_coords_table)\n",
    "        # (window_size_z, window_size_y, window_size_x, num_heads)\n",
    "        relative_position_bias_table = relative_position_bias_table.reshape(-1, self.num_heads)\n",
    "        # (num_patches, num_heads)\n",
    "        relative_position_bias = relative_position_bias_table[self.relative_position_index]\n",
    "        # (num_patches * num_patches, num_heads)\n",
    "        relative_position_bias = rearrange(\n",
    "            relative_position_bias,\n",
    "            \"(num_patches1 num_patches2) num_heads -> num_heads num_patches1 num_patches2\",\n",
    "            num_patches1=np.prod(self.window_size),\n",
    "            num_patches2=np.prod(self.window_size),\n",
    "            num_heads=self.num_heads,\n",
    "        ).contiguous()\n",
    "        # (num_heads, num_patches, num_patches)\n",
    "        relative_position_bias = 16 * torch.sigmoid(relative_position_bias)\n",
    "        # (num_heads, num_patches, num_patches)\n",
    "        return relative_position_bias\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "        _, num_patches_z, num_patches_y, num_patches_x, _ = hidden_states.shape\n",
    "\n",
    "        query, key, value = rearrange(\n",
    "            self.W_qkv(hidden_states),\n",
    "            \"b nz ny nx (n num_heads d) -> n b num_heads (nz ny nx) d\",\n",
    "            n=3,\n",
    "            num_heads=self.num_heads,\n",
    "        )\n",
    "        # num_patches = window_size_z * window_size_y * window_size_x\n",
    "        # Each is (windowed_b, num_heads, num_patches, per_head_dim)\n",
    "\n",
    "        logit_scale = torch.clamp(self.logit_scale, max=np.log(1.0 / 0.01)).exp()\n",
    "\n",
    "        query_normalized = F.normalize(query, dim=-1)\n",
    "        key_normalized = F.normalize(key, dim=-1)\n",
    "\n",
    "        query_normalized_and_scaled = query_normalized * logit_scale  # Scale the query beforehand\n",
    "\n",
    "        relative_position_bias = None\n",
    "        if self.use_relative_position_bias:\n",
    "            relative_position_bias = self.calculate_relative_position_bias()\n",
    "\n",
    "        context = F.scaled_dot_product_attention(\n",
    "            query_normalized_and_scaled,\n",
    "            key_normalized,\n",
    "            value,\n",
    "            attn_mask=relative_position_bias,  # Use this as a way to introduce relative position bias\n",
    "            dropout_p=self.attn_drop_prob,\n",
    "            is_causal=False,\n",
    "            scale=1.0,  # Already scaled the vectors\n",
    "        )\n",
    "        # (windowed_b, num_heads, num_patches, per_head_dim)\n",
    "\n",
    "        context = rearrange(\n",
    "            context,\n",
    "            \"b num_heads (num_patches_z num_patches_y num_patches_x) d -> \"\n",
    "            \"b num_patches_z num_patches_y num_patches_x (num_heads d)\",\n",
    "            num_patches_z=num_patches_z,\n",
    "            num_patches_y=num_patches_y,\n",
    "            num_patches_x=num_patches_x,\n",
    "        )\n",
    "        # (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "\n",
    "        context = self.proj(context)\n",
    "        context = self.proj_drop(context)\n",
    "        # (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m162\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m54\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = SwinV23DMHSA(54, 6, (4, 4, 4), True)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 4, 4, 4, 54)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DLayerMLP(nn.Module):\n",
    "    def __init__(self, dim, intermediate_ratio, dropout_prob=0.0):\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.Linear(dim, dim * intermediate_ratio)\n",
    "        self.act = nn.GELU()\n",
    "        self.dense2 = nn.Linear(dim * intermediate_ratio, dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "        hidden_states = self.dense1(hidden_states)\n",
    "        hidden_states = self.act(hidden_states)\n",
    "        hidden_states = self.dense2(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m16384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m16384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = SwinV23DLayerMLP(64, 256)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 4, 4, 4, 64)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        intermediate_ratio,\n",
    "        layer_norm_eps,\n",
    "        window_size,\n",
    "        use_relative_position_bias,\n",
    "        attn_drop_prob=0.0,\n",
    "        proj_drop_prob=0.0,\n",
    "        mlp_drop_prob=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.mhsa = SwinV23DMHSA(\n",
    "            dim, num_heads, window_size, use_relative_position_bias, attn_drop_prob, proj_drop_prob\n",
    "        )\n",
    "        self.layernorm1 = nn.LayerNorm(dim, eps=layer_norm_eps)\n",
    "        self.mlp = SwinV23DLayerMLP(dim, intermediate_ratio, mlp_drop_prob)\n",
    "        self.layernorm2 = nn.LayerNorm(dim, eps=layer_norm_eps)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "        _, num_patches_z, num_patches_y, num_patches_x, _ = hidden_states.shape\n",
    "\n",
    "        # Perform windowing\n",
    "        window_size_z, window_size_y, window_size_x = self.window_size\n",
    "        num_windows_z, num_windows_y, num_windows_x = (\n",
    "            num_patches_z // window_size_z,\n",
    "            num_patches_y // window_size_y,\n",
    "            num_patches_x // window_size_x,\n",
    "        )\n",
    "        hidden_states = rearrange(\n",
    "            hidden_states,\n",
    "            \"b (num_windows_z window_size_z) (num_windows_y window_size_y) (num_windows_x window_size_x) dim -> \"\n",
    "            \"(b num_windows_z num_windows_y num_windows_x) window_size_z window_size_y window_size_x dim \",\n",
    "            num_windows_z=num_windows_z,\n",
    "            num_windows_y=num_windows_y,\n",
    "            num_windows_x=num_windows_x,\n",
    "            window_size_z=window_size_z,\n",
    "            window_size_y=window_size_y,\n",
    "            window_size_x=window_size_x,\n",
    "        )\n",
    "\n",
    "        res_connection1 = hidden_states\n",
    "        # (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "\n",
    "        hidden_states = self.mhsa(hidden_states)\n",
    "        hidden_states = self.layernorm1(hidden_states)\n",
    "        # (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "\n",
    "        res_connection2 = hidden_states + res_connection1\n",
    "        # (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "\n",
    "        hidden_states = self.mlp(res_connection2)\n",
    "        hidden_states = self.layernorm2(hidden_states)\n",
    "        # (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "\n",
    "        hidden_states = hidden_states + res_connection2\n",
    "        # (windowed_b, window_size_z window_size_y window_size_x, dim)\n",
    "\n",
    "        # Undo windowing\n",
    "        output = rearrange(\n",
    "            hidden_states,\n",
    "            \"(b num_windows_z num_windows_y num_windows_x) window_size_z window_size_y window_size_x dim -> \"\n",
    "            \"b (num_windows_z window_size_z) (num_windows_y window_size_y) (num_windows_x window_size_x) dim\",\n",
    "            num_windows_z=num_windows_z,\n",
    "            num_windows_y=num_windows_y,\n",
    "            num_windows_x=num_windows_x,\n",
    "            window_size_z=window_size_z,\n",
    "            window_size_y=window_size_y,\n",
    "            window_size_x=window_size_x,\n",
    "        )\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m16384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m16384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = SwinV23DLayer(64, 4, 256, 1e-6, (2, 2, 2), True)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 4, 4, 4, 64)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DBlock(nn.Module):\n",
    "    def __init__(self, stage_config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stage_config = stage_config\n",
    "        self.w_layer = SwinV23DLayer(\n",
    "            stage_config[\"_out_dim\"],\n",
    "            stage_config[\"num_heads\"],\n",
    "            stage_config[\"intermediate_ratio\"],\n",
    "            stage_config[\"layer_norm_eps\"],\n",
    "            stage_config[\"window_size\"],\n",
    "            stage_config[\"use_relative_position_bias\"],\n",
    "            stage_config.get(\"attn_drop_prob\", 0.0),\n",
    "            stage_config.get(\"proj_drop_prob\", 0.0),\n",
    "            stage_config.get(\"mlp_drop_prob\", 0.0),\n",
    "        )\n",
    "        self.sw_layer = SwinV23DLayer(\n",
    "            stage_config[\"_out_dim\"],\n",
    "            stage_config[\"num_heads\"],\n",
    "            stage_config[\"intermediate_ratio\"],\n",
    "            stage_config[\"layer_norm_eps\"],\n",
    "            stage_config[\"window_size\"],\n",
    "            stage_config[\"use_relative_position_bias\"],\n",
    "            stage_config.get(\"attn_drop_prob\", 0.0),\n",
    "            stage_config.get(\"proj_drop_prob\", 0.0),\n",
    "            stage_config.get(\"mlp_drop_prob\", 0.0),\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        layer_outputs = []\n",
    "\n",
    "        # First layer\n",
    "        hidden_states = self.w_layer(hidden_states)\n",
    "        # (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        layer_outputs.append(hidden_states)\n",
    "\n",
    "        # Shift windows\n",
    "        window_size_z, window_size_y, window_size_x = self.stage_config[\"window_size\"]\n",
    "        shifts = (window_size_z // 2, window_size_y // 2, window_size_x // 2)\n",
    "        hidden_states = torch.roll(hidden_states, shifts=shifts, dims=(1, 2, 3))\n",
    "        # (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        # Second layer\n",
    "        hidden_states = self.sw_layer(hidden_states)\n",
    "        # (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        # Reverse window shift\n",
    "        shifts = tuple(-shift for shift in shifts)\n",
    "        hidden_states = torch.roll(hidden_states, shifts=shifts, dims=(1, 2, 3))\n",
    "        # (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        layer_outputs.append(hidden_states)\n",
    "\n",
    "        return hidden_states, layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_stage_config = {\n",
    "    \"depth\": 4,\n",
    "    \"_out_dim\": 64,\n",
    "    \"num_heads\": 4,\n",
    "    \"intermediate_ratio\": 4,\n",
    "    \"layer_norm_eps\": 1e-6,\n",
    "    \"window_size\": (4, 4, 4),\n",
    "    \"use_relative_position_bias\": True,\n",
    "}\n",
    "\n",
    "test = SwinV23DBlock(test_stage_config)\n",
    "display(test)\n",
    "o = test(torch.randn(2, 4, 4, 4, 64))\n",
    "display((o[0].shape, (o[1][0].shape, o[1][1].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DPatchMerging(nn.Module):\n",
    "    def __init__(self, merge_window_size, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.merge_window_size = merge_window_size\n",
    "\n",
    "        in_dim = in_dim * np.prod(merge_window_size)\n",
    "        self.layer_norm = nn.LayerNorm(in_dim)\n",
    "        self.proj = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        window_size_z, window_size_y, window_size_x = self.merge_window_size\n",
    "\n",
    "        hidden_states = rearrange(\n",
    "            hidden_states,\n",
    "            \"b (new_num_patches_z window_size_z) (new_num_patches_y window_size_y) (new_num_patches_x window_size_x) dim -> \"\n",
    "            \"b new_num_patches_z new_num_patches_y new_num_patches_x (window_size_z window_size_y window_size_x dim)\",\n",
    "            window_size_z=window_size_z,\n",
    "            window_size_y=window_size_y,\n",
    "            window_size_x=window_size_x,\n",
    "        )\n",
    "\n",
    "        hidden_states = self.layer_norm(hidden_states)\n",
    "        hidden_states = self.proj(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DPatchMerging\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m192\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_stage_config = {\n",
    "    \"_in_dim\": 64,\n",
    "    \"_out_dim\": 64 * 3,\n",
    "    \"patch_merging\": {\n",
    "        \"merge_window_size\": (2, 2, 2),\n",
    "        \"out_dim_ratio\": 3,\n",
    "    },\n",
    "    \"depth\": 4,\n",
    "    \"num_heads\": 4,\n",
    "    \"intermediate_size\": 256,\n",
    "    \"layer_norm_eps\": 1e-6,\n",
    "    \"window_size\": (4, 4, 4),\n",
    "    \"use_relative_position_bias\": True,\n",
    "}\n",
    "\n",
    "test = SwinV23DPatchMerging(\n",
    "    test_stage_config[\"patch_merging\"][\"merge_window_size\"],\n",
    "    test_stage_config[\"_in_dim\"],\n",
    "    test_stage_config[\"_out_dim\"],\n",
    ")\n",
    "display(test)\n",
    "display(test(torch.randn(2, 4, 4, 4, 64)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DStage(nn.Module):\n",
    "    def __init__(self, stage_config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = stage_config\n",
    "\n",
    "        self.patch_merging = None\n",
    "        if stage_config[\"patch_merging\"] is not None:\n",
    "            self.patch_merging = SwinV23DPatchMerging(\n",
    "                stage_config[\"patch_merging\"][\"merge_window_size\"],\n",
    "                stage_config[\"_in_dim\"],\n",
    "                stage_config[\"_out_dim\"],\n",
    "            )\n",
    "\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [SwinV23DBlock(stage_config) for _ in range(stage_config[\"depth\"])],\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        if self.patch_merging:\n",
    "            hidden_states = self.patch_merging(hidden_states)\n",
    "            # (b, new_num_patches_z, new_num_patches_y, new_num_patches_x, new_dim)\n",
    "\n",
    "        layer_outputs = []\n",
    "        for layer_module in self.blocks:\n",
    "            hidden_states, _layer_outputs = layer_module(hidden_states)\n",
    "            # (b, new_num_patches_z, new_num_patches_y, new_num_patches_x, new_dim)\n",
    "            layer_outputs.extend(_layer_outputs)\n",
    "\n",
    "        return hidden_states, layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mpatch_merging\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchMerging\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m2\u001b[0m x \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m144\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m576\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m576\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m144\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m144\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m576\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m576\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m144\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m144\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m144\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m144\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m144\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m144\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_stage_config = {\n",
    "    \"patch_merging\": {\n",
    "        \"merge_window_size\": (2, 2, 2),\n",
    "        \"out_dim_ratio\": 3,\n",
    "    },\n",
    "    \"depth\": 2,\n",
    "    \"_in_dim\": 48,\n",
    "    \"_out_dim\": 48 * 3,\n",
    "    \"num_heads\": 4,\n",
    "    \"intermediate_ratio\": 4,\n",
    "    \"layer_norm_eps\": 1e-6,\n",
    "    \"window_size\": (4, 4, 4),\n",
    "    \"use_relative_position_bias\": True,\n",
    "}\n",
    "\n",
    "test = SwinV23DStage(test_stage_config)\n",
    "display(test)\n",
    "o = test(torch.randn(2, 8, 8, 8, 48))\n",
    "display((o[0].shape, [x.shape for x in o[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DEncoder(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stages = nn.ModuleList([SwinV23DStage(stage_config) for stage_config in config[\"stages\"]])\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        # hidden_states: (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        stage_outputs, layer_outputs = [], []\n",
    "        for stage_module in self.stages:\n",
    "            hidden_states, _layer_outputs = stage_module(hidden_states)\n",
    "            # (b, new_num_patches_z, new_num_patches_y, new_num_patches_x, dim)\n",
    "\n",
    "            stage_outputs.append(hidden_states)\n",
    "            layer_outputs.extend(_layer_outputs)\n",
    "\n",
    "        return hidden_states, stage_outputs, layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DEncoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mstages\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mpatch_merging\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchMerging\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m3\u001b[0m x \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m288\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m96\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m96\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m288\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m96\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m384\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m96\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m96\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m96\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"stages\": [\n",
    "        {\n",
    "            \"patch_merging\": None,\n",
    "            \"_in_dim\": 32,\n",
    "            \"_out_dim\": 32,\n",
    "            \"depth\": 1,\n",
    "            \"num_heads\": 4,\n",
    "            \"intermediate_ratio\": 4,\n",
    "            \"layer_norm_eps\": 1e-6,\n",
    "            \"window_size\": (4, 4, 4),\n",
    "            \"use_relative_position_bias\": False,\n",
    "        },\n",
    "        {\n",
    "            \"patch_merging\": {\n",
    "                \"merge_window_size\": (2, 2, 2),\n",
    "                \"out_dim_ratio\": 3,\n",
    "            },\n",
    "            \"_in_dim\": 32,\n",
    "            \"_out_dim\": 32 * 3,\n",
    "            \"depth\": 3,\n",
    "            \"num_heads\": 4,\n",
    "            \"intermediate_ratio\": 4,\n",
    "            \"layer_norm_eps\": 1e-6,\n",
    "            \"window_size\": (4, 4, 4),\n",
    "            \"use_relative_position_bias\": True,\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "test = SwinV23DEncoder(test_config)\n",
    "display(test)\n",
    "o = test(torch.randn(2, 16, 16, 16, 32))\n",
    "display((o[0].shape, [x.shape for x in o[1]], [x.shape for x in o[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DPatchEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        patch_size = config[\"patch_size\"]\n",
    "        num_channels = config[\"in_channels\"]\n",
    "        dim = config[\"dim\"]\n",
    "\n",
    "        self.patch_embeddings = nn.Conv3d(\n",
    "            in_channels=num_channels,\n",
    "            out_channels=dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=patch_size,\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values: torch.Tensor):\n",
    "        # pixel_values: (b, c, z, y, x)\n",
    "\n",
    "        embeddings = self.patch_embeddings(pixel_values)\n",
    "        # (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DPatchEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"patch_size\": (1, 8, 8),\n",
    "    \"in_channels\": 1,\n",
    "    \"dim\": 12,\n",
    "}\n",
    "\n",
    "test = SwinV23DPatchEmbeddings(test_config)\n",
    "display(test)\n",
    "o = test(torch.randn(2, 1, 32, 512, 512))\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_3d_position_embeddings(embedding_size, grid_size, patch_size=(1, 1, 1)):\n",
    "    if embedding_size % 6 != 0:\n",
    "        raise ValueError(\"embed_dim must be divisible by 6\")\n",
    "\n",
    "    grid = get_coords_grid(grid_size)\n",
    "    # (3, d, h, w)\n",
    "\n",
    "    grid = rearrange(grid, \"x d h w -> x 1 d h w\")\n",
    "    # (3, 1, d, h, w)\n",
    "\n",
    "    omega = torch.arange(embedding_size // 6, dtype=torch.float32)\n",
    "    omega /= embedding_size / 6.0\n",
    "    omega = 1.0 / 10000**omega\n",
    "    # (d // 6)\n",
    "\n",
    "    patch_multiplier = torch.Tensor(patch_size) / min(patch_size)\n",
    "\n",
    "    position_embeddings = []\n",
    "    for i, grid_subset in enumerate(grid):\n",
    "        grid_subset = grid_subset.reshape(-1)\n",
    "        out = torch.einsum(\"m,d->md\", grid_subset, omega)\n",
    "\n",
    "        emb_sin = torch.sin(out)\n",
    "        emb_cos = torch.cos(out)\n",
    "\n",
    "        emb = torch.cat([emb_sin, emb_cos], axis=1) * patch_multiplier[i]\n",
    "        position_embeddings.append(emb)\n",
    "\n",
    "    position_embeddings = torch.cat(position_embeddings, axis=1)\n",
    "    # (embedding_size, d * h * w)\n",
    "    d, h, w = grid_size\n",
    "    position_embeddings = rearrange(position_embeddings, \"(d h w) e -> 1 e d h w\", d=d, h=h, w=w)\n",
    "    # (1, embedding_size, d, h, w)\n",
    "\n",
    "    return position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def embed_spacings_in_position_embeddings(embeddings: torch.Tensor, spacings: torch.Tensor):\n",
    "    assert spacings is not None, \"spacing information cannot be None\"\n",
    "    assert spacings.ndim == 2, \"Please provide spacing information for each batch element\"\n",
    "    _, embedding_size, _, _, _ = embeddings.shape\n",
    "    assert embedding_size % 3 == 0, \"To embed spacing info, the embedding size must be divisible by 3\"\n",
    "    embeddings = embeddings * repeat(spacings, f\"B S -> B (S {int(embedding_size / 3)}) 1 1 1\", S=3)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        dim = config[\"dim\"]\n",
    "\n",
    "        self.patch_embeddings = SwinV23DPatchEmbeddings(config)\n",
    "        self.layer_norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.absolute_position_embeddings = None\n",
    "        if config[\"use_absolute_position_embeddings\"]:\n",
    "            grid_size = (\n",
    "                config[\"image_size\"][0] // config[\"patch_size\"][0],\n",
    "                config[\"image_size\"][1] // config[\"patch_size\"][1],\n",
    "                config[\"image_size\"][2] // config[\"patch_size\"][2],\n",
    "            )\n",
    "            if config[\"learnable_absolute_position_embeddings\"]:\n",
    "                self.absolute_position_embeddings = nn.Parameter(\n",
    "                    torch.randn(1, dim, grid_size[0], grid_size[1], grid_size[2])\n",
    "                )\n",
    "            else:\n",
    "                self.absolute_position_embeddings = get_3d_position_embeddings(dim, grid_size, config[\"patch_size\"])\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: torch.Tensor,\n",
    "        spacings: torch.Tensor = None,\n",
    "        mask_patches: torch.Tensor = None,\n",
    "        mask_token: torch.Tensor = None,\n",
    "    ):\n",
    "        # pixel_values: (b, c, z, y, x)\n",
    "\n",
    "        embeddings = self.patch_embeddings(pixel_values)\n",
    "        # (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "        embeddings = rearrange(embeddings, \"b d nz ny nx -> b nz ny nx d\")\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = rearrange(embeddings, \"b nz ny nx d -> b d nz ny nx\")\n",
    "        # (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        if mask_patches is not None:\n",
    "            # mask_patches (binary mask): (b, num_patches_z, num_patches_y, num_patches_x)\n",
    "            # mask_token: (1, dim, 1, 1, 1)\n",
    "            mask_patches = repeat(mask_patches, \"b z y x -> b d z y x\", d=embeddings.shape[1])\n",
    "            embeddings = (embeddings * (1 - mask_patches)) + (mask_patches * mask_token)\n",
    "\n",
    "        if self.absolute_position_embeddings is not None:\n",
    "            absolute_position_embeddings = self.absolute_position_embeddings.to(embeddings.device)\n",
    "            # (1, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "            if self.config[\"embed_spacing_info\"]:\n",
    "                absolute_position_embeddings = embed_spacings_in_position_embeddings(\n",
    "                    absolute_position_embeddings, spacings\n",
    "                )\n",
    "                # (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "            embeddings = embeddings + absolute_position_embeddings\n",
    "            # (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"patch_size\": (1, 8, 8),\n",
    "    \"in_channels\": 1,\n",
    "    \"dim\": 36,\n",
    "    \"use_absolute_position_embeddings\": True,\n",
    "    \"learnable_absolute_position_embeddings\": False,\n",
    "    \"embed_spacing_info\": False,\n",
    "    \"image_size\": (32, 512, 512),\n",
    "}\n",
    "\n",
    "test = SwinV23DEmbeddings(test_config)\n",
    "display(test)\n",
    "o = test(\n",
    "    torch.randn(2, 1, 32, 512, 512),\n",
    "    torch.randn(2, 3),\n",
    ")\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance of (0, 0, 0) with other coords\n",
      "(0, 0, 0) 0.0\n",
      "(0, 0, 1) 0.95885104\n",
      "(0, 1, 0) 0.95885104\n",
      "(0, 1, 1) 1.3560202\n",
      "(1, 0, 0) 0.95885104\n",
      "(1, 0, 1) 1.3560202\n",
      "(1, 1, 0) 1.3560202\n",
      "(1, 1, 1) 1.6607788\n"
     ]
    }
   ],
   "source": [
    "e = get_3d_position_embeddings(6, (2, 2, 2), (1, 1, 1))\n",
    "display(e.shape)\n",
    "\n",
    "print(\"Distance of (0, 0, 0) with other coords\")\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            print((i, j, k), np.linalg.norm(e[0, :, 0, 0, 0] - e[0, :, i, j, k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DModel(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings = SwinV23DEmbeddings(config)\n",
    "        self.pos_drop = nn.Dropout(config.get(\"drop_prob\", 0.0))\n",
    "        self.encoder = SwinV23DEncoder(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: torch.Tensor,\n",
    "        spacings: torch.Tensor = None,\n",
    "        mask_patches: torch.Tensor = None,\n",
    "        mask_token: torch.Tensor = None,\n",
    "    ):\n",
    "        # pixel_values: (b, c, z, y, x)\n",
    "        # spacings: (b, 3)\n",
    "        # mask_patches: (num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        embeddings = self.embeddings(pixel_values, spacings, mask_patches, mask_token)\n",
    "        embeddings = self.pos_drop(embeddings)\n",
    "        # (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        embeddings = rearrange(embeddings, \"b e nz ny nx -> b nz ny nx e\")\n",
    "        # (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "\n",
    "        encoded, stage_outputs, layer_outputs = self.encoder(embeddings)\n",
    "        # encoded: (b, new_num_patches_z, new_num_patches_y, new_num_patches_x, dim)\n",
    "        # stage_outputs, layer_outputs: list of (b, some_num_patches_z, some_num_patches_y, some_num_patches_x, dim)\n",
    "\n",
    "        encoded = rearrange(encoded, \"b nz ny nx d -> b d nz ny nx\")\n",
    "        # (b, dim, new_num_patches_z, new_num_patches_y, new_num_patches_x)\n",
    "\n",
    "        for i in range(len(stage_outputs)):\n",
    "            stage_outputs[i] = rearrange(stage_outputs[i], \"b nz ny nx d -> b d nz ny nx\")\n",
    "            # (b, dim, some_num_patches_z, some_num_patches_y, some_num_patches_x)\n",
    "\n",
    "        for i in range(len(layer_outputs)):\n",
    "            layer_outputs[i] = rearrange(layer_outputs[i], \"b nz ny nx d -> b d nz ny nx\")\n",
    "            # (b, dim, some_num_patches_z, some_num_patches_y, some_num_patches_x)\n",
    "\n",
    "        return encoded, stage_outputs, layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0membeddings\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mpos_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mencoder\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DEncoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mstages\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mpatch_merging\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchMerging\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m288\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m288\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m3\u001b[0m x \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mpatch_merging\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchMerging\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m864\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m864\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m972\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m324\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1296\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1296\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m324\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m972\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m324\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1296\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1296\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m324\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m324\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m324\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m324\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m324\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = populate_and_validate_config(\n",
    "    {\n",
    "        \"patch_size\": (1, 8, 8),\n",
    "        \"in_channels\": 1,\n",
    "        \"use_absolute_position_embeddings\": True,\n",
    "        \"learnable_absolute_position_embeddings\": False,\n",
    "        \"embed_spacing_info\": False,\n",
    "        \"image_size\": (32, 512, 512),\n",
    "        \"dim\": 36,\n",
    "        \"drop_prob\": 0.2,\n",
    "        \"stages\": [\n",
    "            {\n",
    "                \"patch_merging\": None,\n",
    "                \"depth\": 1,\n",
    "                \"num_heads\": 4,\n",
    "                \"intermediate_ratio\": 4,\n",
    "                \"layer_norm_eps\": 1e-6,\n",
    "                \"window_size\": (4, 4, 4),\n",
    "                \"use_relative_position_bias\": False,\n",
    "                \"attn_drop_prob\": 0.2,\n",
    "                \"proj_drop_prob\": 0.2,\n",
    "                \"mlp_drop_prob\": 0.2,\n",
    "            },\n",
    "            {\n",
    "                \"patch_merging\": {\n",
    "                    \"merge_window_size\": (2, 2, 2),\n",
    "                    \"out_dim_ratio\": 3,\n",
    "                },\n",
    "                \"depth\": 3,\n",
    "                \"num_heads\": 4,\n",
    "                \"intermediate_ratio\": 4,\n",
    "                \"layer_norm_eps\": 1e-6,\n",
    "                \"window_size\": (4, 4, 4),\n",
    "                \"use_relative_position_bias\": True,\n",
    "                \"attn_drop_prob\": 0.2,\n",
    "                \"proj_drop_prob\": 0.2,\n",
    "                \"mlp_drop_prob\": 0.2,\n",
    "            },\n",
    "            {\n",
    "                \"patch_merging\": {\n",
    "                    \"merge_window_size\": (2, 2, 2),\n",
    "                    \"out_dim_ratio\": 3,\n",
    "                },\n",
    "                \"depth\": 1,\n",
    "                \"num_heads\": 4,\n",
    "                \"intermediate_ratio\": 4,\n",
    "                \"layer_norm_eps\": 1e-6,\n",
    "                \"window_size\": (4, 4, 4),\n",
    "                \"use_relative_position_bias\": True,\n",
    "                \"attn_drop_prob\": 0.2,\n",
    "                \"proj_drop_prob\": 0.2,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "test = SwinV23DModel(test_config)\n",
    "display(test)\n",
    "o = test(\n",
    "    torch.randn(2, 1, 32, 512, 512),\n",
    "    torch.randn(2, 3),\n",
    ")\n",
    "display((o[0].shape, [x.shape for x in o[1]], [x.shape for x in o[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Image Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DReconstructionDecoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = config[\"in_channels\"]\n",
    "\n",
    "        dim = config[\"dim\"]\n",
    "        patch_size = config[\"patch_size\"]\n",
    "\n",
    "        out_dim = np.prod(patch_size) * self.in_channels\n",
    "        self.final_patch_size = patch_size\n",
    "\n",
    "        self.decoder = nn.Conv3d(dim, out_dim, kernel_size=1)\n",
    "\n",
    "    def forward(self, encodings: torch.Tensor):\n",
    "        # encodings: (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        decoded = self.decoder(encodings)\n",
    "        # (b, new_dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        decoded = rearrange(\n",
    "            decoded,\n",
    "            \"b (c pz py px) nz ny nx -> b c (nz pz) (ny py) (nx px)\",\n",
    "            c=self.in_channels,\n",
    "            pz=self.final_patch_size[0],\n",
    "            py=self.final_patch_size[1],\n",
    "            px=self.final_patch_size[2],\n",
    "        )\n",
    "        # (b, c, z, y, x)\n",
    "\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DReconstructionDecoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdecoder\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"dim\": 108,\n",
    "    \"patch_size\": (2, 16, 16),\n",
    "    \"in_channels\": 1,\n",
    "}\n",
    "\n",
    "test = SwinV23DReconstructionDecoder(test_config)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 108, 16, 32, 32)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DMIM(nn.Module):\n",
    "    def __init__(self, swin_config, decoder_config, mim_config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.swin_config = swin_config\n",
    "        self.decoder_config = decoder_config\n",
    "        self.mim_config = mim_config\n",
    "\n",
    "        self.swin = SwinV23DModel(swin_config)\n",
    "        self.decoder = SwinV23DReconstructionDecoder(decoder_config)\n",
    "\n",
    "        self.mask_token = nn.Parameter(torch.randn(1, swin_config[\"dim\"], 1, 1, 1))\n",
    "\n",
    "    def mask_image(self, pixel_values: torch.Tensor):\n",
    "        b = pixel_values.shape[0]\n",
    "\n",
    "        mask_ratio = self.mim_config[\"mask_ratio\"]\n",
    "        mask_grid_size = self.mim_config[\"mask_grid_size\"]\n",
    "        num_patches = np.prod(mask_grid_size)\n",
    "        mask_patches = []\n",
    "        for _ in range(b):\n",
    "            _mask_patches = torch.zeros(num_patches, dtype=torch.int8, device=pixel_values.device)\n",
    "            _mask_patches[: int(mask_ratio * num_patches)] = 1\n",
    "            _mask_patches = _mask_patches[torch.randperm(num_patches)]\n",
    "            _mask_patches = rearrange(\n",
    "                _mask_patches, \"(z y x) -> z y x\", z=mask_grid_size[0], y=mask_grid_size[1], x=mask_grid_size[2]\n",
    "            )\n",
    "            mask_patches.append(_mask_patches)\n",
    "        mask_patches: torch.Tensor = torch.stack(mask_patches, dim=0)\n",
    "\n",
    "        grid_size = tuple(\n",
    "            [size // patch for size, patch in zip(self.swin_config[\"image_size\"], self.swin_config[\"patch_size\"])]\n",
    "        )\n",
    "        assert all(\n",
    "            [x % y == 0 for x, y in zip(grid_size, mask_grid_size)]\n",
    "        ), \"Mask grid size must divide image grid size\"\n",
    "        mask_patches = repeat(\n",
    "            mask_patches,\n",
    "            \"b z y x -> b (z gz) (y gy) (x gx)\",\n",
    "            gz=grid_size[0] // mask_grid_size[0],\n",
    "            gy=grid_size[1] // mask_grid_size[1],\n",
    "            gx=grid_size[2] // mask_grid_size[2],\n",
    "        )\n",
    "\n",
    "        return mask_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DSimMIM(SwinV23DMIM, PyTorchModelHubMixin):\n",
    "    def __init__(self, swin_config, decoder_config, mim_config):\n",
    "        super().__init__(swin_config, decoder_config, mim_config)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_fn(pred: torch.Tensor, target: torch.Tensor, reduction=\"mean\"):\n",
    "        return nn.functional.l1_loss(pred, target, reduction=reduction)\n",
    "\n",
    "    def forward(self, pixel_values: torch.Tensor, spacings: torch.Tensor = None):\n",
    "        mask_patches = self.mask_image(pixel_values)\n",
    "\n",
    "        encodings, _, _ = self.swin(pixel_values, spacings, mask_patches, self.mask_token)\n",
    "\n",
    "        decoded = self.decoder(encodings)\n",
    "\n",
    "        loss = self.loss_fn(decoded, pixel_values, reduction=\"none\")\n",
    "        mask = repeat(\n",
    "            mask_patches,\n",
    "            \"b z y x -> b (z pz) (y py) (x px)\",\n",
    "            pz=self.swin_config[\"patch_size\"][0],\n",
    "            py=self.swin_config[\"patch_size\"][1],\n",
    "            px=self.swin_config[\"patch_size\"][2],\n",
    "        )\n",
    "        loss = (loss * mask).sum() / ((mask.sum() + 1e-5) * self.swin_config[\"in_channels\"])\n",
    "\n",
    "        return decoded, loss, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DSimMIM\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mswin\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0membeddings\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mpos_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mencoder\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DEncoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mstages\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m2\u001b[0m x \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mpatch_merging\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchMerging\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m288\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m288\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m6\u001b[0m x \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdecoder\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DReconstructionDecoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdecoder\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m4.8695\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDivBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"swin\": populate_and_validate_config(\n",
    "        {\n",
    "            \"dim\": 36,\n",
    "            \"patch_size\": (1, 8, 8),\n",
    "            \"in_channels\": 1,\n",
    "            \"use_absolute_position_embeddings\": True,\n",
    "            \"learnable_absolute_position_embeddings\": False,\n",
    "            \"embed_spacing_info\": False,\n",
    "            \"image_size\": (32, 512, 512),\n",
    "            \"stages\": [\n",
    "                {\n",
    "                    \"patch_merging\": None,\n",
    "                    \"depth\": 2,\n",
    "                    \"num_heads\": 4,\n",
    "                    \"intermediate_ratio\": 4,\n",
    "                    \"layer_norm_eps\": 1e-6,\n",
    "                    \"window_size\": (4, 4, 4),\n",
    "                    \"use_relative_position_bias\": False,\n",
    "                },\n",
    "                {\n",
    "                    \"patch_merging\": {\n",
    "                        \"merge_window_size\": (2, 2, 2),\n",
    "                        \"out_dim_ratio\": 3,\n",
    "                    },\n",
    "                    \"depth\": 6,\n",
    "                    \"num_heads\": 4,\n",
    "                    \"intermediate_ratio\": 4,\n",
    "                    \"layer_norm_eps\": 1e-6,\n",
    "                    \"window_size\": (4, 4, 4),\n",
    "                    \"use_relative_position_bias\": True,\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ),\n",
    "    \"mim\": {\n",
    "        \"mask_ratio\": 0.8,\n",
    "        \"mask_grid_size\": (8, 8, 8),\n",
    "    },\n",
    "}\n",
    "test_config[\"decoder\"] = {\n",
    "    \"dim\": test_config[\"swin\"][\"stages\"][-1][\"_out_dim\"],\n",
    "    \"patch_size\": test_config[\"swin\"][\"stages\"][-1][\"_out_patch_size\"],\n",
    "    \"in_channels\": test_config[\"swin\"][\"in_channels\"],\n",
    "}\n",
    "\n",
    "test = SwinV23DSimMIM(test_config[\"swin\"], test_config[\"decoder\"], test_config[\"mim\"])\n",
    "display(test)\n",
    "o = test(\n",
    "    torch.randn(2, 1, 32, 512, 512),\n",
    "    torch.randn(2, 3),\n",
    ")\n",
    "display((o[0].shape, o[1], o[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb3da6228c24f968909d73a02844a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='z', max=31), Output()), _dom_classes=('widget-interact',"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from neuro_utils.visualize import plot_scans\n",
    "\n",
    "plot_scans([o[0][0, 0].detach(), o[0][0, 0].detach() * (1 - o[2][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SwinV23DVAEMIM(SwinV23DMIM, PyTorchModelHubMixin):\n",
    "    def __init__(self, swin_config, decoder_config, mim_config):\n",
    "        super().__init__(swin_config, decoder_config, mim_config)\n",
    "\n",
    "        assert (decoder_config[\"beta\"] is None) is not (\n",
    "            decoder_config[\"beta_schedule\"] is None\n",
    "        ), \"Only one of beta or beta_schedule should be provided\"\n",
    "\n",
    "        if decoder_config[\"beta_schedule\"] is not None:\n",
    "            self.beta_schedule = decoder_config[\"beta_schedule\"]\n",
    "            self.beta_increment = (self.beta_schedule[2] - self.beta_schedule[1]) / self.beta_schedule[0]\n",
    "            self.beta = None\n",
    "        else:\n",
    "            self.beta = decoder_config[\"beta\"]\n",
    "            self.beta_schedule = None\n",
    "            self.beta_increment = None\n",
    "\n",
    "        self.mu_layer = nn.Conv3d(swin_config[\"stages\"][-1][\"_out_dim\"], decoder_config[\"dim\"], kernel_size=1)\n",
    "        self.logvar_layer = nn.Conv3d(swin_config[\"stages\"][-1][\"_out_dim\"], decoder_config[\"dim\"], kernel_size=1)\n",
    "\n",
    "    def get_beta(self):\n",
    "        # If fixed beta\n",
    "        if self.beta_schedule is None:\n",
    "            return self.beta\n",
    "\n",
    "        # Else there is a beta schedule\n",
    "        if self.beta is None:\n",
    "            # If first iteration\n",
    "            self.beta = self.beta_schedule[1]\n",
    "        else:\n",
    "            # Calculate new beta and return\n",
    "            self.beta = min(self.beta + self.beta_increment, self.beta_schedule[2])\n",
    "        return self.beta\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        return mu + torch.randn_like(logvar) * torch.exp(0.5 * logvar)\n",
    "\n",
    "    @staticmethod\n",
    "    def reconstruction_loss_fn(pred: torch.Tensor, target: torch.Tensor, loss_type: str = \"l2\", reduction=\"mean\"):\n",
    "        loss = ...\n",
    "        if loss_type == \"l2\":\n",
    "            loss = nn.functional.mse_loss(pred, target, reduction=reduction)\n",
    "        elif loss_type == \"l1\":\n",
    "            loss = nn.functional.l1_loss(pred, target, reduction=reduction)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Loss type {loss_type} not implemented\")\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def kl_divergence_loss_fn(mu: torch.Tensor, logvar: torch.Tensor):\n",
    "        return torch.mean(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: torch.Tensor,\n",
    "        spacings: torch.Tensor = None,\n",
    "        reconstruction_loss_type: str = \"l2\",\n",
    "    ):\n",
    "        mask_patches = self.mask_image(pixel_values)\n",
    "\n",
    "        encodings, _, _ = self.swin(pixel_values, spacings, mask_patches, self.mask_token)\n",
    "\n",
    "        mu = self.mu_layer(encodings)\n",
    "        logvar = self.logvar_layer(encodings)\n",
    "        kl_loss = self.kl_divergence_loss_fn(mu, logvar)\n",
    "\n",
    "        sampled = self.reparameterize(mu, logvar)\n",
    "        decoded = self.decoder(sampled)\n",
    "\n",
    "        reconstruction_loss = self.reconstruction_loss_fn(decoded, pixel_values, reconstruction_loss_type)\n",
    "\n",
    "        mask = repeat(\n",
    "            mask_patches,\n",
    "            \"b z y x -> b (z pz) (y py) (x px)\",\n",
    "            pz=self.swin_config[\"patch_size\"][0],\n",
    "            py=self.swin_config[\"patch_size\"][1],\n",
    "            px=self.swin_config[\"patch_size\"][2],\n",
    "        )\n",
    "\n",
    "        beta = self.get_beta()\n",
    "        loss = reconstruction_loss + beta * kl_loss\n",
    "\n",
    "        return decoded, loss, mask, [reconstruction_loss, kl_loss, beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mSwinV23DVAEMIM\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mswin\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0membeddings\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchEmbeddings\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m36\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mpos_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mencoder\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DEncoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mstages\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m2\u001b[0m x \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m36\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m36\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DStage\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mpatch_merging\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DPatchMerging\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m288\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m288\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m6\u001b[0m x \u001b[1;35mSwinV23DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "              \u001b[1m(\u001b[0msw_layer\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmhsa\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DMHSA\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mW_qkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m324\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mproj_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DLayerMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'none'\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdense2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m432\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m108\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "                  \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "                \u001b[1m(\u001b[0mlayernorm2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-06\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "              \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdecoder\u001b[1m)\u001b[0m: \u001b[1;35mSwinV23DReconstructionDecoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdecoder\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmu_layer\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlogvar_layer\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m108\u001b[0m, \u001b[1;36m108\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2730.4104\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mAddBackward0\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m32\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m512\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m17.5157\u001b[0m\u001b[39m, \u001b[0m\u001b[33mgrad_fn\u001b[0m\u001b[39m=<MseLossBackward0>\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m, \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m2712.8948\u001b[0m\u001b[39m, \u001b[0m\u001b[33mgrad_fn\u001b[0m\u001b[39m=<MeanBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"swin\": populate_and_validate_config(\n",
    "        {\n",
    "            \"dim\": 36,\n",
    "            \"patch_size\": (1, 8, 8),\n",
    "            \"in_channels\": 1,\n",
    "            \"use_absolute_position_embeddings\": True,\n",
    "            \"learnable_absolute_position_embeddings\": False,\n",
    "            \"embed_spacing_info\": False,\n",
    "            \"image_size\": (32, 512, 512),\n",
    "            \"stages\": [\n",
    "                {\n",
    "                    \"patch_merging\": None,\n",
    "                    \"depth\": 2,\n",
    "                    \"num_heads\": 4,\n",
    "                    \"intermediate_ratio\": 4,\n",
    "                    \"layer_norm_eps\": 1e-6,\n",
    "                    \"window_size\": (4, 4, 4),\n",
    "                    \"use_relative_position_bias\": False,\n",
    "                },\n",
    "                {\n",
    "                    \"patch_merging\": {\n",
    "                        \"merge_window_size\": (2, 2, 2),\n",
    "                        \"out_dim_ratio\": 3,\n",
    "                    },\n",
    "                    \"depth\": 6,\n",
    "                    \"num_heads\": 4,\n",
    "                    \"intermediate_ratio\": 4,\n",
    "                    \"layer_norm_eps\": 1e-6,\n",
    "                    \"window_size\": (4, 4, 4),\n",
    "                    \"use_relative_position_bias\": True,\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ),\n",
    "    \"mim\": {\n",
    "        \"mask_ratio\": 0.8,\n",
    "        \"mask_grid_size\": (8, 8, 8),\n",
    "    },\n",
    "}\n",
    "test_config[\"decoder\"] = {\n",
    "    \"dim\": test_config[\"swin\"][\"stages\"][-1][\"_out_dim\"],\n",
    "    \"patch_size\": test_config[\"swin\"][\"stages\"][-1][\"_out_patch_size\"],\n",
    "    \"in_channels\": test_config[\"swin\"][\"in_channels\"],\n",
    "    \"beta\": 1,\n",
    "    \"beta_schedule\": None,\n",
    "}\n",
    "\n",
    "test = SwinV23DVAEMIM(test_config[\"swin\"], test_config[\"decoder\"], test_config[\"mim\"])\n",
    "display(test)\n",
    "o = test(\n",
    "    torch.randn(2, 1, 32, 512, 512),\n",
    "    torch.randn(2, 3),\n",
    ")\n",
    "display((o[0].shape, o[1], o[2].shape, o[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some more tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m1183892\u001b[0m, \u001b[1;36m197632\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "sample_spacings = torch.tensor([[1, 0.1, 0.1], [2, 0.2, 0.2], [3, 0.3, 0.3], [4, 0.4, 0.4], [5, 0.5, 0.5]])\n",
    "sample_batch = torch.rand(3, 1, 16, 128, 128)\n",
    "sample_config = {\n",
    "    \"swin\": populate_and_validate_config(\n",
    "        {\n",
    "            \"patch_size\": (1, 4, 4),\n",
    "            \"dim\": 12,\n",
    "            \"in_channels\": 1,\n",
    "            \"use_absolute_position_embeddings\": True,\n",
    "            \"learnable_absolute_position_embeddings\": False,\n",
    "            \"embed_spacing_info\": False,\n",
    "            \"image_size\": (16, 128, 128),\n",
    "            \"drop_prob\": 0.2,\n",
    "            \"stages\": [\n",
    "                {\n",
    "                    \"patch_merging\": None,\n",
    "                    \"depth\": 1,\n",
    "                    \"num_heads\": 4,\n",
    "                    \"intermediate_ratio\": 4,\n",
    "                    \"layer_norm_eps\": 1e-6,\n",
    "                    \"window_size\": (4, 4, 4),\n",
    "                    \"use_relative_position_bias\": True,\n",
    "                    \"attn_drop_prob\": 0.2,\n",
    "                    \"proj_drop_prob\": 0.2,\n",
    "                    \"mlp_drop_prob\": 0.2,\n",
    "                },\n",
    "                {\n",
    "                    \"patch_merging\": {\n",
    "                        \"merge_window_size\": (2, 2, 2),\n",
    "                        \"out_dim_ratio\": 4,\n",
    "                    },\n",
    "                    \"depth\": 3,\n",
    "                    \"num_heads\": 4,\n",
    "                    \"intermediate_ratio\": 4,\n",
    "                    \"layer_norm_eps\": 1e-6,\n",
    "                    \"window_size\": (4, 4, 4),\n",
    "                    \"use_relative_position_bias\": True,\n",
    "                },\n",
    "                {\n",
    "                    \"patch_merging\": {\n",
    "                        \"merge_window_size\": (2, 2, 2),\n",
    "                        \"out_dim_ratio\": 4,\n",
    "                    },\n",
    "                    \"depth\": 1,\n",
    "                    \"num_heads\": 4,\n",
    "                    \"intermediate_ratio\": 4,\n",
    "                    \"layer_norm_eps\": 1e-6,\n",
    "                    \"window_size\": (4, 4, 4),\n",
    "                    \"use_relative_position_bias\": True,\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ),\n",
    "    \"mim\": {\n",
    "        \"mask_ratio\": 0.7,\n",
    "        \"mask_grid_size\": (8, 8, 8),\n",
    "    },\n",
    "}\n",
    "sample_config[\"decoder\"] = {\n",
    "    \"dim\": sample_config[\"swin\"][\"stages\"][-1][\"_out_dim\"],\n",
    "    \"patch_size\": sample_config[\"swin\"][\"stages\"][-1][\"_out_patch_size\"],\n",
    "    \"in_channels\": sample_config[\"swin\"][\"in_channels\"],\n",
    "}\n",
    "\n",
    "model = SwinV23DSimMIM(sample_config[\"swin\"], sample_config[\"decoder\"], sample_config[\"mim\"])\n",
    "\n",
    "sum(x.numel() for x in model.swin.parameters()), sum(x.numel() for x in model.decoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 1,381,536\n",
      "+---------------------------------------------------------------+------------+\n",
      "|                             Module                            | Parameters |\n",
      "+---------------------------------------------------------------+------------+\n",
      "|                           mask_token                          |     12     |\n",
      "|    swin.embeddings.patch_embeddings.patch_embeddings.weight   |    192     |\n",
      "|     swin.embeddings.patch_embeddings.patch_embeddings.bias    |     12     |\n",
      "|               swin.embeddings.layer_norm.weight               |     12     |\n",
      "|                swin.embeddings.layer_norm.bias                |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mhsa.W_qkv.weight   |    432     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mhsa.W_qkv.bias    |     36     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mhsa.proj.weight    |    144     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mhsa.proj.bias     |     12     |\n",
      "|  swin.encoder.stages.0.blocks.0.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.0.blocks.0.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.0.blocks.0.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.layernorm1.weight   |     12     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.layernorm1.bias    |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mlp.dense1.weight   |    576     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mlp.dense1.bias    |     48     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mlp.dense2.weight   |    576     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mlp.dense2.bias    |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.layernorm2.weight   |     12     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.layernorm2.bias    |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.mhsa.W_qkv.weight   |    432     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mhsa.W_qkv.bias    |     36     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mhsa.proj.weight   |    144     |\n",
      "|     swin.encoder.stages.0.blocks.0.sw_layer.mhsa.proj.bias    |     12     |\n",
      "| swin.encoder.stages.0.blocks.0.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.0.blocks.0.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.0.blocks.0.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.layernorm1.weight   |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.layernorm1.bias    |     12     |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense1.weight   |    576     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense1.bias    |     48     |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense2.weight   |    576     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense2.bias    |     12     |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.layernorm2.weight   |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.layernorm2.bias    |     12     |\n",
      "|     swin.encoder.stages.1.patch_merging.layer_norm.weight     |     96     |\n",
      "|      swin.encoder.stages.1.patch_merging.layer_norm.bias      |     96     |\n",
      "|        swin.encoder.stages.1.patch_merging.proj.weight        |   4,608    |\n",
      "|         swin.encoder.stages.1.patch_merging.proj.bias         |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mhsa.proj.weight    |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mhsa.proj.bias     |     48     |\n",
      "|  swin.encoder.stages.1.blocks.0.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.1.blocks.0.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.1.blocks.0.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.layernorm1.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.layernorm1.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mlp.dense1.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mlp.dense1.bias    |    192     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mlp.dense2.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mlp.dense2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.layernorm2.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mhsa.proj.weight   |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.0.sw_layer.mhsa.proj.bias    |     48     |\n",
      "| swin.encoder.stages.1.blocks.0.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.1.blocks.0.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.1.blocks.0.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.layernorm1.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.layernorm1.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense1.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense1.bias    |    192     |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense2.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense2.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.layernorm2.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mhsa.proj.weight    |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mhsa.proj.bias     |     48     |\n",
      "|  swin.encoder.stages.1.blocks.1.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.1.blocks.1.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.1.blocks.1.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.layernorm1.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.layernorm1.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mlp.dense1.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mlp.dense1.bias    |    192     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mlp.dense2.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mlp.dense2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.layernorm2.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mhsa.proj.weight   |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.1.sw_layer.mhsa.proj.bias    |     48     |\n",
      "| swin.encoder.stages.1.blocks.1.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.1.blocks.1.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.1.blocks.1.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.layernorm1.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.layernorm1.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense1.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense1.bias    |    192     |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense2.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense2.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.layernorm2.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mhsa.proj.weight    |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mhsa.proj.bias     |     48     |\n",
      "|  swin.encoder.stages.1.blocks.2.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.1.blocks.2.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.1.blocks.2.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.layernorm1.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.layernorm1.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mlp.dense1.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mlp.dense1.bias    |    192     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mlp.dense2.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mlp.dense2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.layernorm2.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mhsa.proj.weight   |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.2.sw_layer.mhsa.proj.bias    |     48     |\n",
      "| swin.encoder.stages.1.blocks.2.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.1.blocks.2.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.1.blocks.2.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.layernorm1.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.layernorm1.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense1.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense1.bias    |    192     |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense2.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense2.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.layernorm2.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.layernorm2.bias    |     48     |\n",
      "|     swin.encoder.stages.2.patch_merging.layer_norm.weight     |    384     |\n",
      "|      swin.encoder.stages.2.patch_merging.layer_norm.bias      |    384     |\n",
      "|        swin.encoder.stages.2.patch_merging.proj.weight        |   73,728   |\n",
      "|         swin.encoder.stages.2.patch_merging.proj.bias         |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mhsa.W_qkv.weight   |  110,592   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mhsa.W_qkv.bias    |    576     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mhsa.proj.weight    |   36,864   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mhsa.proj.bias     |    192     |\n",
      "|  swin.encoder.stages.2.blocks.0.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.2.blocks.0.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.2.blocks.0.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.layernorm1.weight   |    192     |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.layernorm1.bias    |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mlp.dense1.weight   |  147,456   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mlp.dense1.bias    |    768     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mlp.dense2.weight   |  147,456   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mlp.dense2.bias    |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.layernorm2.weight   |    192     |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.layernorm2.bias    |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.mhsa.W_qkv.weight   |  110,592   |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mhsa.W_qkv.bias    |    576     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mhsa.proj.weight   |   36,864   |\n",
      "|     swin.encoder.stages.2.blocks.0.sw_layer.mhsa.proj.bias    |    192     |\n",
      "| swin.encoder.stages.2.blocks.0.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.2.blocks.0.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.2.blocks.0.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.layernorm1.weight   |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.layernorm1.bias    |    192     |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense1.weight   |  147,456   |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense1.bias    |    768     |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense2.weight   |  147,456   |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense2.bias    |    192     |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.layernorm2.weight   |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.layernorm2.bias    |    192     |\n",
      "|                     decoder.decoder.weight                    |  196,608   |\n",
      "|                      decoder.decoder.bias                     |   1,024    |\n",
      "+---------------------------------------------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from neuro_utils.describe import describe_model\n",
    "\n",
    "describe_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = sample_batch.cuda()\n",
    "sample_spacings = sample_spacings.cuda()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2682c72fe02428fa9538d5e9ed4577e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.373485\tLR: 0.500000\n",
      "Loss: 3.265403\tLR: 0.500000\n",
      "Loss: 5.286547\tLR: 0.500000\n",
      "Loss: 4.664566\tLR: 0.500000\n",
      "Loss: 3.819725\tLR: 0.500000\n",
      "Loss: 2.773649\tLR: 0.450000\n",
      "Loss: 2.197162\tLR: 0.450000\n",
      "Loss: 2.031960\tLR: 0.450000\n",
      "Loss: 1.988742\tLR: 0.450000\n",
      "Loss: 1.862298\tLR: 0.450000\n",
      "Loss: 1.673134\tLR: 0.405000\n",
      "Loss: 1.760884\tLR: 0.405000\n",
      "Loss: 1.624750\tLR: 0.405000\n",
      "Loss: 1.582400\tLR: 0.405000\n",
      "Loss: 1.467627\tLR: 0.405000\n",
      "Loss: 1.493500\tLR: 0.364500\n",
      "Loss: 1.285004\tLR: 0.364500\n",
      "Loss: 1.346008\tLR: 0.364500\n",
      "Loss: 1.431819\tLR: 0.364500\n",
      "Loss: 1.323951\tLR: 0.364500\n",
      "Loss: 1.394667\tLR: 0.328050\n",
      "Loss: 1.197774\tLR: 0.328050\n",
      "Loss: 1.364096\tLR: 0.328050\n",
      "Loss: 1.251438\tLR: 0.328050\n",
      "Loss: 1.352384\tLR: 0.328050\n",
      "Loss: 1.141207\tLR: 0.295245\n",
      "Loss: 1.200245\tLR: 0.295245\n",
      "Loss: 1.123198\tLR: 0.295245\n",
      "Loss: 1.205392\tLR: 0.295245\n",
      "Loss: 1.078262\tLR: 0.295245\n",
      "Loss: 1.198036\tLR: 0.265721\n",
      "Loss: 1.006277\tLR: 0.265721\n",
      "Loss: 1.083206\tLR: 0.265721\n",
      "Loss: 1.062278\tLR: 0.265721\n",
      "Loss: 1.055890\tLR: 0.265721\n",
      "Loss: 1.017003\tLR: 0.239148\n",
      "Loss: 0.959304\tLR: 0.239148\n",
      "Loss: 0.930668\tLR: 0.239148\n",
      "Loss: 0.923691\tLR: 0.239148\n",
      "Loss: 0.903056\tLR: 0.239148\n",
      "Loss: 0.897556\tLR: 0.215234\n",
      "Loss: 0.857589\tLR: 0.215234\n",
      "Loss: 0.852807\tLR: 0.215234\n",
      "Loss: 0.864291\tLR: 0.215234\n",
      "Loss: 0.867170\tLR: 0.215234\n",
      "Loss: 0.869897\tLR: 0.193710\n",
      "Loss: 0.814464\tLR: 0.193710\n",
      "Loss: 0.788329\tLR: 0.193710\n",
      "Loss: 0.771782\tLR: 0.193710\n",
      "Loss: 0.764566\tLR: 0.193710\n",
      "Loss: 0.759204\tLR: 0.174339\n",
      "Loss: 0.754195\tLR: 0.174339\n",
      "Loss: 0.751662\tLR: 0.174339\n",
      "Loss: 0.750585\tLR: 0.174339\n",
      "Loss: 0.750072\tLR: 0.174339\n",
      "Loss: 0.749521\tLR: 0.156905\n",
      "Loss: 0.749365\tLR: 0.156905\n",
      "Loss: 0.749827\tLR: 0.156905\n",
      "Loss: 0.749619\tLR: 0.156905\n",
      "Loss: 0.749593\tLR: 0.156905\n",
      "Loss: 0.749075\tLR: 0.141215\n",
      "Loss: 0.749490\tLR: 0.141215\n",
      "Loss: 0.749487\tLR: 0.141215\n",
      "Loss: 0.749410\tLR: 0.141215\n",
      "Loss: 0.749575\tLR: 0.141215\n",
      "Loss: 0.749591\tLR: 0.127093\n",
      "Loss: 0.749692\tLR: 0.127093\n",
      "Loss: 0.749030\tLR: 0.127093\n",
      "Loss: 0.749331\tLR: 0.127093\n",
      "Loss: 0.749171\tLR: 0.127093\n",
      "Loss: 0.749486\tLR: 0.114384\n",
      "Loss: 0.749278\tLR: 0.114384\n",
      "Loss: 0.749523\tLR: 0.114384\n",
      "Loss: 0.749172\tLR: 0.114384\n",
      "Loss: 0.749533\tLR: 0.114384\n",
      "Loss: 0.749586\tLR: 0.102946\n",
      "Loss: 0.749446\tLR: 0.102946\n",
      "Loss: 0.749338\tLR: 0.102946\n",
      "Loss: 0.749281\tLR: 0.102946\n",
      "Loss: 0.749542\tLR: 0.102946\n",
      "Loss: 0.749604\tLR: 0.092651\n",
      "Loss: 0.749482\tLR: 0.092651\n",
      "Loss: 0.749405\tLR: 0.092651\n",
      "Loss: 0.749471\tLR: 0.092651\n",
      "Loss: 0.749801\tLR: 0.092651\n",
      "Loss: 0.749282\tLR: 0.083386\n",
      "Loss: 0.749503\tLR: 0.083386\n",
      "Loss: 0.749159\tLR: 0.083386\n",
      "Loss: 0.749246\tLR: 0.083386\n",
      "Loss: 0.749547\tLR: 0.083386\n",
      "Loss: 0.749198\tLR: 0.075047\n",
      "Loss: 0.749370\tLR: 0.075047\n",
      "Loss: 0.749262\tLR: 0.075047\n",
      "Loss: 0.749259\tLR: 0.075047\n",
      "Loss: 0.749468\tLR: 0.075047\n",
      "Loss: 0.749442\tLR: 0.067543\n",
      "Loss: 0.749360\tLR: 0.067543\n",
      "Loss: 0.749493\tLR: 0.067543\n",
      "Loss: 0.749309\tLR: 0.067543\n",
      "Loss: 0.749445\tLR: 0.067543\n",
      "Loss: 0.749791\tLR: 0.060788\n",
      "Loss: 0.749623\tLR: 0.060788\n",
      "Loss: 0.749243\tLR: 0.060788\n",
      "Loss: 0.749629\tLR: 0.060788\n",
      "Loss: 0.749743\tLR: 0.060788\n",
      "Loss: 0.749405\tLR: 0.054709\n",
      "Loss: 0.749518\tLR: 0.054709\n",
      "Loss: 0.749432\tLR: 0.054709\n",
      "Loss: 0.749210\tLR: 0.054709\n",
      "Loss: 0.749556\tLR: 0.054709\n",
      "Loss: 0.749378\tLR: 0.049239\n",
      "Loss: 0.749707\tLR: 0.049239\n",
      "Loss: 0.749199\tLR: 0.049239\n",
      "Loss: 0.749441\tLR: 0.049239\n",
      "Loss: 0.749432\tLR: 0.049239\n",
      "Loss: 0.749283\tLR: 0.044315\n",
      "Loss: 0.749393\tLR: 0.044315\n",
      "Loss: 0.749469\tLR: 0.044315\n",
      "Loss: 0.749480\tLR: 0.044315\n",
      "Loss: 0.749223\tLR: 0.044315\n",
      "Loss: 0.749229\tLR: 0.039883\n",
      "Loss: 0.749279\tLR: 0.039883\n",
      "Loss: 0.749699\tLR: 0.039883\n",
      "Loss: 0.749383\tLR: 0.039883\n",
      "Loss: 0.749311\tLR: 0.039883\n",
      "Loss: 0.749534\tLR: 0.035895\n",
      "Loss: 0.749525\tLR: 0.035895\n",
      "Loss: 0.749515\tLR: 0.035895\n",
      "Loss: 0.749276\tLR: 0.035895\n",
      "Loss: 0.749242\tLR: 0.035895\n",
      "Loss: 0.749487\tLR: 0.032305\n",
      "Loss: 0.749725\tLR: 0.032305\n",
      "Loss: 0.749378\tLR: 0.032305\n",
      "Loss: 0.749568\tLR: 0.032305\n",
      "Loss: 0.749333\tLR: 0.032305\n",
      "Loss: 0.749416\tLR: 0.029075\n",
      "Loss: 0.749655\tLR: 0.029075\n",
      "Loss: 0.749536\tLR: 0.029075\n",
      "Loss: 0.749445\tLR: 0.029075\n",
      "Loss: 0.749433\tLR: 0.029075\n",
      "Loss: 0.749143\tLR: 0.026167\n",
      "Loss: 0.749296\tLR: 0.026167\n",
      "Loss: 0.749355\tLR: 0.026167\n",
      "Loss: 0.749245\tLR: 0.026167\n",
      "Loss: 0.749309\tLR: 0.026167\n",
      "Loss: 0.749464\tLR: 0.023551\n",
      "Loss: 0.749203\tLR: 0.023551\n",
      "Loss: 0.749219\tLR: 0.023551\n",
      "Loss: 0.749289\tLR: 0.023551\n",
      "Loss: 0.749458\tLR: 0.023551\n",
      "Loss: 0.749378\tLR: 0.021196\n",
      "Loss: 0.749330\tLR: 0.021196\n",
      "Loss: 0.749370\tLR: 0.021196\n",
      "Loss: 0.749442\tLR: 0.021196\n",
      "Loss: 0.749250\tLR: 0.021196\n",
      "Loss: 0.749473\tLR: 0.019076\n",
      "Loss: 0.749152\tLR: 0.019076\n",
      "Loss: 0.749542\tLR: 0.019076\n",
      "Loss: 0.749351\tLR: 0.019076\n",
      "Loss: 0.749511\tLR: 0.019076\n",
      "Loss: 0.749263\tLR: 0.017168\n",
      "Loss: 0.749292\tLR: 0.017168\n",
      "Loss: 0.748979\tLR: 0.017168\n",
      "Loss: 0.749657\tLR: 0.017168\n",
      "Loss: 0.749011\tLR: 0.017168\n",
      "Loss: 0.749704\tLR: 0.015452\n",
      "Loss: 0.749057\tLR: 0.015452\n",
      "Loss: 0.749967\tLR: 0.015452\n",
      "Loss: 0.749468\tLR: 0.015452\n",
      "Loss: 0.749143\tLR: 0.015452\n",
      "Loss: 0.749375\tLR: 0.013906\n",
      "Loss: 0.749359\tLR: 0.013906\n",
      "Loss: 0.749430\tLR: 0.013906\n",
      "Loss: 0.749186\tLR: 0.013906\n",
      "Loss: 0.749187\tLR: 0.013906\n",
      "Loss: 0.749548\tLR: 0.012516\n",
      "Loss: 0.749314\tLR: 0.012516\n",
      "Loss: 0.749434\tLR: 0.012516\n",
      "Loss: 0.749712\tLR: 0.012516\n",
      "Loss: 0.749246\tLR: 0.012516\n",
      "Loss: 0.749697\tLR: 0.011264\n",
      "Loss: 0.749407\tLR: 0.011264\n",
      "Loss: 0.749415\tLR: 0.011264\n",
      "Loss: 0.749259\tLR: 0.011264\n",
      "Loss: 0.749288\tLR: 0.011264\n",
      "Loss: 0.749735\tLR: 0.010138\n",
      "Loss: 0.749467\tLR: 0.010138\n",
      "Loss: 0.749045\tLR: 0.010138\n",
      "Loss: 0.749367\tLR: 0.010138\n",
      "Loss: 0.749050\tLR: 0.010138\n",
      "Loss: 0.749247\tLR: 0.009124\n",
      "Loss: 0.749588\tLR: 0.009124\n",
      "Loss: 0.749362\tLR: 0.009124\n",
      "Loss: 0.749323\tLR: 0.009124\n",
      "Loss: 0.749217\tLR: 0.009124\n",
      "Loss: 0.749317\tLR: 0.008212\n",
      "Loss: 0.749283\tLR: 0.008212\n",
      "Loss: 0.749624\tLR: 0.008212\n",
      "Loss: 0.749289\tLR: 0.008212\n",
      "Loss: 0.749644\tLR: 0.008212\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(200)):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(sample_batch, sample_spacings)\n",
    "    print(f\"Loss: {output[1]:f}\\tLR: {scheduler.get_last_lr()[0]:f}\")\n",
    "    output[1].backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.grad is None:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m1183892\u001b[0m, \u001b[1;36m197632\u001b[0m, \u001b[1;36m74112\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_config[\"decoder\"][\"beta\"] = None\n",
    "sample_config[\"decoder\"][\"beta_schedule\"] = (100, 0.0, 2.0)\n",
    "\n",
    "model = SwinV23DVAEMIM(sample_config[\"swin\"], sample_config[\"decoder\"], sample_config[\"mim\"])\n",
    "\n",
    "encoder_params = sum(x.numel() for x in model.swin.parameters())\n",
    "decoder_params = sum(x.numel() for x in model.decoder.parameters())\n",
    "sampling_params = sum(x.numel() for x in model.mu_layer.parameters()) + sum(\n",
    "    x.numel() for x in model.logvar_layer.parameters()\n",
    ")\n",
    "encoder_params, decoder_params, sampling_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 1,455,648\n",
      "+---------------------------------------------------------------+------------+\n",
      "|                             Module                            | Parameters |\n",
      "+---------------------------------------------------------------+------------+\n",
      "|                           mask_token                          |     12     |\n",
      "|    swin.embeddings.patch_embeddings.patch_embeddings.weight   |    192     |\n",
      "|     swin.embeddings.patch_embeddings.patch_embeddings.bias    |     12     |\n",
      "|               swin.embeddings.layer_norm.weight               |     12     |\n",
      "|                swin.embeddings.layer_norm.bias                |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mhsa.W_qkv.weight   |    432     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mhsa.W_qkv.bias    |     36     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mhsa.proj.weight    |    144     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mhsa.proj.bias     |     12     |\n",
      "|  swin.encoder.stages.0.blocks.0.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.0.blocks.0.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.0.blocks.0.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.layernorm1.weight   |     12     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.layernorm1.bias    |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mlp.dense1.weight   |    576     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mlp.dense1.bias    |     48     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.mlp.dense2.weight   |    576     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.mlp.dense2.bias    |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.w_layer.layernorm2.weight   |     12     |\n",
      "|     swin.encoder.stages.0.blocks.0.w_layer.layernorm2.bias    |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.mhsa.W_qkv.weight   |    432     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mhsa.W_qkv.bias    |     36     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mhsa.proj.weight   |    144     |\n",
      "|     swin.encoder.stages.0.blocks.0.sw_layer.mhsa.proj.bias    |     12     |\n",
      "| swin.encoder.stages.0.blocks.0.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.0.blocks.0.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.0.blocks.0.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.layernorm1.weight   |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.layernorm1.bias    |     12     |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense1.weight   |    576     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense1.bias    |     48     |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense2.weight   |    576     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.mlp.dense2.bias    |     12     |\n",
      "|   swin.encoder.stages.0.blocks.0.sw_layer.layernorm2.weight   |     12     |\n",
      "|    swin.encoder.stages.0.blocks.0.sw_layer.layernorm2.bias    |     12     |\n",
      "|     swin.encoder.stages.1.patch_merging.layer_norm.weight     |     96     |\n",
      "|      swin.encoder.stages.1.patch_merging.layer_norm.bias      |     96     |\n",
      "|        swin.encoder.stages.1.patch_merging.proj.weight        |   4,608    |\n",
      "|         swin.encoder.stages.1.patch_merging.proj.bias         |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mhsa.proj.weight    |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mhsa.proj.bias     |     48     |\n",
      "|  swin.encoder.stages.1.blocks.0.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.1.blocks.0.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.1.blocks.0.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.layernorm1.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.layernorm1.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mlp.dense1.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mlp.dense1.bias    |    192     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.mlp.dense2.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.mlp.dense2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.w_layer.layernorm2.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.0.w_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mhsa.proj.weight   |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.0.sw_layer.mhsa.proj.bias    |     48     |\n",
      "| swin.encoder.stages.1.blocks.0.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.1.blocks.0.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.1.blocks.0.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.layernorm1.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.layernorm1.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense1.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense1.bias    |    192     |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense2.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.mlp.dense2.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.0.sw_layer.layernorm2.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.0.sw_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mhsa.proj.weight    |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mhsa.proj.bias     |     48     |\n",
      "|  swin.encoder.stages.1.blocks.1.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.1.blocks.1.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.1.blocks.1.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.layernorm1.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.layernorm1.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mlp.dense1.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mlp.dense1.bias    |    192     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.mlp.dense2.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.mlp.dense2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.w_layer.layernorm2.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.1.w_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mhsa.proj.weight   |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.1.sw_layer.mhsa.proj.bias    |     48     |\n",
      "| swin.encoder.stages.1.blocks.1.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.1.blocks.1.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.1.blocks.1.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.layernorm1.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.layernorm1.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense1.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense1.bias    |    192     |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense2.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.mlp.dense2.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.1.sw_layer.layernorm2.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.1.sw_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mhsa.proj.weight    |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mhsa.proj.bias     |     48     |\n",
      "|  swin.encoder.stages.1.blocks.2.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.1.blocks.2.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.1.blocks.2.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.layernorm1.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.layernorm1.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mlp.dense1.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mlp.dense1.bias    |    192     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.mlp.dense2.weight   |   9,216    |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.mlp.dense2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.w_layer.layernorm2.weight   |     48     |\n",
      "|     swin.encoder.stages.1.blocks.2.w_layer.layernorm2.bias    |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.mhsa.W_qkv.weight   |   6,912    |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mhsa.W_qkv.bias    |    144     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mhsa.proj.weight   |   2,304    |\n",
      "|     swin.encoder.stages.1.blocks.2.sw_layer.mhsa.proj.bias    |     48     |\n",
      "| swin.encoder.stages.1.blocks.2.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.1.blocks.2.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.1.blocks.2.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.layernorm1.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.layernorm1.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense1.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense1.bias    |    192     |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense2.weight   |   9,216    |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.mlp.dense2.bias    |     48     |\n",
      "|   swin.encoder.stages.1.blocks.2.sw_layer.layernorm2.weight   |     48     |\n",
      "|    swin.encoder.stages.1.blocks.2.sw_layer.layernorm2.bias    |     48     |\n",
      "|     swin.encoder.stages.2.patch_merging.layer_norm.weight     |    384     |\n",
      "|      swin.encoder.stages.2.patch_merging.layer_norm.bias      |    384     |\n",
      "|        swin.encoder.stages.2.patch_merging.proj.weight        |   73,728   |\n",
      "|         swin.encoder.stages.2.patch_merging.proj.bias         |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mhsa.logit_scale    |     4      |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mhsa.W_qkv.weight   |  110,592   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mhsa.W_qkv.bias    |    576     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mhsa.proj.weight    |   36,864   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mhsa.proj.bias     |    192     |\n",
      "|  swin.encoder.stages.2.blocks.0.w_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|   swin.encoder.stages.2.blocks.0.w_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "|  swin.encoder.stages.2.blocks.0.w_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.layernorm1.weight   |    192     |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.layernorm1.bias    |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mlp.dense1.weight   |  147,456   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mlp.dense1.bias    |    768     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.mlp.dense2.weight   |  147,456   |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.mlp.dense2.bias    |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.w_layer.layernorm2.weight   |    192     |\n",
      "|     swin.encoder.stages.2.blocks.0.w_layer.layernorm2.bias    |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mhsa.logit_scale   |     4      |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.mhsa.W_qkv.weight   |  110,592   |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mhsa.W_qkv.bias    |    576     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mhsa.proj.weight   |   36,864   |\n",
      "|     swin.encoder.stages.2.blocks.0.sw_layer.mhsa.proj.bias    |    192     |\n",
      "| swin.encoder.stages.2.blocks.0.sw_layer.mhsa.cpb_mlp.0.weight |   1,536    |\n",
      "|  swin.encoder.stages.2.blocks.0.sw_layer.mhsa.cpb_mlp.0.bias  |    512     |\n",
      "| swin.encoder.stages.2.blocks.0.sw_layer.mhsa.cpb_mlp.2.weight |   2,048    |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.layernorm1.weight   |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.layernorm1.bias    |    192     |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense1.weight   |  147,456   |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense1.bias    |    768     |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense2.weight   |  147,456   |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.mlp.dense2.bias    |    192     |\n",
      "|   swin.encoder.stages.2.blocks.0.sw_layer.layernorm2.weight   |    192     |\n",
      "|    swin.encoder.stages.2.blocks.0.sw_layer.layernorm2.bias    |    192     |\n",
      "|                     decoder.decoder.weight                    |  196,608   |\n",
      "|                      decoder.decoder.bias                     |   1,024    |\n",
      "|                        mu_layer.weight                        |   36,864   |\n",
      "|                         mu_layer.bias                         |    192     |\n",
      "|                      logvar_layer.weight                      |   36,864   |\n",
      "|                       logvar_layer.bias                       |    192     |\n",
      "+---------------------------------------------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "describe_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = sample_batch.cuda()\n",
    "sample_spacings = sample_spacings.cuda()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94241c61a7d048a4b9ac5d2804211acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.456338\tLR: 0.001000\tBeta: 0.000000\n",
      "Loss: 5.215645\tLR: 0.001000\tBeta: 0.020000\n",
      "Loss: 6.410508\tLR: 0.001000\tBeta: 0.040000\n",
      "Loss: 13.061232\tLR: 0.001000\tBeta: 0.060000\n",
      "Loss: 11.995522\tLR: 0.001000\tBeta: 0.080000\n",
      "Loss: 14.299932\tLR: 0.000900\tBeta: 0.100000\n",
      "Loss: 10.443936\tLR: 0.000900\tBeta: 0.120000\n",
      "Loss: 7.685822\tLR: 0.000900\tBeta: 0.140000\n",
      "Loss: 11.613286\tLR: 0.000900\tBeta: 0.160000\n",
      "Loss: 17.467367\tLR: 0.000900\tBeta: 0.180000\n",
      "Loss: 13.522301\tLR: 0.000810\tBeta: 0.200000\n",
      "Loss: 5.320558\tLR: 0.000810\tBeta: 0.220000\n",
      "Loss: 3.899948\tLR: 0.000810\tBeta: 0.240000\n",
      "Loss: 3.748618\tLR: 0.000810\tBeta: 0.260000\n",
      "Loss: 4.591671\tLR: 0.000810\tBeta: 0.280000\n",
      "Loss: 7.079453\tLR: 0.000729\tBeta: 0.300000\n",
      "Loss: 9.702607\tLR: 0.000729\tBeta: 0.320000\n",
      "Loss: 11.484289\tLR: 0.000729\tBeta: 0.340000\n",
      "Loss: 12.137519\tLR: 0.000729\tBeta: 0.360000\n",
      "Loss: 12.625584\tLR: 0.000729\tBeta: 0.380000\n",
      "Loss: 9.555960\tLR: 0.000656\tBeta: 0.400000\n",
      "Loss: 6.450995\tLR: 0.000656\tBeta: 0.420000\n",
      "Loss: 4.102845\tLR: 0.000656\tBeta: 0.440000\n",
      "Loss: 3.875857\tLR: 0.000656\tBeta: 0.460000\n",
      "Loss: 4.368300\tLR: 0.000656\tBeta: 0.480000\n",
      "Loss: 6.119079\tLR: 0.000590\tBeta: 0.500000\n",
      "Loss: 7.034772\tLR: 0.000590\tBeta: 0.520000\n",
      "Loss: 8.205009\tLR: 0.000590\tBeta: 0.540000\n",
      "Loss: 8.819866\tLR: 0.000590\tBeta: 0.560000\n",
      "Loss: 8.984061\tLR: 0.000590\tBeta: 0.580000\n",
      "Loss: 8.432966\tLR: 0.000531\tBeta: 0.600000\n",
      "Loss: 6.099067\tLR: 0.000531\tBeta: 0.620000\n",
      "Loss: 5.491862\tLR: 0.000531\tBeta: 0.640000\n",
      "Loss: 5.888125\tLR: 0.000531\tBeta: 0.660000\n",
      "Loss: 7.613251\tLR: 0.000531\tBeta: 0.680000\n",
      "Loss: 9.978857\tLR: 0.000478\tBeta: 0.700000\n",
      "Loss: 9.390270\tLR: 0.000478\tBeta: 0.720000\n",
      "Loss: 8.093465\tLR: 0.000478\tBeta: 0.740000\n",
      "Loss: 6.826412\tLR: 0.000478\tBeta: 0.760000\n",
      "Loss: 6.308676\tLR: 0.000478\tBeta: 0.780000\n",
      "Loss: 6.077952\tLR: 0.000430\tBeta: 0.800000\n",
      "Loss: 4.837397\tLR: 0.000430\tBeta: 0.820000\n",
      "Loss: 4.353650\tLR: 0.000430\tBeta: 0.840000\n",
      "Loss: 4.280376\tLR: 0.000430\tBeta: 0.860000\n",
      "Loss: 4.482715\tLR: 0.000430\tBeta: 0.880000\n",
      "Loss: 4.942758\tLR: 0.000387\tBeta: 0.900000\n",
      "Loss: 4.155562\tLR: 0.000387\tBeta: 0.920000\n",
      "Loss: 3.682183\tLR: 0.000387\tBeta: 0.940000\n",
      "Loss: 3.320535\tLR: 0.000387\tBeta: 0.960000\n",
      "Loss: 3.178161\tLR: 0.000387\tBeta: 0.980000\n",
      "Loss: 3.118664\tLR: 0.000349\tBeta: 1.000000\n",
      "Loss: 2.659067\tLR: 0.000349\tBeta: 1.020000\n",
      "Loss: 2.376703\tLR: 0.000349\tBeta: 1.040000\n",
      "Loss: 2.281175\tLR: 0.000349\tBeta: 1.060000\n",
      "Loss: 2.253439\tLR: 0.000349\tBeta: 1.080000\n",
      "Loss: 2.343875\tLR: 0.000314\tBeta: 1.100000\n",
      "Loss: 2.173085\tLR: 0.000314\tBeta: 1.120000\n",
      "Loss: 2.059931\tLR: 0.000314\tBeta: 1.140000\n",
      "Loss: 2.031968\tLR: 0.000314\tBeta: 1.160000\n",
      "Loss: 2.057204\tLR: 0.000314\tBeta: 1.180000\n",
      "Loss: 2.124100\tLR: 0.000282\tBeta: 1.200000\n",
      "Loss: 1.979870\tLR: 0.000282\tBeta: 1.220000\n",
      "Loss: 1.906707\tLR: 0.000282\tBeta: 1.240000\n",
      "Loss: 1.862398\tLR: 0.000282\tBeta: 1.260000\n",
      "Loss: 1.854458\tLR: 0.000282\tBeta: 1.280000\n",
      "Loss: 1.884300\tLR: 0.000254\tBeta: 1.300000\n",
      "Loss: 1.757032\tLR: 0.000254\tBeta: 1.320000\n",
      "Loss: 1.668933\tLR: 0.000254\tBeta: 1.340000\n",
      "Loss: 1.625413\tLR: 0.000254\tBeta: 1.360000\n",
      "Loss: 1.601229\tLR: 0.000254\tBeta: 1.380000\n",
      "Loss: 1.583902\tLR: 0.000229\tBeta: 1.400000\n",
      "Loss: 1.543078\tLR: 0.000229\tBeta: 1.420000\n",
      "Loss: 1.501028\tLR: 0.000229\tBeta: 1.440000\n",
      "Loss: 1.486697\tLR: 0.000229\tBeta: 1.460000\n",
      "Loss: 1.477721\tLR: 0.000229\tBeta: 1.480000\n",
      "Loss: 1.477106\tLR: 0.000206\tBeta: 1.500000\n",
      "Loss: 1.449894\tLR: 0.000206\tBeta: 1.520000\n",
      "Loss: 1.441072\tLR: 0.000206\tBeta: 1.540000\n",
      "Loss: 1.446708\tLR: 0.000206\tBeta: 1.560000\n",
      "Loss: 1.446985\tLR: 0.000206\tBeta: 1.580000\n",
      "Loss: 1.453198\tLR: 0.000185\tBeta: 1.600000\n",
      "Loss: 1.446345\tLR: 0.000185\tBeta: 1.620000\n",
      "Loss: 1.446307\tLR: 0.000185\tBeta: 1.640000\n",
      "Loss: 1.451544\tLR: 0.000185\tBeta: 1.660000\n",
      "Loss: 1.461847\tLR: 0.000185\tBeta: 1.680000\n",
      "Loss: 1.456540\tLR: 0.000167\tBeta: 1.700000\n",
      "Loss: 1.461142\tLR: 0.000167\tBeta: 1.720000\n",
      "Loss: 1.459703\tLR: 0.000167\tBeta: 1.740000\n",
      "Loss: 1.464839\tLR: 0.000167\tBeta: 1.760000\n",
      "Loss: 1.467637\tLR: 0.000167\tBeta: 1.780000\n",
      "Loss: 1.468940\tLR: 0.000150\tBeta: 1.800000\n",
      "Loss: 1.480203\tLR: 0.000150\tBeta: 1.820000\n",
      "Loss: 1.483019\tLR: 0.000150\tBeta: 1.840000\n",
      "Loss: 1.484835\tLR: 0.000150\tBeta: 1.860000\n",
      "Loss: 1.483522\tLR: 0.000150\tBeta: 1.880000\n",
      "Loss: 1.494711\tLR: 0.000135\tBeta: 1.900000\n",
      "Loss: 1.500134\tLR: 0.000135\tBeta: 1.920000\n",
      "Loss: 1.485718\tLR: 0.000135\tBeta: 1.940000\n",
      "Loss: 1.493325\tLR: 0.000135\tBeta: 1.960000\n",
      "Loss: 1.493128\tLR: 0.000135\tBeta: 1.980000\n",
      "Loss: 1.505473\tLR: 0.000122\tBeta: 2.000000\n",
      "Loss: 1.502500\tLR: 0.000122\tBeta: 2.000000\n",
      "Loss: 1.490745\tLR: 0.000122\tBeta: 2.000000\n",
      "Loss: 1.492182\tLR: 0.000122\tBeta: 2.000000\n",
      "Loss: 1.484444\tLR: 0.000122\tBeta: 2.000000\n",
      "Loss: 1.478843\tLR: 0.000109\tBeta: 2.000000\n",
      "Loss: 1.480991\tLR: 0.000109\tBeta: 2.000000\n",
      "Loss: 1.476414\tLR: 0.000109\tBeta: 2.000000\n",
      "Loss: 1.461670\tLR: 0.000109\tBeta: 2.000000\n",
      "Loss: 1.472885\tLR: 0.000109\tBeta: 2.000000\n",
      "Loss: 1.464616\tLR: 0.000098\tBeta: 2.000000\n",
      "Loss: 1.462012\tLR: 0.000098\tBeta: 2.000000\n",
      "Loss: 1.445235\tLR: 0.000098\tBeta: 2.000000\n",
      "Loss: 1.444072\tLR: 0.000098\tBeta: 2.000000\n",
      "Loss: 1.450373\tLR: 0.000098\tBeta: 2.000000\n",
      "Loss: 1.436856\tLR: 0.000089\tBeta: 2.000000\n",
      "Loss: 1.445365\tLR: 0.000089\tBeta: 2.000000\n",
      "Loss: 1.435290\tLR: 0.000089\tBeta: 2.000000\n",
      "Loss: 1.441448\tLR: 0.000089\tBeta: 2.000000\n",
      "Loss: 1.421397\tLR: 0.000089\tBeta: 2.000000\n",
      "Loss: 1.428126\tLR: 0.000080\tBeta: 2.000000\n",
      "Loss: 1.425262\tLR: 0.000080\tBeta: 2.000000\n",
      "Loss: 1.419136\tLR: 0.000080\tBeta: 2.000000\n",
      "Loss: 1.425215\tLR: 0.000080\tBeta: 2.000000\n",
      "Loss: 1.418907\tLR: 0.000080\tBeta: 2.000000\n",
      "Loss: 1.418907\tLR: 0.000072\tBeta: 2.000000\n",
      "Loss: 1.420000\tLR: 0.000072\tBeta: 2.000000\n",
      "Loss: 1.419087\tLR: 0.000072\tBeta: 2.000000\n",
      "Loss: 1.403476\tLR: 0.000072\tBeta: 2.000000\n",
      "Loss: 1.412471\tLR: 0.000072\tBeta: 2.000000\n",
      "Loss: 1.410676\tLR: 0.000065\tBeta: 2.000000\n",
      "Loss: 1.414210\tLR: 0.000065\tBeta: 2.000000\n",
      "Loss: 1.411113\tLR: 0.000065\tBeta: 2.000000\n",
      "Loss: 1.406151\tLR: 0.000065\tBeta: 2.000000\n",
      "Loss: 1.406649\tLR: 0.000065\tBeta: 2.000000\n",
      "Loss: 1.398352\tLR: 0.000058\tBeta: 2.000000\n",
      "Loss: 1.407185\tLR: 0.000058\tBeta: 2.000000\n",
      "Loss: 1.402286\tLR: 0.000058\tBeta: 2.000000\n",
      "Loss: 1.390513\tLR: 0.000058\tBeta: 2.000000\n",
      "Loss: 1.396549\tLR: 0.000058\tBeta: 2.000000\n",
      "Loss: 1.398512\tLR: 0.000052\tBeta: 2.000000\n",
      "Loss: 1.385880\tLR: 0.000052\tBeta: 2.000000\n",
      "Loss: 1.395901\tLR: 0.000052\tBeta: 2.000000\n",
      "Loss: 1.398605\tLR: 0.000052\tBeta: 2.000000\n",
      "Loss: 1.388972\tLR: 0.000052\tBeta: 2.000000\n",
      "Loss: 1.388330\tLR: 0.000047\tBeta: 2.000000\n",
      "Loss: 1.389586\tLR: 0.000047\tBeta: 2.000000\n",
      "Loss: 1.383128\tLR: 0.000047\tBeta: 2.000000\n",
      "Loss: 1.381031\tLR: 0.000047\tBeta: 2.000000\n",
      "Loss: 1.389186\tLR: 0.000047\tBeta: 2.000000\n",
      "Loss: 1.383649\tLR: 0.000042\tBeta: 2.000000\n",
      "Loss: 1.382138\tLR: 0.000042\tBeta: 2.000000\n",
      "Loss: 1.370786\tLR: 0.000042\tBeta: 2.000000\n",
      "Loss: 1.374874\tLR: 0.000042\tBeta: 2.000000\n",
      "Loss: 1.382962\tLR: 0.000042\tBeta: 2.000000\n",
      "Loss: 1.375688\tLR: 0.000038\tBeta: 2.000000\n",
      "Loss: 1.385629\tLR: 0.000038\tBeta: 2.000000\n",
      "Loss: 1.369216\tLR: 0.000038\tBeta: 2.000000\n",
      "Loss: 1.371493\tLR: 0.000038\tBeta: 2.000000\n",
      "Loss: 1.385978\tLR: 0.000038\tBeta: 2.000000\n",
      "Loss: 1.377892\tLR: 0.000034\tBeta: 2.000000\n",
      "Loss: 1.371526\tLR: 0.000034\tBeta: 2.000000\n",
      "Loss: 1.370916\tLR: 0.000034\tBeta: 2.000000\n",
      "Loss: 1.361960\tLR: 0.000034\tBeta: 2.000000\n",
      "Loss: 1.378137\tLR: 0.000034\tBeta: 2.000000\n",
      "Loss: 1.367162\tLR: 0.000031\tBeta: 2.000000\n",
      "Loss: 1.355642\tLR: 0.000031\tBeta: 2.000000\n",
      "Loss: 1.354812\tLR: 0.000031\tBeta: 2.000000\n",
      "Loss: 1.365016\tLR: 0.000031\tBeta: 2.000000\n",
      "Loss: 1.362092\tLR: 0.000031\tBeta: 2.000000\n",
      "Loss: 1.363545\tLR: 0.000028\tBeta: 2.000000\n",
      "Loss: 1.363437\tLR: 0.000028\tBeta: 2.000000\n",
      "Loss: 1.356798\tLR: 0.000028\tBeta: 2.000000\n",
      "Loss: 1.365751\tLR: 0.000028\tBeta: 2.000000\n",
      "Loss: 1.360948\tLR: 0.000028\tBeta: 2.000000\n",
      "Loss: 1.365409\tLR: 0.000025\tBeta: 2.000000\n",
      "Loss: 1.350569\tLR: 0.000025\tBeta: 2.000000\n",
      "Loss: 1.354595\tLR: 0.000025\tBeta: 2.000000\n",
      "Loss: 1.364710\tLR: 0.000025\tBeta: 2.000000\n",
      "Loss: 1.355812\tLR: 0.000025\tBeta: 2.000000\n",
      "Loss: 1.357666\tLR: 0.000023\tBeta: 2.000000\n",
      "Loss: 1.362666\tLR: 0.000023\tBeta: 2.000000\n",
      "Loss: 1.355135\tLR: 0.000023\tBeta: 2.000000\n",
      "Loss: 1.359733\tLR: 0.000023\tBeta: 2.000000\n",
      "Loss: 1.361629\tLR: 0.000023\tBeta: 2.000000\n",
      "Loss: 1.363628\tLR: 0.000020\tBeta: 2.000000\n",
      "Loss: 1.359203\tLR: 0.000020\tBeta: 2.000000\n",
      "Loss: 1.357392\tLR: 0.000020\tBeta: 2.000000\n",
      "Loss: 1.349901\tLR: 0.000020\tBeta: 2.000000\n",
      "Loss: 1.358808\tLR: 0.000020\tBeta: 2.000000\n",
      "Loss: 1.351160\tLR: 0.000018\tBeta: 2.000000\n",
      "Loss: 1.351652\tLR: 0.000018\tBeta: 2.000000\n",
      "Loss: 1.351984\tLR: 0.000018\tBeta: 2.000000\n",
      "Loss: 1.359528\tLR: 0.000018\tBeta: 2.000000\n",
      "Loss: 1.357382\tLR: 0.000018\tBeta: 2.000000\n",
      "Loss: 1.347397\tLR: 0.000016\tBeta: 2.000000\n",
      "Loss: 1.342614\tLR: 0.000016\tBeta: 2.000000\n",
      "Loss: 1.344516\tLR: 0.000016\tBeta: 2.000000\n",
      "Loss: 1.346360\tLR: 0.000016\tBeta: 2.000000\n",
      "Loss: 1.354375\tLR: 0.000016\tBeta: 2.000000\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(200)):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(sample_batch, sample_spacings)\n",
    "    print(f\"Loss: {output[1]:f}\\tLR: {scheduler.get_last_lr()[0]:f}\\tBeta: {output[3][2]:f}\")\n",
    "    # print(output[-1])\n",
    "    output[1].backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.grad is None:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough work"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "coords_h = torch.arange(4)\n",
    "coords_w = torch.arange(4)\n",
    "coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing=\"ij\"))\n",
    "coords_flatten = torch.flatten(coords, 1)\n",
    "relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "relative_coords[:, :, 0] += 4 - 1\n",
    "relative_coords[:, :, 1] += 4 - 1\n",
    "relative_coords[:, :, 0] *= 2 * 4 - 1\n",
    "relative_position_index = relative_coords.sum(-1)\n",
    "\n",
    "relative_position_index.min(), relative_position_index.max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "window_size = (4, 4, 4)\n",
    "relative_limits = (7, 7, 7)\n",
    "\n",
    "coords = get_coords_grid(window_size)\n",
    "coords_flatten = rearrange(coords, \"three_dimensional d h w -> three_dimensional (d h w)\", three_dimensional=3)\n",
    "relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "relative_coords[:, :, 0] += window_size[0] - 1\n",
    "relative_coords[:, :, 1] += window_size[1] - 1\n",
    "relative_coords[:, :, 2] += window_size[2] - 1\n",
    "relative_position_index: torch.Tensor = (\n",
    "    relative_coords[:, :, 0] * relative_limits[1] * relative_limits[2]\n",
    "    + relative_coords[:, :, 1] * relative_limits[2]\n",
    "    + relative_coords[:, :, 2]\n",
    ")\n",
    "\n",
    "relative_position_index.min(), relative_position_index.max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "window_size = (2, 2, 2)\n",
    "relative_limits = (2 * window_size[0] - 1, 2 * window_size[1] - 1, 2 * window_size[2] - 1)\n",
    "\n",
    "relative_coords_table = get_coords_grid(relative_limits)\n",
    "relative_coords_table[0] -= window_size[0] - 1\n",
    "relative_coords_table[1] -= window_size[1] - 1\n",
    "relative_coords_table[2] -= window_size[2] - 1\n",
    "relative_coords_table = relative_coords_table.permute(1, 2, 3, 0).contiguous()\n",
    "relative_coords_table[0, 2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
