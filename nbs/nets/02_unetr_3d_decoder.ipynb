{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp nets/unetr_3d_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from torch import nn\n",
    "\n",
    "from vision_architectures.blocks.cnn import CNNBlock3D\n",
    "from vision_architectures.docstrings import populate_docstring\n",
    "from vision_architectures.utils.custom_base_model import CustomBaseModel, Field, model_validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "KernelSizeType = int | tuple[int, int, int]\n",
    "\n",
    "\n",
    "class UNetR3DDecoderConfig(CustomBaseModel):\n",
    "    num_outputs: int = Field(..., description=\"The number of output channels\")\n",
    "    conv_kernel_size: KernelSizeType = Field(..., description=\"The kernel size of the convolution layers\")\n",
    "    final_layer_kernel_size: KernelSizeType = Field(..., description=\"The kernel size of the final layer\")\n",
    "\n",
    "\n",
    "class UNetR3DStageConfig(CustomBaseModel):\n",
    "    in_dim: int = Field(..., description=\"The number of input channels\")\n",
    "    out_dim: int = Field(..., description=\"The number of output channels\")\n",
    "    in_patch_size: tuple[int, int, int] = Field(..., description=\"The patch size of the input\")\n",
    "    out_patch_size: tuple[int, int, int] = Field(..., description=\"The patch size of the output\")\n",
    "\n",
    "\n",
    "class UNetR3DConfig(CustomBaseModel):\n",
    "    in_channels: int = Field(..., description=\"The number of input channels\")\n",
    "\n",
    "    decoder: UNetR3DDecoderConfig = Field(..., description=\"The decoder configuration\")\n",
    "    stages: list[UNetR3DStageConfig] = Field(..., description=\"The stage configurations\")\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate(self):\n",
    "        out_dim = None\n",
    "        out_patch_size = None\n",
    "        for stage in self.stages:\n",
    "            if out_dim is not None:\n",
    "                assert stage.in_dim == out_dim, \"in_dim of each stage should match the out_stage of the previous stage\"\n",
    "                assert (\n",
    "                    stage.in_patch_size == out_patch_size\n",
    "                ), \"in_patch_size of each stage should match the out_patch_size of the previous stage\"\n",
    "            out_dim = stage.out_dim\n",
    "            out_patch_size = stage.out_patch_size\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mUNetR3DConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33min_channels\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
       "    \u001b[33mdecoder\u001b[0m=\u001b[1;35mUNetR3DDecoderConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mnum_outputs\u001b[0m=\u001b[1;36m5\u001b[0m,\n",
       "        \u001b[33mconv_kernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33mfinal_layer_kernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mstages\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mUNetR3DStageConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_dim\u001b[0m=\u001b[1;36m12\u001b[0m, \u001b[33mout_dim\u001b[0m=\u001b[1;36m12\u001b[0m, \u001b[33min_patch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mout_patch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mUNetR3DStageConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_dim\u001b[0m=\u001b[1;36m12\u001b[0m, \u001b[33mout_dim\u001b[0m=\u001b[1;36m48\u001b[0m, \u001b[33min_patch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mout_patch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mUNetR3DStageConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33min_dim\u001b[0m=\u001b[1;36m48\u001b[0m,\n",
       "            \u001b[33mout_dim\u001b[0m=\u001b[1;36m192\u001b[0m,\n",
       "            \u001b[33min_patch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mout_patch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mUNetR3DStageConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33min_dim\u001b[0m=\u001b[1;36m192\u001b[0m,\n",
       "            \u001b[33mout_dim\u001b[0m=\u001b[1;36m768\u001b[0m,\n",
       "            \u001b[33min_patch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mout_patch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_config = UNetR3DConfig.model_validate(\n",
    "    {\n",
    "        \"in_channels\": 1,\n",
    "        \"decoder\": {\n",
    "            \"conv_kernel_size\": (3, 3, 3),\n",
    "            \"final_layer_kernel_size\": (5, 5, 5),\n",
    "            \"num_outputs\": 5,\n",
    "        },\n",
    "        \"stages\": [\n",
    "            {\n",
    "                \"in_dim\": 12,\n",
    "                \"in_patch_size\": (1, 4, 4),\n",
    "                \"out_dim\": 12,\n",
    "                \"out_patch_size\": (1, 4, 4),\n",
    "            },\n",
    "            {\n",
    "                \"in_dim\": 12,\n",
    "                \"in_patch_size\": (1, 4, 4),\n",
    "                \"out_dim\": 48,\n",
    "                \"out_patch_size\": (2, 8, 8),\n",
    "            },\n",
    "            {\n",
    "                \"in_dim\": 48,\n",
    "                \"in_patch_size\": (2, 8, 8),\n",
    "                \"out_dim\": 192,\n",
    "                \"out_patch_size\": (4, 16, 16),\n",
    "            },\n",
    "            {\n",
    "                \"in_dim\": 192,\n",
    "                \"in_patch_size\": (4, 16, 16),\n",
    "                \"out_dim\": 768,\n",
    "                \"out_patch_size\": (8, 32, 32),\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "test_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@populate_docstring\n",
    "class _UNetR3DBlock(nn.Module):\n",
    "    \"\"\"The conv and deconv layers that make up a UNetR3D block. {CLASS_DESCRIPTION_3D_DOC}\"\"\"\n",
    "\n",
    "    @populate_docstring\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        conv_kernel_size,\n",
    "        deconv_kernel_size,\n",
    "        is_first_layer: bool,\n",
    "        checkpointing_level: int = 0,\n",
    "    ):\n",
    "        \"\"\"Initialize the UNetR3DBlock.\n",
    "\n",
    "        Args:\n",
    "            in_dim: Input dimension of the block.\n",
    "            out_dim: Output dimension of the block.\n",
    "            conv_kernel_size: Kernel size for the convolution layer.\n",
    "            deconv_kernel_size: Kernel size for the deconvolution layer.\n",
    "            is_first_layer: Whether this is the first layer of the UNetR3D.\n",
    "            checkpointing_level: {CHECKPOINTING_LEVEL_DOC}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = CNNBlock3D(\n",
    "            in_channels=in_dim,\n",
    "            out_channels=in_dim,\n",
    "            kernel_size=conv_kernel_size,\n",
    "            stride=1,\n",
    "            padding=tuple([k // 2 for k in conv_kernel_size]),\n",
    "            normalization=\"batchnorm3d\",\n",
    "            activation=\"relu\",\n",
    "            sequence=\"CNA\",\n",
    "            checkpointing_level=checkpointing_level,\n",
    "        )\n",
    "        if not is_first_layer:\n",
    "            in_dim = in_dim * 2\n",
    "        self.deconv = CNNBlock3D(\n",
    "            in_channels=in_dim,\n",
    "            out_channels=out_dim,\n",
    "            transposed=True,\n",
    "            kernel_size=deconv_kernel_size,\n",
    "            stride=deconv_kernel_size,\n",
    "            padding=0,\n",
    "            normalization=\"batchnorm3d\",\n",
    "            activation=\"relu\",\n",
    "            sequence=\"CNA\",\n",
    "            checkpointing_level=checkpointing_level,\n",
    "        )\n",
    "\n",
    "    @populate_docstring\n",
    "    def forward(self, current_layer_output, previous_layer_output=None) -> torch.Tensor:\n",
    "        \"\"\"Process a single scale of the UNet.\n",
    "\n",
    "        Args:\n",
    "            current_layer_output: Current layer output.\n",
    "            previous_layer_output: Previous layer output.\n",
    "\n",
    "        Returns:\n",
    "            {OUTPUT_3D_DOC}\n",
    "        \"\"\"\n",
    "        x = self.conv(current_layer_output)\n",
    "        if previous_layer_output is not None:\n",
    "            x = torch.cat([x, previous_layer_output], dim=1)\n",
    "        x = self.deconv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35m_UNetR3DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mCNNBlock3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m, \u001b[1;36m768\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdeconv\u001b[1m)\u001b[0m: \u001b[1;35mCNNBlock3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConvTranspose3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m, \u001b[1;36m192\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m192\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m192\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = _UNetR3DBlock(768, 192, (3, 3, 3), (2, 2, 2), is_first_layer=True)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 768, 4, 8, 8)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35m_UNetR3DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mCNNBlock3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m192\u001b[0m, \u001b[1;36m192\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m192\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdeconv\u001b[1m)\u001b[0m: \u001b[1;35mCNNBlock3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConvTranspose3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m, \u001b[1;36m48\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m48\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m48\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = _UNetR3DBlock(192, 48, (3, 3, 3), (2, 2, 2), is_first_layer=False)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 192, 8, 16, 16), torch.randn(2, 192, 8, 16, 16)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@populate_docstring\n",
    "class UNetR3DDecoder(nn.Module, PyTorchModelHubMixin):\n",
    "    \"\"\"UNetR3DDecoder made using multiple conv and deconv blocks.\"\"\"\n",
    "\n",
    "    @populate_docstring\n",
    "    def __init__(self, config: UNetR3DConfig = {}, checkpointing_level: int = 0, **kwargs):\n",
    "        \"\"\"Initialize the UNetR3DDecoder.\n",
    "\n",
    "        Args:\n",
    "            config: {CONFIG_INSTANCE_DOC}\n",
    "            checkpointing_level: {CHECKPOINTING_LEVEL_DOC}\n",
    "            **kwargs: {CONFIG_KWARGS_DOC}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = UNetR3DConfig.model_validate(config | kwargs)\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for i in range(len(config.stages)):\n",
    "            stage = config.stages[-i - 1]\n",
    "\n",
    "            in_dim = stage.out_dim\n",
    "            is_first_layer = i == 0\n",
    "\n",
    "            if i == len(config.stages) - 1:\n",
    "                out_dim = config.in_channels\n",
    "                deconv_kernel_size = stage.out_patch_size\n",
    "            else:\n",
    "                out_dim = stage.in_dim\n",
    "                deconv_kernel_size = tuple([o // i for o, i in zip(stage.out_patch_size, stage.in_patch_size)])\n",
    "\n",
    "            self.blocks.append(\n",
    "                _UNetR3DBlock(\n",
    "                    in_dim=in_dim,\n",
    "                    out_dim=out_dim,\n",
    "                    conv_kernel_size=self.config.decoder.conv_kernel_size,\n",
    "                    deconv_kernel_size=deconv_kernel_size,\n",
    "                    is_first_layer=is_first_layer,\n",
    "                    checkpointing_level=checkpointing_level,\n",
    "                )\n",
    "            )\n",
    "        self.scan_conv = nn.Conv3d(\n",
    "            config.in_channels,\n",
    "            config.in_channels,\n",
    "            kernel_size=self.config.decoder.final_layer_kernel_size,\n",
    "            padding=tuple([k // 2 for k in self.config.decoder.final_layer_kernel_size]),\n",
    "        )\n",
    "        self.final_conv = nn.Conv3d(\n",
    "            config.in_channels * 2,\n",
    "            config.decoder.num_outputs,\n",
    "            kernel_size=self.config.decoder.final_layer_kernel_size,\n",
    "            padding=tuple([k // 2 for k in self.config.decoder.final_layer_kernel_size]),\n",
    "        )\n",
    "\n",
    "    @populate_docstring\n",
    "    def forward(self, embeddings, scan) -> torch.Tensor:\n",
    "        \"\"\"Process the multi-scale input embeddings and scan datapoint.\n",
    "\n",
    "        Args:\n",
    "            embeddings: {INPUT_3D_DOC}\n",
    "            scan: {INPUT_3D_DOC}\n",
    "\n",
    "        Returns:\n",
    "            {OUTPUT_3D_DOC}\n",
    "        \"\"\"\n",
    "        # embeddings is a list of (B, C_layer, D_layer, W_layer, H_layer)\n",
    "        embeddings = embeddings[::-1]\n",
    "\n",
    "        decoded = None\n",
    "        for i in range(len(embeddings)):\n",
    "            embedding = embeddings[i]\n",
    "            if i == 0:\n",
    "                decoded = self.blocks[i](embedding)\n",
    "            else:\n",
    "                decoded = self.blocks[i](embedding, decoded)\n",
    "\n",
    "        high_resolution_embeddings = self.scan_conv(scan)\n",
    "        final_embeddings = torch.cat([high_resolution_embeddings, decoded], dim=1)\n",
    "        decoded = self.final_conv(final_embeddings)\n",
    "\n",
    "        return decoded\n",
    "\n",
    "    @staticmethod\n",
    "    def _reduce(loss, reduction):\n",
    "        if reduction is None:\n",
    "            return loss\n",
    "        elif reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            raise NotImplementedError(\"Please implement the reduction type\")\n",
    "\n",
    "    @staticmethod\n",
    "    def soft_dice_loss_fn(\n",
    "        prediction: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        reduction=\"mean\",\n",
    "        ignore_index: int = -100,\n",
    "        smooth: float = 1e-5,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Both prediction and target should be of the form (batch_size, num_classes, depth, width, height).\n",
    "\n",
    "        prediction: probability scores for each class\n",
    "        target: should be binary masks.\n",
    "        \"\"\"\n",
    "\n",
    "        num_classes = prediction.shape[1]\n",
    "\n",
    "        prediction = rearrange(prediction, \"b n d h w -> b n (d h w)\").contiguous()\n",
    "        target = rearrange(target, \"b n d h w -> b n (d h w)\").contiguous()\n",
    "\n",
    "        if ignore_index is not None:\n",
    "            # Remove gradients of the predictions based on the target\n",
    "            mask = target != ignore_index\n",
    "            prediction = prediction * mask\n",
    "            target = target * mask\n",
    "\n",
    "        loss = 1 - (1 / num_classes) * (\n",
    "            (2 * (prediction * target).sum(dim=2) + smooth)\n",
    "            / ((prediction**2).sum(dim=2) + (target**2).sum(dim=2) + smooth)\n",
    "        ).sum(dim=1)\n",
    "        loss = UNetR3DDecoder._reduce(loss, reduction)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_loss_fn(\n",
    "        prediction: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        reduction=\"mean\",\n",
    "        ignore_index: int = -100,\n",
    "        smooth: float = 1e-5,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Both prediction and target should be of the form (batch_size, num_classes, depth, width, height).\n",
    "\n",
    "        prediction: probability scores for each class\n",
    "        target: should be binary masks.\n",
    "        \"\"\"\n",
    "\n",
    "        num_voxels = torch.prod(torch.tensor(prediction.shape[2:]))\n",
    "\n",
    "        prediction = rearrange(prediction, \"b n d h w -> b n (d h w)\").contiguous()\n",
    "        target = rearrange(target, \"b n d h w -> b n (d h w)\").contiguous()\n",
    "\n",
    "        if ignore_index is not None:\n",
    "            # Remove gradients of the predictions based on the target\n",
    "            mask = target != ignore_index\n",
    "            prediction = prediction * mask\n",
    "            target = target * mask\n",
    "\n",
    "        loss = -(1 / num_voxels) * (target * torch.log(prediction + smooth)).sum(dim=(1, 2))\n",
    "        loss = UNetR3DDecoder._reduce(loss, reduction)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_fn(\n",
    "        prediction: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        reduction=\"mean\",\n",
    "        weight_dsc=1.0,\n",
    "        weight_ce=1.0,\n",
    "        ignore_index=-100,\n",
    "        smooth: float = 1e-5,\n",
    "        return_components=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Both prediction and target should be of the form (batch_size, num_classes, depth, width, height).\n",
    "\n",
    "        prediction: probability scores for each class\n",
    "        target: should be binary masks.\n",
    "        \"\"\"\n",
    "\n",
    "        loss1 = UNetR3DDecoder.soft_dice_loss_fn(\n",
    "            prediction, target, reduction=None, ignore_index=ignore_index, smooth=smooth\n",
    "        )\n",
    "        loss2 = UNetR3DDecoder.cross_entropy_loss_fn(\n",
    "            prediction, target, reduction=None, ignore_index=ignore_index, smooth=smooth\n",
    "        )\n",
    "        loss = weight_dsc * loss1 + weight_ce * loss2\n",
    "\n",
    "        loss = UNetR3DDecoder._reduce(loss, reduction)\n",
    "\n",
    "        if return_components:\n",
    "            loss1 = UNetR3DDecoder._reduce(loss1, reduction)\n",
    "            loss2 = UNetR3DDecoder._reduce(loss2, reduction)\n",
    "            return loss, [loss1, loss2]\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mUNetR3DDecoder\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35m_UNetR3DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mCNNBlock3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m, \u001b[1;36m768\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdeconv\u001b[1m)\u001b[0m: \u001b[1;35mCNNBlock3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConvTranspose3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m, \u001b[1;36m192\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m192\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35m_UNetR3DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mCNNBlock3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m192\u001b[0m, \u001b[1;36m192\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m192\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdeconv\u001b[1m)\u001b[0m: \u001b[1;35mCNNBlock3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConvTranspose3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m, \u001b[1;36m48\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m48\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35m_UNetR3DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mCNNBlock3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m48\u001b[0m, \u001b[1;36m48\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m48\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdeconv\u001b[1m)\u001b[0m: \u001b[1;35mCNNBlock3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConvTranspose3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m96\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m12\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35m_UNetR3DBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mCNNBlock3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m12\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m12\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mdeconv\u001b[1m)\u001b[0m: \u001b[1;35mCNNBlock3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConvTranspose3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m24\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mscan_conv\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mfinal_conv\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m256\u001b[0m, \u001b[1;36m256\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = UNetR3DDecoder(test_config)\n",
    "display(test)\n",
    "o = test(\n",
    "    [\n",
    "        torch.randn(2, 12, 32, 64, 64),\n",
    "        torch.randn(2, 48, 16, 32, 32),\n",
    "        torch.randn(2, 192, 8, 16, 16),\n",
    "        torch.randn(2, 768, 4, 8, 8),\n",
    "    ],\n",
    "    torch.randn(2, 1, 32, 256, 256),\n",
    ")\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 32, 256, 256]) torch.Size([2, 5, 32, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m4.7840\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMeanBackward0\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0.6329\u001b[0m\u001b[39m, \u001b[0m\u001b[33mgrad_fn\u001b[0m\u001b[39m=<MeanBackward0>\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m, \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m4.1511\u001b[0m\u001b[39m, \u001b[0m\u001b[33mgrad_fn\u001b[0m\u001b[39m=<MeanBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.softmax(o, dim=1)\n",
    "gt = torch.randint(0, 2, pred.shape)\n",
    "\n",
    "print(pred.shape, gt.shape)\n",
    "test.loss_fn(pred, gt, return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 32, 256, 256]) torch.Size([2, 5, 32, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m., \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMeanBackward0\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m., \u001b[0m\u001b[33mgrad_fn\u001b[0m\u001b[39m=<MeanBackward0>\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m, \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m., \u001b[0m\u001b[33mgrad_fn\u001b[0m\u001b[39m=<MeanBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.softmax(o, dim=1)\n",
    "gt = torch.full(pred.shape, -100)\n",
    "\n",
    "print(pred.shape, gt.shape)\n",
    "test.loss_fn(pred, gt, return_components=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
