{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp nets/unetr_3d_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from torch import nn\n",
    "\n",
    "from vision_architectures.utils.custom_base_model import (\n",
    "    CustomBaseModel,\n",
    "    model_validator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "KernelSizeType = int | tuple[int, int, int]\n",
    "\n",
    "\n",
    "class UNetR3DDecoderConfig(CustomBaseModel):\n",
    "    num_outputs: int\n",
    "    conv_kernel_size: KernelSizeType\n",
    "    final_layer_kernel_size: KernelSizeType\n",
    "\n",
    "\n",
    "class UNetR3DStageConfig(CustomBaseModel):\n",
    "    in_dim: int\n",
    "    out_dim: int\n",
    "    in_patch_size: tuple[int, int, int]\n",
    "    out_patch_size: tuple[int, int, int]\n",
    "\n",
    "\n",
    "class UNetR3DConfig(CustomBaseModel):\n",
    "    in_channels: int\n",
    "\n",
    "    decoder: UNetR3DDecoderConfig\n",
    "    stages: list[UNetR3DStageConfig]\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate(self):\n",
    "        out_dim = None\n",
    "        out_patch_size = None\n",
    "        for stage in self.stages:\n",
    "            if out_dim is not None:\n",
    "                assert stage.in_dim == out_dim, \"in_dim of each stage should match the out_stage of the previous stage\"\n",
    "                assert (\n",
    "                    stage.in_patch_size == out_patch_size\n",
    "                ), \"in_patch_size of each stage should match the out_patch_size of the previous stage\"\n",
    "            out_dim = stage.out_dim\n",
    "            out_patch_size = stage.out_patch_size\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = UNetR3DConfig.model_validate(\n",
    "    {\n",
    "        \"in_channels\": 1,\n",
    "        \"decoder\": {\n",
    "            \"conv_kernel_size\": (3, 3, 3),\n",
    "            \"final_layer_kernel_size\": (5, 5, 5),\n",
    "            \"num_outputs\": 5,\n",
    "        },\n",
    "        \"stages\": [\n",
    "            {\n",
    "                \"in_dim\": 12,\n",
    "                \"in_patch_size\": (1, 4, 4),\n",
    "                \"out_dim\": 12,\n",
    "                \"out_patch_size\": (1, 4, 4),\n",
    "            },\n",
    "            {\n",
    "                \"in_dim\": 12,\n",
    "                \"in_patch_size\": (1, 4, 4),\n",
    "                \"out_dim\": 48,\n",
    "                \"out_patch_size\": (2, 8, 8),\n",
    "            },\n",
    "            {\n",
    "                \"in_dim\": 48,\n",
    "                \"in_patch_size\": (2, 8, 8),\n",
    "                \"out_dim\": 192,\n",
    "                \"out_patch_size\": (4, 16, 16),\n",
    "            },\n",
    "            {\n",
    "                \"in_dim\": 192,\n",
    "                \"in_patch_size\": (4, 16, 16),\n",
    "                \"out_dim\": 768,\n",
    "                \"out_patch_size\": (8, 32, 32),\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "test_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class UNetR3DConvBlock(nn.Module):\n",
    "    def __init__(self, dim, kernel_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv3d(\n",
    "            dim,\n",
    "            dim,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=tuple([k // 2 for k in kernel_size]),\n",
    "            bias=False,\n",
    "        )\n",
    "        self.batch_norm = nn.BatchNorm3d(dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class UNetR3DDeConvBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, kernel_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.deconv = nn.ConvTranspose3d(\n",
    "            in_dim,\n",
    "            out_dim,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=kernel_size,\n",
    "            padding=0,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.batch_norm = nn.BatchNorm3d(out_dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.deconv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class UNetR3DBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, conv_kernel_size, deconv_kernel_size, is_first_layer):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = UNetR3DConvBlock(in_dim, conv_kernel_size)\n",
    "        if not is_first_layer:\n",
    "            in_dim = in_dim * 2\n",
    "        self.deconv = UNetR3DDeConvBlock(in_dim, out_dim, deconv_kernel_size)\n",
    "\n",
    "    def forward(self, current_layer, previous_layer=None):\n",
    "        x = self.conv(current_layer)\n",
    "        if previous_layer is not None:\n",
    "            x = torch.cat([x, previous_layer], dim=1)\n",
    "        x = self.deconv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = UNetR3DBlock(768, 192, (3, 3, 3), (2, 2, 2), is_first_layer=True)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 768, 4, 8, 8)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = UNetR3DBlock(192, 48, (3, 3, 3), (2, 2, 2), is_first_layer=False)\n",
    "display(test)\n",
    "display(test(torch.randn(2, 192, 8, 16, 16), torch.randn(2, 192, 8, 16, 16)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class UNetR3DDecoder(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(self, config: UNetR3DConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        conv_kernel_size = config.decoder.conv_kernel_size\n",
    "        final_layer_kernel_size = config.decoder.final_layer_kernel_size\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for i in range(len(config.stages)):\n",
    "            stage = config.stages[-i - 1]\n",
    "\n",
    "            in_dim = stage.out_dim\n",
    "            is_first_layer = i == 0\n",
    "\n",
    "            if i == len(config.stages) - 1:\n",
    "                out_dim = config.in_channels\n",
    "                deconv_kernel_size = stage.out_patch_size\n",
    "            else:\n",
    "                out_dim = stage.in_dim\n",
    "                deconv_kernel_size = tuple([o // i for o, i in zip(stage.out_patch_size, stage.in_patch_size)])\n",
    "\n",
    "            self.blocks.append(\n",
    "                UNetR3DBlock(\n",
    "                    in_dim=in_dim,\n",
    "                    out_dim=out_dim,\n",
    "                    conv_kernel_size=conv_kernel_size,\n",
    "                    deconv_kernel_size=deconv_kernel_size,\n",
    "                    is_first_layer=is_first_layer,\n",
    "                )\n",
    "            )\n",
    "        self.scan_conv = nn.Conv3d(\n",
    "            config.in_channels,\n",
    "            config.in_channels,\n",
    "            kernel_size=final_layer_kernel_size,\n",
    "            padding=tuple([k // 2 for k in final_layer_kernel_size]),\n",
    "        )\n",
    "        self.final_conv = nn.Conv3d(\n",
    "            config.in_channels * 2,\n",
    "            config.decoder.num_outputs,\n",
    "            kernel_size=final_layer_kernel_size,\n",
    "            padding=tuple([k // 2 for k in final_layer_kernel_size]),\n",
    "        )\n",
    "\n",
    "    def forward(self, embeddings, scan):\n",
    "        # embeddings is a list of (B, C_layer, D_layer, W_layer, H_layer)\n",
    "        embeddings = embeddings[::-1]\n",
    "\n",
    "        decoded = None\n",
    "        for i in range(len(embeddings)):\n",
    "            embedding = embeddings[i]\n",
    "            if i == 0:\n",
    "                decoded = self.blocks[i](embedding)\n",
    "            else:\n",
    "                decoded = self.blocks[i](embedding, decoded)\n",
    "\n",
    "        high_resolution_embeddings = self.scan_conv(scan)\n",
    "        final_embeddings = torch.cat([high_resolution_embeddings, decoded], dim=1)\n",
    "        decoded = self.final_conv(final_embeddings)\n",
    "\n",
    "        return decoded\n",
    "\n",
    "    @staticmethod\n",
    "    def _reduce(loss, reduction):\n",
    "        if reduction is None:\n",
    "            return loss\n",
    "        elif reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            raise NotImplementedError(\"Please implement the reduction type\")\n",
    "\n",
    "    @staticmethod\n",
    "    def soft_dice_loss_fn(\n",
    "        prediction: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        reduction=\"mean\",\n",
    "        ignore_index: int = -100,\n",
    "        smooth: float = 1e-8,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Both prediction and target should be of the form (batch_size, num_classes, depth, width, height).\n",
    "\n",
    "        prediction: probability scores for each class\n",
    "        target: should be binary masks.\n",
    "        \"\"\"\n",
    "\n",
    "        num_classes = prediction.shape[1]\n",
    "\n",
    "        prediction = rearrange(prediction, \"b n d h w -> b n (d h w)\")\n",
    "        target = rearrange(target, \"b n d h w -> b n (d h w)\")\n",
    "\n",
    "        if ignore_index is not None:\n",
    "            # Remove gradients of the predictions based on the target\n",
    "            mask = target != ignore_index\n",
    "            prediction = prediction * mask\n",
    "            target = target * mask\n",
    "\n",
    "        loss = 1 - (1 / num_classes) * (\n",
    "            (2 * (prediction * target).sum(dim=2) + smooth)\n",
    "            / ((prediction**2).sum(dim=2) + (target**2).sum(dim=2) + smooth)\n",
    "        ).sum(dim=1)\n",
    "        loss = UNetR3DDecoder._reduce(loss, reduction)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_loss_fn(\n",
    "        prediction: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        reduction=\"mean\",\n",
    "        ignore_index: int = -100,\n",
    "        smooth: float = 1e-8,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Both prediction and target should be of the form (batch_size, num_classes, depth, width, height).\n",
    "\n",
    "        prediction: probability scores for each class\n",
    "        target: should be binary masks.\n",
    "        \"\"\"\n",
    "\n",
    "        num_voxels = torch.prod(torch.tensor(prediction.shape[2:]))\n",
    "\n",
    "        prediction = rearrange(prediction, \"b n d h w -> b n (d h w)\")\n",
    "        target = rearrange(target, \"b n d h w -> b n (d h w)\")\n",
    "\n",
    "        if ignore_index is not None:\n",
    "            # Remove gradients of the predictions based on the target\n",
    "            mask = target != ignore_index\n",
    "            prediction = prediction * mask\n",
    "            target = target * mask\n",
    "\n",
    "        loss = -(1 / num_voxels) * (target * torch.log(prediction + smooth)).sum(dim=(1, 2))\n",
    "        loss = UNetR3DDecoder._reduce(loss, reduction)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_fn(\n",
    "        prediction: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        reduction=\"mean\",\n",
    "        weight_dsc=1.0,\n",
    "        weight_ce=1.0,\n",
    "        ignore_index=-100,\n",
    "        smooth: float = 1e-8,\n",
    "        return_components=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Both prediction and target should be of the form (batch_size, num_classes, depth, width, height).\n",
    "\n",
    "        prediction: probability scores for each class\n",
    "        target: should be binary masks.\n",
    "        \"\"\"\n",
    "\n",
    "        loss1 = UNetR3DDecoder.soft_dice_loss_fn(\n",
    "            prediction, target, reduction=None, ignore_index=ignore_index, smooth=smooth\n",
    "        )\n",
    "        loss2 = UNetR3DDecoder.cross_entropy_loss_fn(\n",
    "            prediction, target, reduction=None, ignore_index=ignore_index, smooth=smooth\n",
    "        )\n",
    "        loss = weight_dsc * loss1 + weight_ce * loss2\n",
    "\n",
    "        loss = UNetR3DDecoder._reduce(loss, reduction)\n",
    "\n",
    "        if return_components:\n",
    "            loss1 = UNetR3DDecoder._reduce(loss1, reduction)\n",
    "            loss2 = UNetR3DDecoder._reduce(loss2, reduction)\n",
    "            return loss, [loss1, loss2]\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = UNetR3DDecoder(test_config)\n",
    "display(test)\n",
    "o = test(\n",
    "    [\n",
    "        torch.randn(2, 12, 32, 64, 64),\n",
    "        torch.randn(2, 48, 16, 32, 32),\n",
    "        torch.randn(2, 192, 8, 16, 16),\n",
    "        torch.randn(2, 768, 4, 8, 8),\n",
    "    ],\n",
    "    torch.randn(2, 1, 32, 256, 256),\n",
    ")\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.softmax(o, dim=1)\n",
    "gt = torch.randint(0, 2, pred.shape)\n",
    "\n",
    "print(pred.shape, gt.shape)\n",
    "test.loss_fn(pred, gt, return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.softmax(o, dim=1)\n",
    "gt = torch.full(pred.shape, -100)\n",
    "\n",
    "print(pred.shape, gt.shape)\n",
    "test.loss_fn(pred, gt, return_components=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
