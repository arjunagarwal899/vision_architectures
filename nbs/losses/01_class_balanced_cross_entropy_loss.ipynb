{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a7598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp losses/class_balanced_cross_entropy_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5958da",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd3d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from vision_architectures.docstrings import populate_docstring\n",
    "from vision_architectures.utils.custom_base_model import CustomBaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5c5524",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ClassBalancedCrossEntropyLossConfig(CustomBaseModel):\n",
    "    num_classes: int = Field(..., description=\"Number of classes to weight cross entropy loss.\")\n",
    "    ema_decay: float = Field(\n",
    "        0.99, description=\"Exponential moving average decay. By default 0.99 is used which has a half life of ~69 steps\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7d3d45",
   "metadata": {},
   "source": [
    "# The loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f20615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ClassBalancedCrossEntropyLoss(nn.Module):\n",
    "    @populate_docstring\n",
    "    def __init__(self, config: ClassBalancedCrossEntropyLossConfig = {}, **kwargs):\n",
    "        \"\"\"Class-balanced cross-entropy loss with running prevalence estimation.\n",
    "\n",
    "        This loss reweights the standard multi-class cross-entropy by the inverse of\n",
    "        the observed class prevalences in the training data. Class prevalences are\n",
    "        estimated online via an exponential moving average (EMA) using class counts\n",
    "        from the incoming targets.\n",
    "\n",
    "        Notes:\n",
    "            - Targets must be discrete integer class indices in [0, num_classes-1].\n",
    "              Probabilistic/soft labels are not supported.\n",
    "            - For classes that haven't been observed yet, their prevalence is treated\n",
    "              as NaN and replaced in the weight vector by the mean of observed weights\n",
    "              (then clamped within 3 standard deviations to avoid extreme values).\n",
    "\n",
    "        Args:\n",
    "            config: {CONFIG_INSTANCE_DOC}\n",
    "            **kwargs: {CONFIG_KWARGS_DOC}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = ClassBalancedCrossEntropyLossConfig.model_validate(config | kwargs)\n",
    "\n",
    "        # Save class prevalence percentages to weight the cross entropy loss\n",
    "        self.class_prevalences = [None] * self.config.num_classes\n",
    "        # Initialized with None as we don't know the initial class prevalence estimates.\n",
    "\n",
    "    def update_class_prevalences(self, target: torch.Tensor):\n",
    "        \"\"\"Update the running class-prevalence estimates from a target tensor.\n",
    "\n",
    "        The method counts class occurrences in the provided target, converts counts\n",
    "        to per-batch prevalences, then updates the internal EMA-tracked prevalence\n",
    "        vector for each class.\n",
    "\n",
    "        Args:\n",
    "            target: A tensor of integer class indices with any shape, typically\n",
    "                (N,) or (N, ...) for segmentation. Values outside\n",
    "                [0, num_classes-1] are ignored.\n",
    "        \"\"\"\n",
    "        # Count the number of times each class is encountered\n",
    "        class_counts = Counter(target.flatten().int().tolist())\n",
    "\n",
    "        # Remove those counts that exceed the number of classes that are being tracked\n",
    "        class_counts = {k: v for k, v in class_counts.items() if k < self.config.num_classes}\n",
    "\n",
    "        # Calculate prevalence of each class\n",
    "        total_count = sum(class_counts.values())\n",
    "        new_prevalences = (\n",
    "            {class_id: count / total_count for class_id, count in class_counts.items()} if total_count > 0 else {}\n",
    "        )\n",
    "\n",
    "        # Update current prevalences using EMA to allow for distribution shift in data\n",
    "        decay = self.config.ema_decay\n",
    "        for i in range(self.config.num_classes):\n",
    "            if self.class_prevalences[i] is None:\n",
    "                # if encountered for the first time\n",
    "                if new_prevalences.get(i, 0.0) > 0.0:\n",
    "                    self.class_prevalences[i] = new_prevalences.get(i, 0.0)\n",
    "                # otherwise let it stay None\n",
    "            else:\n",
    "                # update to new value using EMA\n",
    "                self.class_prevalences[i] = self.class_prevalences[i] * decay + new_prevalences.get(i, 0.0) * (\n",
    "                    1 - decay\n",
    "                )\n",
    "\n",
    "    def get_class_prevalences(self, device=torch.device(\"cpu\")) -> torch.Tensor:\n",
    "        \"\"\"Return the current vector of class prevalences as a tensor.\n",
    "\n",
    "        For classes that haven't been observed yet, the corresponding entry will be\n",
    "        NaN. This method does not perform any imputation or normalization beyond\n",
    "        returning the current EMA state.\n",
    "\n",
    "        Args:\n",
    "            device: The device on which to place the returned tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape (num_classes,) with dtype float32 containing per-class\n",
    "            prevalence estimates in [0, 1] or NaN for unseen classes.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get class prevalences and replace None with nan\n",
    "        class_prevalences = [\n",
    "            prevalence if prevalence is not None else torch.nan for prevalence in self.class_prevalences\n",
    "        ]\n",
    "\n",
    "        # Calculate weights as inverse of class prevalences\n",
    "        class_prevalences = torch.tensor(class_prevalences, dtype=torch.float32, device=device)\n",
    "\n",
    "        return class_prevalences\n",
    "\n",
    "    def get_class_weights(self, device=torch.device(\"cpu\")) -> torch.Tensor:\n",
    "        \"\"\"Compute per-class weights as the inverse of prevalences with safeguards.\n",
    "\n",
    "        Steps:\n",
    "            1) Convert current EMA prevalences to a tensor with NaNs for unseen classes.\n",
    "            2) Take the inverse to obtain raw weights (higher weight for rarer classes).\n",
    "            3) Replace NaNs by the mean of observed weights to avoid biasing toward\n",
    "               unseen classes, then clamp to mean ± 3·std to prevent extreme values.\n",
    "            4) Renormalize weights to sum to num_classes (so the average weight is 1).\n",
    "\n",
    "        Args:\n",
    "            device: The device on which to place the returned tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape (num_classes,) containing normalized class weights.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get class prevalences\n",
    "        class_prevalences = self.get_class_prevalences(device)\n",
    "\n",
    "        # If there were no class prevalences, then all weights will be nan; handle this\n",
    "        if class_prevalences.isnan().all():\n",
    "            class_prevalences = class_prevalences.nan_to_num(1.0)\n",
    "\n",
    "        # Calculate weights as inverse of class prevalences\n",
    "        weights = 1 / class_prevalences\n",
    "\n",
    "        # Substitute nan values with mean and clamp weights to a limit\n",
    "        # Assumption: all classes are visited at least once in the dataset\n",
    "        mu, std = weights.nanmean(), weights[~weights.isnan()].std()\n",
    "        weights = weights.nan_to_num(mu)\n",
    "        weights = weights.clamp(mu - 3 * std, mu + 3 * std)\n",
    "\n",
    "        # Add failsafe just in case nans are still present\n",
    "        weights = weights.nan_to_num(1.0)\n",
    "\n",
    "        # Normalize weights to sum to self.config.num_classes\n",
    "        weights = self.config.num_classes * weights / weights.sum()\n",
    "\n",
    "        return weights\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        update_class_prevalences: bool = True,\n",
    "        return_class_weights: bool = False,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor | tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Compute class-balanced cross entropy.\n",
    "\n",
    "        This updates the internal class-prevalence EMA using the provided targets,\n",
    "        then computes cross-entropy with a weight vector derived from the current\n",
    "        prevalences.\n",
    "\n",
    "        Args:\n",
    "            input: Logits of shape (N, C, ...) where C == num_classes. Any extra spatial\n",
    "                dimensions (e.g., H, W, D) are supported as long as `target` is broadcastable\n",
    "                to the same non-channel shape expected by torch.nn.functional.cross_entropy.\n",
    "            target: Integer class indices with shape matching input without the channel\n",
    "                dimension, e.g., (N, ...) with values in [0, C-1].\n",
    "            update_class_prevalences: If True, update the internal class prevalence estimates\n",
    "                using the provided targets.\n",
    "            return_class_weights: If True, also return the per-class weight tensor used\n",
    "                for this call.\n",
    "            *args, **kwargs: Additional keyword args forwarded to F.cross_entropy\n",
    "                (e.g., reduction='mean').\n",
    "\n",
    "        Returns:\n",
    "            If return_class_weights is False: a scalar tensor loss.\n",
    "            If True: a tuple (loss, class_weights).\n",
    "        \"\"\"\n",
    "        # Update class prevalences\n",
    "        if update_class_prevalences:\n",
    "            self.update_class_prevalences(target)\n",
    "\n",
    "        # Get class weights\n",
    "        class_weights = self.get_class_weights(input.device)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(input, target, weight=class_weights, *args, **kwargs)\n",
    "\n",
    "        if return_class_weights:\n",
    "            return loss, class_weights\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f3c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2635) tensor([1.2000, 0.6000, 1.2000])\n",
      "tensor(1.1835) tensor([1.1798, 0.6047, 1.2155])\n",
      "tensor(1.2358) tensor([1.1836, 0.6096, 1.2069])\n",
      "tensor(1.0405) tensor([1.1837, 0.6095, 1.2068])\n",
      "tensor(1.1366) tensor([1.1957, 0.6094, 1.1949])\n",
      "tensor(1.1001) tensor([1.2076, 0.6093, 1.1831])\n",
      "tensor(1.0922) tensor([1.2194, 0.6090, 1.1715])\n",
      "tensor(1.0698) tensor([1.2258, 0.6185, 1.1557])\n",
      "tensor(1.1738) tensor([1.2170, 0.6234, 1.1596])\n",
      "tensor(1.0539) tensor([1.2084, 0.6282, 1.1635])\n"
     ]
    }
   ],
   "source": [
    "# Regular test\n",
    "\n",
    "\n",
    "test = ClassBalancedCrossEntropyLoss(num_classes=3)\n",
    "\n",
    "for _ in range(10):\n",
    "    example_input = torch.rand(4, 3)\n",
    "    example_target = torch.randint(0, 3, (4,))\n",
    "    loss, class_weights = test(example_input, example_target, return_class_weights=True)\n",
    "    print(loss, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2986d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3756) tensor([1.2000, 0.6000, 1.2000, 1.0000, 1.0000])\n",
      "tensor(1.7763) tensor([1.2036, 0.6048, 1.1916, 1.0000, 1.0000])\n",
      "tensor(1.5222) tensor([1.2070, 0.6096, 1.1834, 1.0000, 1.0000])\n",
      "tensor(1.7942) tensor([1.2069, 0.6095, 1.1836, 1.0000, 1.0000])\n",
      "tensor(1.6321) tensor([1.2188, 0.6092, 1.1720, 1.0000, 1.0000])\n",
      "tensor(1.5927) tensor([1.2219, 0.6139, 1.1642, 1.0000, 1.0000])\n",
      "tensor(1.3780) tensor([1.2132, 0.6188, 1.1681, 1.0000, 1.0000])\n",
      "tensor(1.7535) tensor([1.2280, 0.6231, 1.1488, 1.0000, 1.0000])\n",
      "tensor(1.9232) tensor([1.2277, 0.6229, 1.1493, 1.0000, 1.0000])\n",
      "tensor(1.5832) tensor([1.2220, 0.6326, 1.1454, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# Test where last two classes are never encountered\n",
    "\n",
    "test = ClassBalancedCrossEntropyLoss(num_classes=5)\n",
    "\n",
    "for _ in range(10):\n",
    "    example_input = torch.rand(4, 5)\n",
    "    example_target = torch.randint(0, 3, (4,))\n",
    "    loss, class_weights = test(example_input, example_target, return_class_weights=True)\n",
    "    print(loss, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc71cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0290) tensor([1., 1., 1.])\n",
      "tensor(1.0518) tensor([1., 1., 1.])\n",
      "tensor(0.9804) tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Don't update prevalences\n",
    "\n",
    "test = ClassBalancedCrossEntropyLoss(num_classes=3)\n",
    "\n",
    "for _ in range(3):\n",
    "    example_input = torch.rand(4, 3)\n",
    "    example_target = torch.randint(0, 3, (4,))\n",
    "    loss, class_weights = test(example_input, example_target, update_class_prevalences=False, return_class_weights=True)\n",
    "    print(loss, class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f28624",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1089315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
