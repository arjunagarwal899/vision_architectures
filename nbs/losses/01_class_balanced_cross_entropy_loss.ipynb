{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a7598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp losses/class_balanced_cross_entropy_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5958da",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd3d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from vision_architectures.docstrings import populate_docstring\n",
    "from vision_architectures.utils.custom_base_model import CustomBaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5c5524",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ClassBalancedCrossEntropyLossConfig(CustomBaseModel):\n",
    "    num_classes: int = Field(..., description=\"Number of classes to weight cross entropy loss.\")\n",
    "    ema_decay: float = Field(\n",
    "        0.99, description=\"Exponential moving average decay. By default 0.99 is used which has a half life of ~69 steps\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7d3d45",
   "metadata": {},
   "source": [
    "# The loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f20615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ClassBalancedCrossEntropyLoss(nn.Module):\n",
    "    @populate_docstring\n",
    "    def __init__(self, config: ClassBalancedCrossEntropyLossConfig = {}, **kwargs):\n",
    "        \"\"\"Class-balanced cross-entropy loss with running prevalence estimation.\n",
    "\n",
    "        This loss reweights the standard multi-class cross-entropy by the inverse of\n",
    "        the observed class prevalences in the training data. Class prevalences are\n",
    "        estimated online via an exponential moving average (EMA) using class counts\n",
    "        from the incoming targets.\n",
    "\n",
    "        Notes:\n",
    "            - Targets must be discrete integer class indices in [0, num_classes-1].\n",
    "              Probabilistic/soft labels are not supported.\n",
    "            - For classes that haven't been observed yet, their prevalence is treated\n",
    "              as NaN and replaced in the weight vector by the mean of observed weights\n",
    "              (then clamped within 3 standard deviations to avoid extreme values).\n",
    "\n",
    "        Args:\n",
    "            config: {CONFIG_INSTANCE_DOC}\n",
    "            **kwargs: {CONFIG_KWARGS_DOC}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = ClassBalancedCrossEntropyLossConfig.model_validate(config | kwargs)\n",
    "\n",
    "        # Save class prevalence percentages to weight the cross entropy loss\n",
    "        self.class_prevalences = [None] * self.config.num_classes\n",
    "        # Initialized with None as we don't know the initial class prevalence estimates.\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_class_prevalences(self, target: torch.Tensor, ignore_index: int = -100):\n",
    "        \"\"\"Update the running class-prevalence estimates from a target tensor.\n",
    "\n",
    "        The method counts class occurrences in the provided target, converts counts\n",
    "        to per-batch prevalences, then updates the internal EMA-tracked prevalence\n",
    "        vector for each class.\n",
    "\n",
    "        Args:\n",
    "            target: A tensor of integer class indices with any shape, typically\n",
    "                (N,) or (N, ...) for segmentation. Values outside\n",
    "                [0, num_classes-1] are ignored.\n",
    "            ignore_index: A class index to ignore during updates.\n",
    "        \"\"\"\n",
    "        # Count the number of times each class is encountered\n",
    "        class_counts = Counter(target.flatten().int().tolist())\n",
    "\n",
    "        # Remove ignore_index if present\n",
    "        class_counts.pop(ignore_index, None)\n",
    "\n",
    "        # Remove those counts that exceed the number of classes that are being tracked\n",
    "        class_counts = {k: v for k, v in class_counts.items() if k < self.config.num_classes}\n",
    "\n",
    "        # Calculate prevalence of each class\n",
    "        total_count = sum(class_counts.values())\n",
    "        new_prevalences = (\n",
    "            {class_id: count / total_count for class_id, count in class_counts.items()} if total_count > 0 else {}\n",
    "        )\n",
    "\n",
    "        # Update current prevalences using EMA to allow for distribution shift in data\n",
    "        decay = self.config.ema_decay\n",
    "        for i in range(self.config.num_classes):\n",
    "            # when encountered for the first time, assume each class was equally prevalent at the start\n",
    "            if self.class_prevalences[i] is None and i in new_prevalences:\n",
    "                self.class_prevalences[i] = 1 / self.config.num_classes\n",
    "\n",
    "            # update to the new value using EMA\n",
    "            if self.class_prevalences[i] is not None:\n",
    "                self.class_prevalences[i] = self.class_prevalences[i] * decay + new_prevalences.get(i, 0.0) * (\n",
    "                    1 - decay\n",
    "                )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_class_prevalences(self, device=torch.device(\"cpu\")) -> torch.Tensor:\n",
    "        \"\"\"Return the current vector of class prevalences as a tensor.\n",
    "\n",
    "        For classes that haven't been observed yet, the corresponding entry will be\n",
    "        NaN. This method does not perform any imputation or normalization beyond\n",
    "        returning the current EMA state.\n",
    "\n",
    "        Args:\n",
    "            device: The device on which to place the returned tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape (num_classes,) with dtype float32 containing per-class\n",
    "            prevalence estimates in [0, 1] or NaN for unseen classes.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get class prevalences and replace None with nan\n",
    "        class_prevalences = [\n",
    "            prevalence if prevalence is not None else torch.nan for prevalence in self.class_prevalences\n",
    "        ]\n",
    "\n",
    "        # Calculate weights as inverse of class prevalences\n",
    "        class_prevalences = torch.tensor(class_prevalences, dtype=torch.float32, device=device)\n",
    "\n",
    "        return class_prevalences\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_class_weights(self, device=torch.device(\"cpu\")) -> torch.Tensor:\n",
    "        \"\"\"Compute per-class weights as the inverse of prevalences with safeguards.\n",
    "\n",
    "        Steps:\n",
    "            1) Convert current EMA prevalences to a tensor with NaNs for unseen classes.\n",
    "            2) Take the inverse to obtain raw weights (higher weight for rarer classes).\n",
    "            3) Replace NaNs by the mean of observed weights to avoid biasing toward\n",
    "               unseen classes, then clamp to mean ± 3·std to prevent extreme values.\n",
    "            4) Renormalize weights to sum to num_classes (so the average weight is 1).\n",
    "\n",
    "        Args:\n",
    "            device: The device on which to place the returned tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape (num_classes,) containing normalized class weights.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get class prevalences\n",
    "        class_prevalences = self.get_class_prevalences(device)\n",
    "\n",
    "        # If there were no class prevalences, then all weights will be nan; handle this\n",
    "        if class_prevalences.isnan().all():\n",
    "            class_prevalences = class_prevalences.nan_to_num(1.0)\n",
    "\n",
    "        # Calculate weights as inverse of class prevalences\n",
    "        weights = 1 / class_prevalences\n",
    "\n",
    "        # Substitute nan values with mean and clamp weights to a limit\n",
    "        # Assumption: all classes are visited at least once in the dataset\n",
    "        mu, std = weights.nanmean(), weights[~weights.isnan()].std()\n",
    "        weights = weights.nan_to_num(nan=mu, posinf=mu, neginf=mu)\n",
    "        weights = weights.clamp(mu - 3 * std, mu + 3 * std)\n",
    "\n",
    "        # Add failsafe just in case nans are still present\n",
    "        weights = weights.nan_to_num(1.0)\n",
    "\n",
    "        # Normalize weights to sum to self.config.num_classes\n",
    "        weights = self.config.num_classes * weights / weights.sum()\n",
    "\n",
    "        return weights\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        update_class_prevalences: bool = True,\n",
    "        return_class_weights: bool = False,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor | tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Compute class-balanced cross entropy.\n",
    "\n",
    "        This updates the internal class-prevalence EMA using the provided targets,\n",
    "        then computes cross-entropy with a weight vector derived from the current\n",
    "        prevalences.\n",
    "\n",
    "        Args:\n",
    "            input: Logits of shape (N, C, ...) where C == num_classes. Any extra spatial\n",
    "                dimensions (e.g., H, W, D) are supported as long as `target` is broadcastable\n",
    "                to the same non-channel shape expected by torch.nn.functional.cross_entropy.\n",
    "            target: Integer class indices with shape matching input without the channel\n",
    "                dimension, e.g., (N, ...) with values in [0, C-1].\n",
    "            update_class_prevalences: If True, update the internal class prevalence estimates\n",
    "                using the provided targets.\n",
    "            return_class_weights: If True, also return the per-class weight tensor used\n",
    "                for this call.\n",
    "            *args, **kwargs: Additional keyword args forwarded to F.cross_entropy\n",
    "                (e.g., reduction='mean').\n",
    "\n",
    "        Returns:\n",
    "            If return_class_weights is False: a scalar tensor loss.\n",
    "            If True: a tuple (loss, class_weights).\n",
    "        \"\"\"\n",
    "        # Update class prevalences\n",
    "        if update_class_prevalences:\n",
    "            self.update_class_prevalences(target, kwargs.get(\"ignore_index\", -100))\n",
    "\n",
    "        # Get class weights\n",
    "        class_weights = self.get_class_weights(input.device)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(input, target, weight=class_weights, *args, **kwargs)\n",
    "\n",
    "        if return_class_weights:\n",
    "            return loss, class_weights\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f3c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0876) tensor([1.0000, 1.0075, 0.9925])\n",
      "tensor(1.1896) tensor([1.0000, 1.0222, 0.9778])\n",
      "tensor(1.1945) tensor([1.0000, 1.0293, 0.9707])\n",
      "tensor(1.2458) tensor([1.0039, 1.0344, 0.9617])\n",
      "tensor(1.2453) tensor([1.0144, 1.0138, 0.9718])\n",
      "tensor(1.0574) tensor([1.0093, 1.0163, 0.9744])\n",
      "tensor(1.0806) tensor([1.0116, 1.0186, 0.9699])\n",
      "tensor(1.3428) tensor([0.9991, 1.0211, 0.9798])\n",
      "tensor(1.2334) tensor([0.9867, 1.0311, 0.9822])\n",
      "tensor(1.0478) tensor([0.9817, 1.0411, 0.9772])\n"
     ]
    }
   ],
   "source": [
    "# Regular test\n",
    "\n",
    "\n",
    "test = ClassBalancedCrossEntropyLoss(num_classes=3)\n",
    "\n",
    "for _ in range(10):\n",
    "    example_input = torch.rand(4, 3)\n",
    "    example_target = torch.randint(0, 3, (4,))\n",
    "    loss, class_weights = test(example_input, example_target, return_class_weights=True)\n",
    "    print(loss, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04dbaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1791) tensor([0.9861, 1.0070, 1.0070])\n",
      "tensor(1.1051) tensor([0.9725, 1.0137, 1.0137])\n",
      "tensor(1.1137) tensor([0.9593, 1.0204, 1.0204])\n",
      "tensor(1.0792) tensor([0.9463, 1.0268, 1.0268])\n",
      "tensor(1.1001) tensor([0.9337, 1.0332, 1.0332])\n"
     ]
    }
   ],
   "source": [
    "# Regular test with imbalanced targets\n",
    "\n",
    "\n",
    "test = ClassBalancedCrossEntropyLoss(num_classes=3)\n",
    "\n",
    "for _ in range(5):\n",
    "    example_input = torch.rand(10, 3)\n",
    "    example_target = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 2], dtype=torch.long)\n",
    "    loss, class_weights = test(example_input, example_target, return_class_weights=True)\n",
    "    print(loss, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2986d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5731) tensor([1.0041, 1.0041, 0.9918, 1.0000, 1.0000])\n",
      "tensor(1.7351) tensor([0.9958, 0.9958, 1.0083, 1.0000, 1.0000])\n",
      "tensor(1.5972) tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "tensor(1.6398) tensor([1.0164, 0.9918, 0.9918, 1.0000, 1.0000])\n",
      "tensor(1.3470) tensor([1.0202, 0.9958, 0.9840, 1.0000, 1.0000])\n",
      "tensor(1.6411) tensor([1.0117, 1.0000, 0.9883, 1.0000, 1.0000])\n",
      "tensor(1.5053) tensor([1.0156, 0.9921, 0.9923, 1.0000, 1.0000])\n",
      "tensor(1.5732) tensor([1.0194, 0.9960, 0.9846, 1.0000, 1.0000])\n",
      "tensor(1.5261) tensor([1.0110, 1.0001, 0.9888, 1.0000, 1.0000])\n",
      "tensor(1.7578) tensor([0.9912, 1.0160, 0.9928, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# Test where last two classes are never encountered\n",
    "\n",
    "test = ClassBalancedCrossEntropyLoss(num_classes=5)\n",
    "\n",
    "for _ in range(10):\n",
    "    example_input = torch.rand(4, 5)\n",
    "    example_target = torch.randint(0, 3, (4,))\n",
    "    loss, class_weights = test(example_input, example_target, return_class_weights=True)\n",
    "    print(loss, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc71cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1322) tensor([1., 1., 1.])\n",
      "tensor(1.1589) tensor([1., 1., 1.])\n",
      "tensor(1.0178) tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Don't update prevalences\n",
    "\n",
    "test = ClassBalancedCrossEntropyLoss(num_classes=3)\n",
    "\n",
    "for _ in range(3):\n",
    "    example_input = torch.rand(4, 3)\n",
    "    example_target = torch.randint(0, 3, (4,))\n",
    "    loss, class_weights = test(example_input, example_target, update_class_prevalences=False, return_class_weights=True)\n",
    "    print(loss, class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f28624",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1089315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
