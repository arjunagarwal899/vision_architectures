{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp layers/upsample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a10177",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3918aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from torch import nn\n",
    "\n",
    "from vision_architectures.blocks.cnn import CNNBlock3D, CNNBlockConfig\n",
    "from vision_architectures.utils.activation_checkpointing import ActivationCheckpointing\n",
    "from vision_architectures.utils.custom_base_model import Field\n",
    "from vision_architectures.utils.rearrange import rearrange_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe639fa",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bfb78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class PixelShuffleUpsampleConfig(CNNBlockConfig):\n",
    "    \"\"\"\n",
    "    Configuration class for PixelShuffleUpsample.\n",
    "    \"\"\"\n",
    "\n",
    "    scale_factor: int = Field(2, description=\"Scale factor for upsampling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea466f",
   "metadata": {},
   "source": [
    "# Upsample layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ea4b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class PixelShuffleUpsample3D(nn.Module):\n",
    "    def __init__(self, config: PixelShuffleUpsampleConfig = {}, checkpointing_level: int = 0, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = PixelShuffleUpsampleConfig.model_validate(config | kwargs)\n",
    "\n",
    "        expand_config = CNNBlockConfig.model_validate(self.config)\n",
    "        expand_config.out_channels = expand_config.out_channels * (self.config.scale_factor**3)\n",
    "        self.expand = CNNBlock3D(expand_config, checkpointing_level)\n",
    "\n",
    "        self.checkpointing_level1 = ActivationCheckpointing(1, checkpointing_level)\n",
    "\n",
    "    def _forward(self, x: torch.Tensor, channels_first: bool = True) -> torch.Tensor:\n",
    "        # x: (b, [in_channels], z, y, x, [in_channels])\n",
    "\n",
    "        x = rearrange_channels(x, channels_first, True)\n",
    "        # (b, in_channels, z, y, x)\n",
    "\n",
    "        x = self.expand(x)\n",
    "        # (b, out_channels * scale_factor**2, y, x)\n",
    "        x = rearrange(\n",
    "            x,\n",
    "            \"b (c s1 s2 s3) z y x -> b c (z s1) (y s2) (x s3)\",\n",
    "            s1=self.config.scale_factor,\n",
    "            s2=self.config.scale_factor,\n",
    "            s3=self.config.scale_factor,\n",
    "        ).contiguous()\n",
    "        # (b, out_channels, z * scale_factor, y * scale_factor, x * scale_factor)\n",
    "\n",
    "        x = rearrange_channels(x, True, channels_first)\n",
    "        # (b, [out_channels], z * scale_factor, y * scale_factor, x * scale_factor, [out_channels])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.checkpointing_level1(self._forward, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec8296b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mPixelShuffleUpsample3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mexpand\u001b[1m)\u001b[0m: \u001b[1;35mCNNBlock3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1024\u001b[0m, \u001b[1;36m4096\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m4198400\u001b[0m, \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = PixelShuffleUpsample3D(\n",
    "    in_channels=1024, out_channels=512, kernel_size=1, activation=None, normalization=None, padding=0\n",
    ")\n",
    "display(test)\n",
    "\n",
    "sample_input = torch.randn(2, 1024, 4, 4, 4)\n",
    "\n",
    "sum([param.numel() for param in test.parameters()]), test(sample_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dcc22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea194be4",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b8becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f63fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
