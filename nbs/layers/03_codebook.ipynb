{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp layers/codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from einops import rearrange\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from torch import nn\n",
    "\n",
    "from vision_architectures.utils.custom_base_model import CustomBaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class CodebookConfig(CustomBaseModel):\n",
    "    num_vectors: int\n",
    "    dim: int\n",
    "\n",
    "    revive_dead_vectors_after_n_steps: int = 100  # 0 means never revive\n",
    "\n",
    "    ema_decay: float | None = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Codebook(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(self, config: CodebookConfig = {}, use_ema: bool = True, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = CodebookConfig.model_validate(config | kwargs)\n",
    "\n",
    "        self.use_ema = use_ema\n",
    "        if self.use_ema:\n",
    "            assert self.config.ema_decay is not None, \"ema_decay must be provided if use_ema is True\"\n",
    "\n",
    "        num_vectors = self.config.num_vectors\n",
    "        dim = self.config.dim\n",
    "\n",
    "        self.vectors = nn.Embedding(num_vectors, dim)\n",
    "\n",
    "        # Usage counter tracks the number of times a vector has been used since it was last revived\n",
    "        usage_counter = torch.zeros(num_vectors, dtype=torch.long)\n",
    "        self.register_buffer(\"usage_counter\", usage_counter, persistent=False)\n",
    "        self.usage_counter: torch.Tensor  # For hinting\n",
    "\n",
    "        # stale_counter tracks the number of batches a vector has been unused since the last time it was used\n",
    "        stale_counter = torch.zeros(num_vectors, dtype=torch.long)\n",
    "        self.register_buffer(\"stale_counter\", stale_counter, persistent=False)\n",
    "        self.stale_counter: torch.Tensor\n",
    "\n",
    "        # Create a generator object so that randomness is consistent across all devices\n",
    "        self.generator = torch.Generator()\n",
    "        self.generator_initalized = False\n",
    "\n",
    "        if self.use_ema:\n",
    "            self.decay = self.config.ema_decay\n",
    "\n",
    "            # EMA cluster size tracking\n",
    "            cluster_size = torch.zeros(self.config.num_vectors)\n",
    "            self.register_buffer(\"cluster_size\", cluster_size, persistent=False)\n",
    "            self.cluster_size: torch.Tensor\n",
    "\n",
    "            # EMA for embedding vectors\n",
    "            ema_vectors = torch.zeros_like(self.vectors.weight)\n",
    "            self.register_buffer(\"ema_vectors\", ema_vectors, persistent=False)\n",
    "            self.ema_vectors: torch.Tensor\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def calculate_perplexity(self, indices: torch.Tensor):\n",
    "        encodings = torch.zeros(indices.shape[0], self.config.num_vectors, device=indices.device)\n",
    "        encodings.scatter_(1, indices.unsqueeze(1), 1)\n",
    "        avg_probs = encodings.float().mean(0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "        return perplexity\n",
    "\n",
    "    def calculate_losses(self, x: torch.Tensor, z: torch.Tensor):\n",
    "        commitment_loss = torch.mean((z - x.detach()) ** 2)\n",
    "        if self.use_ema:\n",
    "            codebook_loss = torch.zeros_like(commitment_loss)\n",
    "        else:\n",
    "            codebook_loss = torch.mean((z.detach() - x) ** 2)\n",
    "        return codebook_loss, commitment_loss\n",
    "\n",
    "    def quantize(self, x: torch.Tensor):\n",
    "        # x: (BS, C)  where BS is a combination of batch and spatial/temporal dimensions\n",
    "\n",
    "        # Compute distances\n",
    "        distances = torch.cdist(x, self.vectors.weight)\n",
    "        # (BS, num_vectors)\n",
    "\n",
    "        # Find nearest vectors\n",
    "        indices = torch.argmin(distances, dim=1)\n",
    "        # (BS,)\n",
    "\n",
    "        # Quantize\n",
    "        z: torch.Tensor = self.vectors(indices)\n",
    "        # (BS, C)\n",
    "\n",
    "        # Perform EMA\n",
    "        if self.training and self.use_ema:\n",
    "            self._perform_ema(x, indices)\n",
    "\n",
    "        # Loss calculations\n",
    "        codebook_loss, commitment_loss = self.calculate_losses(x, z)\n",
    "\n",
    "        # Allow gradients to propagate using straight-through estimator\n",
    "        z = x + (z - x).detach()\n",
    "        # (BS, C)\n",
    "\n",
    "        # Calculate perplexity\n",
    "        perplexity = self.calculate_perplexity(indices)\n",
    "\n",
    "        # Update counters\n",
    "        if self.training:\n",
    "            self._update_counters(indices)\n",
    "\n",
    "        return z, codebook_loss, commitment_loss, perplexity\n",
    "\n",
    "    def revive_dead_vectors(self):\n",
    "        assert self.training, \"revive_dead_vectors should only be called during training\"\n",
    "        revive_vector_mask = self.stale_counter >= self.config.revive_dead_vectors_after_n_steps\n",
    "        if not revive_vector_mask.any():\n",
    "            return\n",
    "\n",
    "        revive_vectors_shape = self.vectors.weight[revive_vector_mask].shape\n",
    "        num_revive_vectors = revive_vectors_shape[0]\n",
    "\n",
    "        # Sample commonly used vectors from the codebook\n",
    "        sampling_probabilities = self.usage_counter.clone().to(torch.float32)\n",
    "        sampling_probabilities.clamp_(min=1e-9)  # Don't allow all zero probabilities\n",
    "        selected_vectors_mask = torch.multinomial(\n",
    "            sampling_probabilities, num_revive_vectors, replacement=True, generator=self.generator\n",
    "        )\n",
    "        selected_vectors = self.vectors(selected_vectors_mask).detach()\n",
    "\n",
    "        # Add noise to the selected vectors\n",
    "        noise = torch.empty_like(selected_vectors).normal_(\n",
    "            generator=self.generator\n",
    "        )  # This is because current randn_like does not support generator input\n",
    "        with torch.no_grad():\n",
    "            std = self._estimate_codebook_distance() * 0.1  # https://openreview.net/pdf?id=HkGGfhC5Y7\n",
    "        noised_selected_vectors = selected_vectors + noise * std\n",
    "\n",
    "        # Replace dead vectors with noised selected vectors\n",
    "        self.vectors.weight.data[revive_vector_mask] = noised_selected_vectors\n",
    "\n",
    "        self.usage_counter[revive_vector_mask] = 0\n",
    "        self.stale_counter[revive_vector_mask] = 0\n",
    "\n",
    "        if self.use_ema:\n",
    "            # Also update the EMA buffers for these vectors\n",
    "            self.ema_vectors.data[revive_vector_mask] = noised_selected_vectors\n",
    "            self.cluster_size.data[revive_vector_mask] = 0\n",
    "\n",
    "    def forward(self, x: torch.Tensor, channels_first: bool = None):\n",
    "        #  If channels_first is None: x: (B, T, C) if ndim == 3, else (B, C, ...)\n",
    "        #  If channels_first is True: x: (B, C, ...)\n",
    "        #  If channels_first is False: x: (B, ..., C)\n",
    "\n",
    "        if not self.generator_initalized:\n",
    "            self._initialize_generator()\n",
    "\n",
    "        shape = x.shape\n",
    "        ndim = x.ndim\n",
    "        B = shape[0]\n",
    "\n",
    "        if channels_first is None:\n",
    "            if ndim == 3:\n",
    "                channels_first = False\n",
    "            else:\n",
    "                channels_first = True\n",
    "\n",
    "        if channels_first:\n",
    "            forward_pattern = \"b c ... -> (b ...) c\"\n",
    "            backward_pattern = \"(b s) c -> b c s\"  # s stands for flattened spatial dimensions\n",
    "        else:\n",
    "            forward_pattern = \"b ... c -> (b ...) c\"\n",
    "            backward_pattern = \"(b s) c -> b s c\"\n",
    "\n",
    "        # Flatten input\n",
    "        x = rearrange(x, forward_pattern)\n",
    "        # (BS, C)\n",
    "\n",
    "        z, codebook_loss, commitment_loss, perplexity = self.quantize(x)\n",
    "\n",
    "        # Return back to original shape\n",
    "        z = rearrange(z, backward_pattern, b=B).reshape(shape)\n",
    "        # (x.shape)\n",
    "\n",
    "        if self.training and self.config.revive_dead_vectors_after_n_steps > 0:\n",
    "            self.revive_dead_vectors()\n",
    "\n",
    "        return z, codebook_loss, commitment_loss, perplexity\n",
    "\n",
    "    def _perform_ema(self, x: torch.Tensor, indices: torch.Tensor):\n",
    "        # Create one-hot encodings for the selected indices\n",
    "        encodings = torch.zeros(x.shape[0], self.config.num_vectors, device=x.device)\n",
    "        encodings.scatter_(1, indices.unsqueeze(1), 1)\n",
    "\n",
    "        # Calculate new cluster sizes with EMA\n",
    "        batch_cluster_size = encodings.sum(0)  # Sum over batch dimension\n",
    "\n",
    "        # Synchronize across devices if using distributed training\n",
    "        if dist.is_initialized():\n",
    "            dist.all_reduce(batch_cluster_size, op=dist.ReduceOp.SUM)\n",
    "\n",
    "        # Update cluster size using EMA\n",
    "        self.cluster_size.data = self.cluster_size * self.decay + (1 - self.decay) * batch_cluster_size\n",
    "\n",
    "        # Calculate sum of embeddings assigned to each cluster\n",
    "        batch_ema_vectors = torch.matmul(encodings.t(), x)\n",
    "\n",
    "        # Synchronize across devices if using distributed training\n",
    "        if dist.is_initialized():\n",
    "            dist.all_reduce(batch_ema_vectors, op=dist.ReduceOp.SUM)\n",
    "\n",
    "        # Update EMA for vectors\n",
    "        self.ema_vectors.data = self.ema_vectors * self.decay + (1 - self.decay) * batch_ema_vectors\n",
    "\n",
    "        # Normalize EMA vectors by cluster size\n",
    "        n = self.cluster_size.sum()\n",
    "        cluster_size = (self.cluster_size + 1e-6) / (n + self.config.num_vectors * 1e-6) * n\n",
    "\n",
    "        # Normalize codebook vectors using Laplace smoothing\n",
    "        normalized_vectors = self.ema_vectors / cluster_size.unsqueeze(1)\n",
    "        self.vectors.weight.data = normalized_vectors\n",
    "\n",
    "    def _initialize_generator(self):\n",
    "        assert not self.generator_initalized, \"Generator has already been initialized\"\n",
    "        seed = torch.randint(0, 2**32, (1,))\n",
    "        if dist.is_initialized():\n",
    "            dist.all_reduce(seed, op=dist.ReduceOp.MIN)\n",
    "        self.generator.manual_seed(seed.item())\n",
    "        self.generator_initalized = True\n",
    "\n",
    "    def _update_counters(self, indices):\n",
    "        # Create a tensor which counts the number of times a vector has been used\n",
    "        used_vector_indices, counts = torch.unique(indices, return_counts=True)\n",
    "        usage_counter_increment = torch.zeros_like(self.usage_counter)\n",
    "        usage_counter_increment[used_vector_indices] = counts\n",
    "\n",
    "        # Synchronise the usage counts across all devices\n",
    "        if dist.is_initialized():\n",
    "            dist.all_reduce(usage_counter_increment, op=dist.ReduceOp.SUM)\n",
    "\n",
    "        # Don't allow counters to exceed maximum possible values\n",
    "        approximate_max_value = int(torch.iinfo(torch.long).max * 0.9)\n",
    "        self.usage_counter.clamp_(max=approximate_max_value)\n",
    "        self.stale_counter.clamp_(max=approximate_max_value)\n",
    "\n",
    "        # Update usage counter\n",
    "        self.usage_counter += usage_counter_increment\n",
    "\n",
    "        # Identify vectors that were not used across all devices\n",
    "        stale_counter_increment = torch.zeros_like(self.stale_counter)\n",
    "        stale_counter_increment[usage_counter_increment == 0] = 1\n",
    "\n",
    "        # Incrememnt counts of stale vectors and reset counts of used vectors\n",
    "        self.stale_counter += stale_counter_increment\n",
    "        self.stale_counter[usage_counter_increment > 0] = 0\n",
    "\n",
    "    def _estimate_codebook_distance(self, max_sample=500):\n",
    "        \"\"\"Estimate mean distance between codebook vectors\"\"\"\n",
    "        with torch.no_grad():\n",
    "            if self.vectors.weight.shape[0] > max_sample:\n",
    "                # Sample a subset for efficiency\n",
    "                idx = torch.randperm(self.vectors.weight.shape[0], generator=self.generator)[:max_sample]\n",
    "                vectors_weight = self.vectors.weight[idx]\n",
    "            else:\n",
    "                vectors_weight = self.vectors.weight\n",
    "\n",
    "            distances = torch.cdist(vectors_weight, vectors_weight)\n",
    "            mask = ~torch.eye(distances.shape[0], dtype=torch.bool, device=distances.device)  # Exclude self-distances\n",
    "            codebook_distance = distances[mask].mean()\n",
    "\n",
    "        return codebook_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mCodebook\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mvectors\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1024\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0.6293\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMeanBackward0\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0.6293\u001b[0m\u001b[39m, \u001b[0m\u001b[33mgrad_fn\u001b[0m\u001b[39m=<MeanBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m24.4819\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m121\u001b[0m, \u001b[1;36m205\u001b[0m,  \u001b[1;36m86\u001b[0m,  \u001b[1;36m90\u001b[0m,  \u001b[1;36m56\u001b[0m,  \u001b[1;36m78\u001b[0m, \u001b[1;36m110\u001b[0m,  \u001b[1;36m18\u001b[0m,  \u001b[1;36m58\u001b[0m,  \u001b[1;36m44\u001b[0m,  \u001b[1;36m59\u001b[0m,  \u001b[1;36m64\u001b[0m, \u001b[1;36m109\u001b[0m, \u001b[1;36m113\u001b[0m,\n",
       "         \u001b[1;36m72\u001b[0m,  \u001b[1;36m32\u001b[0m,  \u001b[1;36m20\u001b[0m,  \u001b[1;36m25\u001b[0m,  \u001b[1;36m11\u001b[0m, \u001b[1;36m133\u001b[0m,  \u001b[1;36m19\u001b[0m,  \u001b[1;36m23\u001b[0m, \u001b[1;36m143\u001b[0m,  \u001b[1;36m92\u001b[0m,  \u001b[1;36m23\u001b[0m,  \u001b[1;36m11\u001b[0m,  \u001b[1;36m25\u001b[0m,  \u001b[1;36m35\u001b[0m,\n",
       "         \u001b[1;36m92\u001b[0m,  \u001b[1;36m12\u001b[0m,   \u001b[1;36m5\u001b[0m, \u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "        \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m124\u001b[0m, \u001b[1;36m209\u001b[0m,  \u001b[1;36m89\u001b[0m,  \u001b[1;36m92\u001b[0m,  \u001b[1;36m59\u001b[0m,  \u001b[1;36m82\u001b[0m, \u001b[1;36m115\u001b[0m,  \u001b[1;36m18\u001b[0m,  \u001b[1;36m58\u001b[0m,  \u001b[1;36m44\u001b[0m,  \u001b[1;36m61\u001b[0m,  \u001b[1;36m65\u001b[0m, \u001b[1;36m111\u001b[0m, \u001b[1;36m115\u001b[0m,\n",
       "         \u001b[1;36m74\u001b[0m,  \u001b[1;36m33\u001b[0m,  \u001b[1;36m21\u001b[0m,  \u001b[1;36m25\u001b[0m,  \u001b[1;36m11\u001b[0m, \u001b[1;36m137\u001b[0m,  \u001b[1;36m21\u001b[0m,  \u001b[1;36m25\u001b[0m, \u001b[1;36m151\u001b[0m,  \u001b[1;36m96\u001b[0m,  \u001b[1;36m23\u001b[0m,  \u001b[1;36m11\u001b[0m,  \u001b[1;36m25\u001b[0m,  \u001b[1;36m36\u001b[0m,\n",
       "         \u001b[1;36m96\u001b[0m,  \u001b[1;36m12\u001b[0m,   \u001b[1;36m5\u001b[0m, \u001b[1;36m132\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "        \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m127\u001b[0m, \u001b[1;36m213\u001b[0m,  \u001b[1;36m92\u001b[0m,  \u001b[1;36m94\u001b[0m,  \u001b[1;36m62\u001b[0m,  \u001b[1;36m86\u001b[0m, \u001b[1;36m120\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m,  \u001b[1;36m63\u001b[0m,  \u001b[1;36m66\u001b[0m, \u001b[1;36m113\u001b[0m, \u001b[1;36m117\u001b[0m,\n",
       "         \u001b[1;36m76\u001b[0m,  \u001b[1;36m34\u001b[0m,  \u001b[1;36m22\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m, \u001b[1;36m141\u001b[0m,  \u001b[1;36m23\u001b[0m,  \u001b[1;36m27\u001b[0m, \u001b[1;36m159\u001b[0m, \u001b[1;36m100\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m,  \u001b[1;36m37\u001b[0m,\n",
       "        \u001b[1;36m100\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m, \u001b[1;36m136\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "        \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0.6592\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMeanBackward0\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0.6592\u001b[0m\u001b[39m, \u001b[0m\u001b[33mgrad_fn\u001b[0m\u001b[39m=<MeanBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m19.0532\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = Codebook(num_vectors=32, dim=8, revive_dead_vectors_after_n_steps=3, use_ema=False)\n",
    "display(test)\n",
    "\n",
    "sample_input = torch.randn(2, 2**10, 8, requires_grad=True)\n",
    "output = test(sample_input)\n",
    "display([output[0].shape, *output[1:]])\n",
    "\n",
    "sample_input = torch.randn(8, 8, 2, 2, 2, requires_grad=True)\n",
    "output = test(sample_input)\n",
    "display([test.usage_counter, test.stale_counter])\n",
    "output = test(sample_input)\n",
    "display([test.usage_counter, test.stale_counter])\n",
    "output = test(sample_input)\n",
    "display([test.usage_counter, test.stale_counter])\n",
    "display([output[0].shape, *output[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mCodebook\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mvectors\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1024\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m.\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0.6147\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMeanBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m25.3004\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m43\u001b[0m, \u001b[1;36m100\u001b[0m,  \u001b[1;36m34\u001b[0m,  \u001b[1;36m33\u001b[0m,  \u001b[1;36m82\u001b[0m,  \u001b[1;36m45\u001b[0m,  \u001b[1;36m84\u001b[0m, \u001b[1;36m225\u001b[0m,  \u001b[1;36m69\u001b[0m,  \u001b[1;36m47\u001b[0m,  \u001b[1;36m87\u001b[0m,  \u001b[1;36m60\u001b[0m,  \u001b[1;36m99\u001b[0m,  \u001b[1;36m44\u001b[0m,\n",
       "         \u001b[1;36m53\u001b[0m,   \u001b[1;36m9\u001b[0m,  \u001b[1;36m28\u001b[0m,  \u001b[1;36m36\u001b[0m,  \u001b[1;36m28\u001b[0m,  \u001b[1;36m30\u001b[0m,  \u001b[1;36m74\u001b[0m, \u001b[1;36m184\u001b[0m,  \u001b[1;36m65\u001b[0m,  \u001b[1;36m22\u001b[0m,  \u001b[1;36m17\u001b[0m,  \u001b[1;36m80\u001b[0m,  \u001b[1;36m33\u001b[0m, \u001b[1;36m100\u001b[0m,\n",
       "         \u001b[1;36m91\u001b[0m,  \u001b[1;36m29\u001b[0m,  \u001b[1;36m26\u001b[0m, \u001b[1;36m155\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "        \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m46\u001b[0m, \u001b[1;36m102\u001b[0m,  \u001b[1;36m36\u001b[0m,  \u001b[1;36m33\u001b[0m,  \u001b[1;36m83\u001b[0m,  \u001b[1;36m48\u001b[0m,  \u001b[1;36m86\u001b[0m, \u001b[1;36m227\u001b[0m,  \u001b[1;36m72\u001b[0m,  \u001b[1;36m48\u001b[0m,  \u001b[1;36m88\u001b[0m,  \u001b[1;36m64\u001b[0m, \u001b[1;36m103\u001b[0m,  \u001b[1;36m44\u001b[0m,\n",
       "         \u001b[1;36m56\u001b[0m,   \u001b[1;36m9\u001b[0m,  \u001b[1;36m28\u001b[0m,  \u001b[1;36m38\u001b[0m,  \u001b[1;36m30\u001b[0m,  \u001b[1;36m33\u001b[0m,  \u001b[1;36m76\u001b[0m, \u001b[1;36m190\u001b[0m,  \u001b[1;36m66\u001b[0m,  \u001b[1;36m23\u001b[0m,  \u001b[1;36m19\u001b[0m,  \u001b[1;36m83\u001b[0m,  \u001b[1;36m36\u001b[0m, \u001b[1;36m101\u001b[0m,\n",
       "         \u001b[1;36m92\u001b[0m,  \u001b[1;36m29\u001b[0m,  \u001b[1;36m30\u001b[0m, \u001b[1;36m157\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "        \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m49\u001b[0m, \u001b[1;36m104\u001b[0m,  \u001b[1;36m39\u001b[0m,   \u001b[1;36m0\u001b[0m,  \u001b[1;36m84\u001b[0m,  \u001b[1;36m51\u001b[0m,  \u001b[1;36m88\u001b[0m, \u001b[1;36m229\u001b[0m,  \u001b[1;36m75\u001b[0m,  \u001b[1;36m49\u001b[0m,  \u001b[1;36m89\u001b[0m,  \u001b[1;36m68\u001b[0m, \u001b[1;36m107\u001b[0m,   \u001b[1;36m0\u001b[0m,\n",
       "         \u001b[1;36m59\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m,  \u001b[1;36m40\u001b[0m,  \u001b[1;36m32\u001b[0m,  \u001b[1;36m36\u001b[0m,  \u001b[1;36m78\u001b[0m, \u001b[1;36m195\u001b[0m,  \u001b[1;36m67\u001b[0m,  \u001b[1;36m24\u001b[0m,  \u001b[1;36m21\u001b[0m,  \u001b[1;36m86\u001b[0m,  \u001b[1;36m39\u001b[0m, \u001b[1;36m102\u001b[0m,\n",
       "         \u001b[1;36m93\u001b[0m,   \u001b[1;36m0\u001b[0m,  \u001b[1;36m34\u001b[0m, \u001b[1;36m159\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "        \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m.\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0.5011\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMeanBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m24.2387\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = Codebook(num_vectors=32, dim=8, revive_dead_vectors_after_n_steps=3, use_ema=True)\n",
    "display(test)\n",
    "\n",
    "sample_input = torch.randn(2, 2**10, 8, requires_grad=True)\n",
    "output = test(sample_input)\n",
    "display([output[0].shape, *output[1:]])\n",
    "\n",
    "sample_input = torch.randn(8, 8, 2, 2, 2, requires_grad=True)\n",
    "output = test(sample_input)\n",
    "display([test.usage_counter, test.stale_counter])\n",
    "output = test(sample_input)\n",
    "display([test.usage_counter, test.stale_counter])\n",
    "output = test(sample_input)\n",
    "display([test.usage_counter, test.stale_counter])\n",
    "display([output[0].shape, *output[1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
