{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp layers/codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from einops import rearrange\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from torch import nn\n",
    "\n",
    "from vision_architectures.docstrings import populate_docstring\n",
    "from vision_architectures.utils.custom_base_model import CustomBaseModel, Field, computed_field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class CodebookConfig(CustomBaseModel):\n",
    "    num_vectors: int = Field(..., description=\"Number of vectors in the codebook\")\n",
    "    dim: int = Field(..., description=\"Dimension of each vector in the codebook\")\n",
    "\n",
    "    revive_dead_vectors_after_n_steps: int = Field(\n",
    "        100, description=\"Number of steps after which a vector is declared dead and is revived (0 means never revive)\"\n",
    "    )\n",
    "\n",
    "    ema_decay: float | None = Field(0.99, description=\"EMA decay rate for updating codebook vectors\")\n",
    "\n",
    "    @computed_field(description=\"Whether to use EMA for updating codebook vectors\")\n",
    "    @property\n",
    "    def use_ema(self) -> bool:\n",
    "        return self.ema_decay is not None and self.ema_decay > 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Codebook(nn.Module, PyTorchModelHubMixin):\n",
    "    \"\"\"Codebook that can be used for vector quantization. This implementation maintains the vectors in distributed\n",
    "    settings. It also supports exponential moving average (EMA) updates of the codebook vectors as well as reviving\n",
    "    dead vectors.\"\"\"\n",
    "\n",
    "    @populate_docstring\n",
    "    def __init__(self, config: CodebookConfig = {}, **kwargs):\n",
    "        \"\"\"Initialize the Codebook.\n",
    "\n",
    "        Args:\n",
    "            config: {CONFIG_KWARGS_DOC}\n",
    "            **kwargs: {CONFIG_KWARGS_DOC}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = CodebookConfig.model_validate(config | kwargs)\n",
    "\n",
    "        num_vectors = self.config.num_vectors\n",
    "        dim = self.config.dim\n",
    "\n",
    "        self.vectors = nn.Embedding(num_vectors, dim)\n",
    "\n",
    "        # Usage counter tracks the number of times a vector has been used since it was last revived\n",
    "        usage_counter = torch.zeros(num_vectors, dtype=torch.long)\n",
    "        self.register_buffer(\"usage_counter\", usage_counter, persistent=False)\n",
    "        self.usage_counter: torch.Tensor  # For hinting\n",
    "\n",
    "        # stale_counter tracks the number of batches a vector has been unused since the last time it was used\n",
    "        stale_counter = torch.zeros(num_vectors, dtype=torch.long)\n",
    "        self.register_buffer(\"stale_counter\", stale_counter, persistent=False)\n",
    "        self.stale_counter: torch.Tensor\n",
    "\n",
    "        # Create a generator object so that randomness is consistent across all devices\n",
    "        self.generator = torch.Generator()\n",
    "        self.generator_initalized = False\n",
    "\n",
    "        if self.config.use_ema:\n",
    "            self.decay = self.config.ema_decay\n",
    "\n",
    "            # EMA cluster size tracking\n",
    "            cluster_size = torch.zeros(self.config.num_vectors)\n",
    "            self.register_buffer(\"cluster_size\", cluster_size, persistent=False)\n",
    "            self.cluster_size: torch.Tensor\n",
    "\n",
    "            # EMA for embedding vectors\n",
    "            ema_vectors = torch.zeros_like(self.vectors.weight)\n",
    "            self.register_buffer(\"ema_vectors\", ema_vectors, persistent=False)\n",
    "            self.ema_vectors: torch.Tensor\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def calculate_perplexity(self, indices: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Calculate perplexity of the codebook usage.\n",
    "\n",
    "        Args:\n",
    "            indices: Indices of the codebook vectors chosen for each input vector.\n",
    "\n",
    "        Returns:\n",
    "            Perplexity of the codebook usage.\n",
    "        \"\"\"\n",
    "        # Get mapping of which BS vector chose which codebook vector\n",
    "        encodings = self._one_hot_indices(indices)\n",
    "        # Calculate average number of times each codebook vector was chosen\n",
    "        avg_probs = encodings.float().mean(dim=0)\n",
    "        # Calculate perplexity i.e. utililzation of codebook\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "        return perplexity\n",
    "\n",
    "    def calculate_losses(self, x: torch.Tensor, z: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Calculate codebook and commitment losses.\n",
    "\n",
    "        Args:\n",
    "            x: Input vectors. Should be of shape (BS, C) where BS is a combination of batch and spatial/temporal\n",
    "                dimensions.\n",
    "            z: Quantized vectors. Should be of shape (BS, C).\n",
    "\n",
    "        Returns:\n",
    "            codebook_loss: Codebook loss.\n",
    "            commitment_loss: Commitment loss.\n",
    "        \"\"\"\n",
    "        commitment_loss = torch.mean((z - x.detach()) ** 2)\n",
    "        if self.config.use_ema:\n",
    "            codebook_loss = torch.zeros_like(commitment_loss)\n",
    "        else:\n",
    "            codebook_loss = torch.mean((z.detach() - x) ** 2)\n",
    "        return codebook_loss, commitment_loss\n",
    "\n",
    "    def quantize(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Quantize the input vectors using the codebook and return along with losses and perplexity.\n",
    "\n",
    "        Args:\n",
    "            x: Input vectors to be quantized. Should be of shape (BS, C) where BS is a combination of batch and\n",
    "                spatial/temporal dimensions.\n",
    "\n",
    "        Returns:\n",
    "            z: Quantized vectors of shape (BS, C).\n",
    "            codebook_loss: Codebook loss.\n",
    "            commitment_loss: Commitment loss.\n",
    "            perplexity: Perplexity of the codebook usage.\n",
    "        \"\"\"\n",
    "        # Compute distances\n",
    "        distances = torch.cdist(x, self.vectors.weight)\n",
    "        # (BS, num_vectors)\n",
    "\n",
    "        # Find nearest vectors\n",
    "        indices = torch.argmin(distances, dim=1)\n",
    "        # (BS,)\n",
    "\n",
    "        # Quantize\n",
    "        z: torch.Tensor = self.vectors(indices)\n",
    "        # (BS, C)\n",
    "\n",
    "        # Perform EMA\n",
    "        if self.training and self.config.use_ema:\n",
    "            self._perform_ema(x, indices)\n",
    "\n",
    "        # Loss calculations\n",
    "        codebook_loss, commitment_loss = self.calculate_losses(x, z)\n",
    "\n",
    "        # Allow gradients to propagate using straight-through estimator\n",
    "        z = x + (z - x).detach()\n",
    "        # (BS, C)\n",
    "\n",
    "        # Calculate perplexity\n",
    "        perplexity = self.calculate_perplexity(indices)\n",
    "\n",
    "        # Update counters\n",
    "        if self.training:\n",
    "            self._update_counters(indices)\n",
    "\n",
    "        return z, codebook_loss, commitment_loss, perplexity\n",
    "\n",
    "    def revive_dead_vectors(self):\n",
    "        \"\"\"Revive dead vectors in the codebook by replacing them with noised commonly used vectors.\"\"\"\n",
    "\n",
    "        assert self.training, \"revive_dead_vectors should only be called during training\"\n",
    "        revive_vector_mask = self.stale_counter >= self.config.revive_dead_vectors_after_n_steps\n",
    "        if not revive_vector_mask.any():\n",
    "            return\n",
    "\n",
    "        revive_vectors_shape = self.vectors.weight[revive_vector_mask].shape\n",
    "        num_revive_vectors = revive_vectors_shape[0]\n",
    "\n",
    "        # Sample commonly used vectors from the codebook\n",
    "        sampling_probabilities = self.usage_counter.clone().to(torch.float32)\n",
    "        sampling_probabilities.clamp_(min=1e-9)  # Don't allow all zero probabilities\n",
    "        selected_vectors_mask = torch.multinomial(\n",
    "            sampling_probabilities, num_revive_vectors, replacement=True, generator=self.generator\n",
    "        )\n",
    "        selected_vectors = self.vectors(selected_vectors_mask).detach()\n",
    "\n",
    "        # Add noise to the selected vectors\n",
    "        noise = torch.empty_like(selected_vectors).normal_(\n",
    "            generator=self.generator\n",
    "        )  # This is because current randn_like does not support generator input\n",
    "        with torch.no_grad():\n",
    "            std = self._estimate_codebook_distance() * 0.1  # https://openreview.net/pdf?id=HkGGfhC5Y7\n",
    "        noised_selected_vectors = selected_vectors + noise * std\n",
    "\n",
    "        # Replace dead vectors with noised selected vectors\n",
    "        self.vectors.weight.data[revive_vector_mask] = noised_selected_vectors\n",
    "\n",
    "        self.usage_counter[revive_vector_mask] = 0\n",
    "        self.stale_counter[revive_vector_mask] = 0\n",
    "\n",
    "        if self.config.use_ema:\n",
    "            # Also update the EMA buffers for these vectors\n",
    "            self.ema_vectors.data[revive_vector_mask] = noised_selected_vectors\n",
    "            self.cluster_size.data[revive_vector_mask] = 0\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, channels_first: bool = None\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Quantize the input tensor using the codebook. Update the codebook vectors if using EMA. Revive dead vectors\n",
    "        if applicable..\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor to be quantized. Should be of shape (B, ..., C) if channels_first is False, (B, C, ...) if\n",
    "                channels_first is True or None with ndim != 3, else (B, T, C) if channels_first is None and ndim == 3.\n",
    "            channels_first: Whether the input tensor has channels as the first dimension after batch dimension.\n",
    "\n",
    "        Returns:\n",
    "            z: Quantized tensor of the same shape as input.\n",
    "            codebook_loss: Codebook loss.\n",
    "            commitment_loss: Commitment loss.\n",
    "            perplexity: Perplexity of the codebook usage.\n",
    "        \"\"\"\n",
    "        #  If channels_first is None: x: (B, T, C) if ndim == 3, else (B, C, ...)\n",
    "        #  If channels_first is True: x: (B, C, ...)\n",
    "        #  If channels_first is False: x: (B, ..., C)\n",
    "\n",
    "        if not self.generator_initalized:\n",
    "            self._initialize_generator()\n",
    "\n",
    "        shape = x.shape\n",
    "        ndim = x.ndim\n",
    "        B = shape[0]\n",
    "\n",
    "        if channels_first is None:\n",
    "            if ndim == 3:\n",
    "                channels_first = False\n",
    "            else:\n",
    "                channels_first = True\n",
    "\n",
    "        if channels_first:\n",
    "            forward_pattern = \"b c ... -> (b ...) c\"\n",
    "            backward_pattern = \"(b s) c -> b c s\"  # s stands for flattened spatial dimensions\n",
    "        else:\n",
    "            forward_pattern = \"b ... c -> (b ...) c\"\n",
    "            backward_pattern = \"(b s) c -> b s c\"\n",
    "\n",
    "        # Flatten input\n",
    "        x = rearrange(x, forward_pattern).contiguous()\n",
    "        # (BS, C)\n",
    "\n",
    "        z, codebook_loss, commitment_loss, perplexity = self.quantize(x)\n",
    "\n",
    "        # Return back to original shape\n",
    "        z = rearrange(z, backward_pattern, b=B).contiguous().reshape(shape)\n",
    "        # (x.shape)\n",
    "\n",
    "        if self.training and self.config.revive_dead_vectors_after_n_steps > 0:\n",
    "            self.revive_dead_vectors()\n",
    "\n",
    "        return z, codebook_loss, commitment_loss, perplexity\n",
    "\n",
    "    def _initialize_generator(self):\n",
    "        \"\"\"Initialize the random number generator to have the same seed across all devices.\"\"\"\n",
    "        assert not self.generator_initalized, \"Generator has already been initialized\"\n",
    "        seed = torch.randint(0, 2**32, (1,))\n",
    "        if dist.is_initialized():\n",
    "            dist.all_reduce(seed, op=dist.ReduceOp.MIN)\n",
    "        self.generator.manual_seed(seed.item())\n",
    "        self.generator_initalized = True\n",
    "\n",
    "    def _perform_ema(self, x: torch.Tensor, indices: torch.Tensor):\n",
    "        \"\"\"Perform EMA update of the codebook vectors.\n",
    "\n",
    "        Args:\n",
    "            x: Input vectors. Should be of shape (BS, C) where BS is a combination of batch and spatial/temporal\n",
    "                dimensions.\n",
    "            indices: Indices of the codebook vectors chosen for each input vector. Should be of shape (BS,).\n",
    "        \"\"\"\n",
    "        # Create one-hot encodings for the selected indices\n",
    "        encodings = self._one_hot_indices(indices)\n",
    "\n",
    "        # Calculate new cluster sizes with EMA\n",
    "        batch_cluster_size = encodings.sum(0)  # Sum over batch dimension\n",
    "\n",
    "        # Synchronize across devices if using distributed training\n",
    "        if dist.is_initialized():\n",
    "            dist.all_reduce(batch_cluster_size, op=dist.ReduceOp.SUM)\n",
    "\n",
    "        # Update cluster size using EMA\n",
    "        self.cluster_size.data = self.cluster_size * self.decay + (1 - self.decay) * batch_cluster_size\n",
    "\n",
    "        # Calculate sum of embeddings assigned to each cluster\n",
    "        batch_ema_vectors = torch.matmul(encodings.t(), x)\n",
    "\n",
    "        # Synchronize across devices if using distributed training\n",
    "        if dist.is_initialized():\n",
    "            dist.all_reduce(batch_ema_vectors, op=dist.ReduceOp.SUM)\n",
    "\n",
    "        # Update EMA for vectors\n",
    "        self.ema_vectors.data = self.ema_vectors * self.decay + (1 - self.decay) * batch_ema_vectors\n",
    "\n",
    "        # Normalize EMA vectors by cluster size\n",
    "        n = self.cluster_size.sum()\n",
    "        cluster_size = (self.cluster_size + 1e-5) / (n + self.config.num_vectors * 1e-5) * n\n",
    "\n",
    "        # Normalize codebook vectors using Laplace smoothing\n",
    "        normalized_vectors = self.ema_vectors / cluster_size.unsqueeze(1)\n",
    "        self.vectors.weight.data = normalized_vectors\n",
    "\n",
    "    def _one_hot_indices(self, indices: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Convert indices to one-hot encodings.\"\"\"\n",
    "        encodings = torch.zeros(indices.shape[0], self.config.num_vectors, device=indices.device)\n",
    "        encodings.scatter_(1, indices.unsqueeze(1), 1)\n",
    "        return encodings\n",
    "\n",
    "    def _update_counters(self, indices):\n",
    "        \"\"\"Update usage and stale counters based on the indices used in the current batch.\"\"\"\n",
    "        # Create a tensor which counts the number of times a vector has been used\n",
    "        used_vector_indices, counts = torch.unique(indices, return_counts=True)\n",
    "        usage_counter_increment = torch.zeros_like(self.usage_counter)\n",
    "        usage_counter_increment[used_vector_indices] = counts\n",
    "\n",
    "        # Synchronise the usage counts across all devices\n",
    "        if dist.is_initialized():\n",
    "            dist.all_reduce(usage_counter_increment, op=dist.ReduceOp.SUM)\n",
    "\n",
    "        # Don't allow counters to exceed maximum possible values\n",
    "        approximate_max_value = int(torch.iinfo(torch.long).max * 0.5)\n",
    "        self.usage_counter.clamp_(max=approximate_max_value)\n",
    "        self.stale_counter.clamp_(max=approximate_max_value)\n",
    "\n",
    "        # Update usage counter\n",
    "        self.usage_counter += usage_counter_increment\n",
    "\n",
    "        # Identify vectors that were not used across all devices\n",
    "        stale_counter_increment = torch.zeros_like(self.stale_counter)\n",
    "        stale_counter_increment[usage_counter_increment == 0] = 1\n",
    "\n",
    "        # Incrememnt counts of stale vectors and reset counts of used vectors\n",
    "        self.stale_counter += stale_counter_increment\n",
    "        self.stale_counter[usage_counter_increment > 0] = 0\n",
    "\n",
    "    def _estimate_codebook_distance(self, max_sample=500) -> torch.Tensor:\n",
    "        \"\"\"Estimate mean distance between codebook vectors\"\"\"\n",
    "        with torch.no_grad():\n",
    "            vectors_weight = self.vectors.weight\n",
    "            if self.vectors.weight.shape[0] > max_sample:\n",
    "                # Sample a subset for efficiency\n",
    "                idx = torch.randperm(self.vectors.weight.shape[0], generator=self.generator)[:max_sample]\n",
    "                vectors_weight = self.vectors.weight[idx]\n",
    "\n",
    "            distances = torch.cdist(vectors_weight, vectors_weight)\n",
    "            mask = ~torch.eye(distances.shape[0], dtype=torch.bool, device=distances.device)  # Exclude self-distances\n",
    "            codebook_distance = distances[mask].mean()\n",
    "\n",
    "        return codebook_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mCodebook\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mvectors\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1024\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m.\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0.6075\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMeanBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m25.3339\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m16\u001b[0m,  \u001b[1;36m31\u001b[0m, \u001b[1;36m113\u001b[0m, \u001b[1;36m106\u001b[0m, \u001b[1;36m189\u001b[0m,  \u001b[1;36m62\u001b[0m, \u001b[1;36m104\u001b[0m,  \u001b[1;36m83\u001b[0m,  \u001b[1;36m91\u001b[0m,  \u001b[1;36m70\u001b[0m,  \u001b[1;36m22\u001b[0m,   \u001b[1;36m7\u001b[0m,  \u001b[1;36m54\u001b[0m,  \u001b[1;36m39\u001b[0m,\n",
       "         \u001b[1;36m60\u001b[0m,  \u001b[1;36m36\u001b[0m,  \u001b[1;36m73\u001b[0m,  \u001b[1;36m52\u001b[0m,   \u001b[1;36m5\u001b[0m,  \u001b[1;36m26\u001b[0m,  \u001b[1;36m24\u001b[0m, \u001b[1;36m112\u001b[0m,  \u001b[1;36m42\u001b[0m,  \u001b[1;36m12\u001b[0m,  \u001b[1;36m59\u001b[0m, \u001b[1;36m109\u001b[0m, \u001b[1;36m127\u001b[0m, \u001b[1;36m104\u001b[0m,\n",
       "        \u001b[1;36m146\u001b[0m,  \u001b[1;36m39\u001b[0m,  \u001b[1;36m77\u001b[0m,  \u001b[1;36m22\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m18\u001b[0m,  \u001b[1;36m33\u001b[0m, \u001b[1;36m114\u001b[0m, \u001b[1;36m112\u001b[0m, \u001b[1;36m192\u001b[0m,  \u001b[1;36m67\u001b[0m, \u001b[1;36m105\u001b[0m,  \u001b[1;36m86\u001b[0m,  \u001b[1;36m93\u001b[0m,  \u001b[1;36m70\u001b[0m,  \u001b[1;36m26\u001b[0m,   \u001b[1;36m8\u001b[0m,  \u001b[1;36m57\u001b[0m,  \u001b[1;36m40\u001b[0m,\n",
       "         \u001b[1;36m62\u001b[0m,  \u001b[1;36m37\u001b[0m,  \u001b[1;36m75\u001b[0m,  \u001b[1;36m53\u001b[0m,   \u001b[1;36m5\u001b[0m,  \u001b[1;36m29\u001b[0m,  \u001b[1;36m24\u001b[0m, \u001b[1;36m114\u001b[0m,  \u001b[1;36m45\u001b[0m,  \u001b[1;36m12\u001b[0m,  \u001b[1;36m60\u001b[0m, \u001b[1;36m110\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m109\u001b[0m,\n",
       "        \u001b[1;36m149\u001b[0m,  \u001b[1;36m40\u001b[0m,  \u001b[1;36m80\u001b[0m,  \u001b[1;36m23\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m,\n",
       "        \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m20\u001b[0m,  \u001b[1;36m35\u001b[0m, \u001b[1;36m115\u001b[0m, \u001b[1;36m118\u001b[0m, \u001b[1;36m195\u001b[0m,  \u001b[1;36m72\u001b[0m, \u001b[1;36m106\u001b[0m,  \u001b[1;36m89\u001b[0m,  \u001b[1;36m95\u001b[0m,   \u001b[1;36m0\u001b[0m,  \u001b[1;36m30\u001b[0m,   \u001b[1;36m9\u001b[0m,  \u001b[1;36m60\u001b[0m,  \u001b[1;36m41\u001b[0m,\n",
       "         \u001b[1;36m64\u001b[0m,  \u001b[1;36m38\u001b[0m,  \u001b[1;36m77\u001b[0m,  \u001b[1;36m54\u001b[0m,   \u001b[1;36m0\u001b[0m,  \u001b[1;36m32\u001b[0m,   \u001b[1;36m0\u001b[0m, \u001b[1;36m116\u001b[0m,  \u001b[1;36m48\u001b[0m,   \u001b[1;36m0\u001b[0m,  \u001b[1;36m61\u001b[0m, \u001b[1;36m111\u001b[0m, \u001b[1;36m129\u001b[0m, \u001b[1;36m114\u001b[0m,\n",
       "        \u001b[1;36m152\u001b[0m,  \u001b[1;36m41\u001b[0m,  \u001b[1;36m83\u001b[0m,  \u001b[1;36m24\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "        \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m.\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0.4716\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMeanBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m23.6258\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = Codebook(num_vectors=32, dim=8, revive_dead_vectors_after_n_steps=3, use_ema=False)\n",
    "display(test)\n",
    "\n",
    "sample_input = torch.randn(2, 2**10, 8, requires_grad=True)\n",
    "output = test(sample_input)\n",
    "display([output[0].shape, *output[1:]])\n",
    "\n",
    "sample_input = torch.randn(8, 8, 2, 2, 2, requires_grad=True)\n",
    "output = test(sample_input)\n",
    "display([test.usage_counter, test.stale_counter])\n",
    "output = test(sample_input)\n",
    "display([test.usage_counter, test.stale_counter])\n",
    "output = test(sample_input)\n",
    "display([test.usage_counter, test.stale_counter])\n",
    "display([output[0].shape, *output[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mCodebook\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mvectors\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1024\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m.\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0.6198\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMeanBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m25.6295\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m117\u001b[0m,  \u001b[1;36m74\u001b[0m,  \u001b[1;36m61\u001b[0m,  \u001b[1;36m66\u001b[0m,  \u001b[1;36m75\u001b[0m,  \u001b[1;36m88\u001b[0m,  \u001b[1;36m65\u001b[0m,  \u001b[1;36m54\u001b[0m,  \u001b[1;36m57\u001b[0m,   \u001b[1;36m9\u001b[0m,   \u001b[1;36m7\u001b[0m, \u001b[1;36m166\u001b[0m,  \u001b[1;36m19\u001b[0m,  \u001b[1;36m19\u001b[0m,\n",
       "         \u001b[1;36m30\u001b[0m,  \u001b[1;36m97\u001b[0m,  \u001b[1;36m91\u001b[0m, \u001b[1;36m152\u001b[0m,  \u001b[1;36m60\u001b[0m, \u001b[1;36m120\u001b[0m,  \u001b[1;36m14\u001b[0m,  \u001b[1;36m26\u001b[0m, \u001b[1;36m165\u001b[0m,  \u001b[1;36m51\u001b[0m,  \u001b[1;36m28\u001b[0m,  \u001b[1;36m12\u001b[0m,  \u001b[1;36m80\u001b[0m,  \u001b[1;36m48\u001b[0m,\n",
       "         \u001b[1;36m78\u001b[0m,  \u001b[1;36m99\u001b[0m,  \u001b[1;36m32\u001b[0m,  \u001b[1;36m52\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "        \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m118\u001b[0m,  \u001b[1;36m77\u001b[0m,  \u001b[1;36m62\u001b[0m,  \u001b[1;36m68\u001b[0m,  \u001b[1;36m79\u001b[0m,  \u001b[1;36m92\u001b[0m,  \u001b[1;36m68\u001b[0m,  \u001b[1;36m57\u001b[0m,  \u001b[1;36m61\u001b[0m,   \u001b[1;36m9\u001b[0m,   \u001b[1;36m9\u001b[0m, \u001b[1;36m169\u001b[0m,  \u001b[1;36m21\u001b[0m,  \u001b[1;36m20\u001b[0m,\n",
       "         \u001b[1;36m32\u001b[0m,  \u001b[1;36m99\u001b[0m,  \u001b[1;36m93\u001b[0m, \u001b[1;36m155\u001b[0m,  \u001b[1;36m60\u001b[0m, \u001b[1;36m124\u001b[0m,  \u001b[1;36m15\u001b[0m,  \u001b[1;36m26\u001b[0m, \u001b[1;36m173\u001b[0m,  \u001b[1;36m52\u001b[0m,  \u001b[1;36m29\u001b[0m,  \u001b[1;36m12\u001b[0m,  \u001b[1;36m82\u001b[0m,  \u001b[1;36m50\u001b[0m,\n",
       "         \u001b[1;36m79\u001b[0m,  \u001b[1;36m99\u001b[0m,  \u001b[1;36m32\u001b[0m,  \u001b[1;36m54\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "        \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m119\u001b[0m,  \u001b[1;36m80\u001b[0m,  \u001b[1;36m63\u001b[0m,  \u001b[1;36m70\u001b[0m,  \u001b[1;36m83\u001b[0m,  \u001b[1;36m96\u001b[0m,  \u001b[1;36m71\u001b[0m,  \u001b[1;36m60\u001b[0m,  \u001b[1;36m65\u001b[0m,   \u001b[1;36m0\u001b[0m,  \u001b[1;36m11\u001b[0m, \u001b[1;36m172\u001b[0m,  \u001b[1;36m23\u001b[0m,  \u001b[1;36m21\u001b[0m,\n",
       "         \u001b[1;36m34\u001b[0m, \u001b[1;36m101\u001b[0m,  \u001b[1;36m95\u001b[0m, \u001b[1;36m158\u001b[0m,   \u001b[1;36m0\u001b[0m, \u001b[1;36m128\u001b[0m,  \u001b[1;36m16\u001b[0m,   \u001b[1;36m0\u001b[0m, \u001b[1;36m181\u001b[0m,  \u001b[1;36m53\u001b[0m,  \u001b[1;36m30\u001b[0m,   \u001b[1;36m0\u001b[0m,  \u001b[1;36m84\u001b[0m,  \u001b[1;36m52\u001b[0m,\n",
       "         \u001b[1;36m80\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m0\u001b[0m,  \u001b[1;36m56\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "        \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m.\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0.5265\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMeanBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m22.1967\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = Codebook(num_vectors=32, dim=8, revive_dead_vectors_after_n_steps=3, use_ema=True)\n",
    "display(test)\n",
    "\n",
    "sample_input = torch.randn(2, 2**10, 8, requires_grad=True)\n",
    "output = test(sample_input)\n",
    "display([output[0].shape, *output[1:]])\n",
    "\n",
    "sample_input = torch.randn(8, 8, 2, 2, 2, requires_grad=True)\n",
    "output = test(sample_input)\n",
    "display([test.usage_counter, test.stale_counter])\n",
    "output = test(sample_input)\n",
    "display([test.usage_counter, test.stale_counter])\n",
    "output = test(sample_input)\n",
    "display([test.usage_counter, test.stale_counter])\n",
    "display([output[0].shape, *output[1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
