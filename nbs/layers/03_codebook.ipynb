{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp layers/codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from torch import nn\n",
    "\n",
    "from vision_architectures.utils.custom_base_model import CustomBaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class CodebookConfig(CustomBaseModel):\n",
    "    num_vectors: int\n",
    "    dim: int\n",
    "\n",
    "    revive_dead_vectors_after_n_steps: int = 100  # 0 means never revive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Codebook(nn.Module):\n",
    "    def __init__(self, config: CodebookConfig = {}, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = CodebookConfig.model_validate(config | kwargs)\n",
    "\n",
    "        num_vectors = self.config.num_vectors\n",
    "        dim = self.config.dim\n",
    "\n",
    "        self.vectors = nn.Embedding(num_vectors, dim)\n",
    "\n",
    "        usage_counter = torch.zeros(num_vectors)  # +ve => used for the past n steps, -ve => unused for the past n steps\n",
    "        self.register_buffer(\"usage_counter\", usage_counter, persistent=False)\n",
    "        self.usage_counter: torch.Tensor  # For hinting\n",
    "\n",
    "    def quantize(self, x: torch.Tensor, channels_first: bool = None):\n",
    "        #  If channels_first is None: x: (B, T, C) if ndim == 3, else (B, C, ...)\n",
    "        #  If channels_first is True: x: (B, C, ...)\n",
    "        #  If channels_first is False: x: (B, ..., C)\n",
    "\n",
    "        shape = x.shape\n",
    "        ndim = x.ndim\n",
    "        B = shape[0]\n",
    "\n",
    "        if channels_first is None:\n",
    "            if ndim == 3:\n",
    "                channels_first = False\n",
    "            else:\n",
    "                channels_first = True\n",
    "\n",
    "        if channels_first:\n",
    "            forward_pattern = \"b c ... -> (b ...) c\"\n",
    "            backward_pattern = \"(b s) c -> b c s\"  # s stands for flattened spatial dimensions\n",
    "        else:\n",
    "            forward_pattern = \"b ... c -> (b ...) c\"\n",
    "            backward_pattern = \"(b s) c -> b s c\"\n",
    "\n",
    "        # Flatten input\n",
    "        x = rearrange(x, forward_pattern)\n",
    "\n",
    "        # Compute distances\n",
    "        distances = torch.cdist(x, self.vectors.weight)\n",
    "\n",
    "        # Find nearest vectors\n",
    "        indices = torch.argmin(distances, dim=1)\n",
    "\n",
    "        # Quantize and allow gradients to propogate\n",
    "        z = self.vectors(indices)\n",
    "        z = x + (z - x).detach()\n",
    "\n",
    "        # Update counters\n",
    "        used_vector_indices = torch.unique(indices)\n",
    "        used_vector_mask = torch.scatter(\n",
    "            torch.zeros_like(self.usage_counter, dtype=torch.bool), 0, used_vector_indices, True\n",
    "        )\n",
    "        max_value = 2**16\n",
    "        self.usage_counter[used_vector_mask] = self.usage_counter[used_vector_mask] + 1\n",
    "        self.usage_counter[used_vector_mask] = self.usage_counter[used_vector_mask].clamp(min=1, max=max_value)\n",
    "        self.usage_counter[~used_vector_mask] = self.usage_counter[~used_vector_mask] - 1\n",
    "        self.usage_counter[~used_vector_mask] = self.usage_counter[~used_vector_mask].clamp(min=-max_value, max=-1)\n",
    "\n",
    "        # Loss calculations\n",
    "        codebook_loss = torch.mean((z.detach() - x) ** 2)\n",
    "        commitment_loss = torch.mean((z - x.detach()) ** 2)\n",
    "\n",
    "        # Return back to original shape\n",
    "        z = rearrange(z, backward_pattern, b=B).reshape(shape)\n",
    "\n",
    "        # Calculate perplexity\n",
    "        with torch.no_grad():\n",
    "            encodings = torch.zeros(x.shape[0], self.config.num_vectors, device=x.device)\n",
    "            encodings.scatter_(1, indices.unsqueeze(1), 1)\n",
    "            avg_probs = encodings.float().mean(0)\n",
    "            perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "\n",
    "        return z, codebook_loss, commitment_loss, perplexity\n",
    "\n",
    "    def revive_dead_vectors(self):\n",
    "        revive_vector_mask = self.usage_counter <= -self.config.revive_dead_vectors_after_n_steps\n",
    "        if not revive_vector_mask.any():\n",
    "            return\n",
    "\n",
    "        revive_vectors_shape = self.vectors.weight[revive_vector_mask].shape\n",
    "        num_revive_vectors = revive_vectors_shape[0]\n",
    "\n",
    "        # Sample commonly used vectors from the codebook\n",
    "        sampling_probabilities = self.usage_counter.clone()\n",
    "        sampling_probabilities = (\n",
    "            sampling_probabilities - sampling_probabilities[~revive_vector_mask].min() + 1e-9\n",
    "        )  # Make all positive, avoid all being 0\n",
    "        sampling_probabilities[revive_vector_mask] = 0  # Don't sample dead vectors\n",
    "        selected_vectors_mask = torch.multinomial(sampling_probabilities, num_revive_vectors, replacement=True)\n",
    "        selected_vectors = self.vectors(selected_vectors_mask).detach()\n",
    "\n",
    "        # Add noise to the selected vectors\n",
    "        with torch.no_grad():\n",
    "            std = self._estimate_codebook_distance() * 0.1\n",
    "        noised_selected_vectors = selected_vectors + torch.randn_like(selected_vectors) * std\n",
    "\n",
    "        # Replace dead vectors with noised selected vectors\n",
    "        self.vectors.weight.data[revive_vector_mask] = noised_selected_vectors\n",
    "\n",
    "        self.usage_counter[revive_vector_mask] = 0\n",
    "\n",
    "    def forward(self, x: torch.Tensor, channels_first: bool = None):\n",
    "        quantized_output = self.quantize(x, channels_first)\n",
    "        if self.config.revive_dead_vectors_after_n_steps > 0:\n",
    "            self.revive_dead_vectors()\n",
    "        return quantized_output\n",
    "\n",
    "    def _estimate_codebook_distance(self, max_sample=500):\n",
    "        \"\"\"Estimate mean distance between codebook vectors\"\"\"\n",
    "        with torch.no_grad():\n",
    "            if self.vectors.weight.shape[0] > max_sample:\n",
    "                # Sample a subset for efficiency\n",
    "                idx = torch.randperm(self.vectors.weight.shape[0])[:100]\n",
    "                vectors_weight = self.vectors.weight[idx]\n",
    "            else:\n",
    "                vectors_weight = self.vectors.weight\n",
    "\n",
    "            distances = torch.cdist(vectors_weight, vectors_weight)\n",
    "            mask = ~torch.eye(distances.shape[0], dtype=torch.bool, device=distances.device)  # Exclude self-distances\n",
    "            codebook_distance = distances[mask].mean()\n",
    "\n",
    "        return codebook_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mCodebook\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mvectors\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1024\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0.6643\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMeanBackward0\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0.6643\u001b[0m\u001b[39m, \u001b[0m\u001b[33mgrad_fn\u001b[0m\u001b[39m=<MeanBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m23.4808\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1\u001b[0m.,  \u001b[1;36m2\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m.,  \u001b[1;36m2\u001b[0m.,  \u001b[1;36m2\u001b[0m., \u001b[1;36m-1\u001b[0m.,  \u001b[1;36m2\u001b[0m.,  \u001b[1;36m2\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m.,\n",
       "         \u001b[1;36m2\u001b[0m.,  \u001b[1;36m2\u001b[0m.,  \u001b[1;36m2\u001b[0m., \u001b[1;36m-1\u001b[0m.,  \u001b[1;36m2\u001b[0m.,  \u001b[1;36m2\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m.,  \u001b[1;36m2\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m.,\n",
       "        \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m., \u001b[1;36m3\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m3\u001b[0m., \u001b[1;36m3\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m3\u001b[0m., \u001b[1;36m3\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m3\u001b[0m., \u001b[1;36m3\u001b[0m., \u001b[1;36m3\u001b[0m., \u001b[1;36m0\u001b[0m.,\n",
       "        \u001b[1;36m3\u001b[0m., \u001b[1;36m3\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m3\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m.,  \u001b[1;36m1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m.,  \u001b[1;36m4\u001b[0m.,  \u001b[1;36m1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m.,\n",
       "         \u001b[1;36m4\u001b[0m.,  \u001b[1;36m4\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m.,  \u001b[1;36m4\u001b[0m.,  \u001b[1;36m4\u001b[0m., \u001b[1;36m-1\u001b[0m.,  \u001b[1;36m1\u001b[0m., \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m.,  \u001b[1;36m1\u001b[0m.,  \u001b[1;36m4\u001b[0m.,  \u001b[1;36m1\u001b[0m., \u001b[1;36m-1\u001b[0m.,\n",
       "        \u001b[1;36m-1\u001b[0m., \u001b[1;36m-1\u001b[0m.,  \u001b[1;36m1\u001b[0m., \u001b[1;36m-1\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0.5741\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMeanBackward0\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0.5741\u001b[0m\u001b[39m, \u001b[0m\u001b[33mgrad_fn\u001b[0m\u001b[39m=<MeanBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m10.9497\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = Codebook(num_vectors=32, dim=8, revive_dead_vectors_after_n_steps=2)\n",
    "display(test)\n",
    "\n",
    "sample_input = torch.randn(2, 2**10, 8, requires_grad=True)\n",
    "output = test(sample_input)\n",
    "display([output[0].shape, *output[1:]])\n",
    "\n",
    "sample_input = torch.randn(2, 8, 2, 2, 2, requires_grad=True)\n",
    "output = test(sample_input)\n",
    "display(test.usage_counter)\n",
    "output = test(sample_input)\n",
    "display(test.usage_counter)\n",
    "output = test(sample_input)\n",
    "display(test.usage_counter)\n",
    "display([output[0].shape, *output[1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
