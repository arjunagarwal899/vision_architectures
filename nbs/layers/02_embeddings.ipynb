{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp layers/embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "from torch import nn\n",
    "\n",
    "from vision_architectures.utils.normalizations import get_norm_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_coords_grid(grid_size):\n",
    "    d, h, w = grid_size\n",
    "\n",
    "    grid_d = torch.arange(d, dtype=torch.int32)\n",
    "    grid_h = torch.arange(h, dtype=torch.int32)\n",
    "    grid_w = torch.arange(w, dtype=torch.int32)\n",
    "\n",
    "    grid = torch.meshgrid(grid_d, grid_h, grid_w, indexing=\"ij\")\n",
    "    grid = torch.stack(grid, axis=0)\n",
    "    # (3, d, h, w)\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class RelativePositionEmbeddings3D(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_heads,\n",
    "        grid_size: tuple[int, int, int],\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.num_patches = grid_size\n",
    "\n",
    "        # TODO: Add embed_spacing_info functionality\n",
    "\n",
    "        relative_limits = (2 * grid_size[0] - 1, 2 * grid_size[1] - 1, 2 * grid_size[2] - 1)\n",
    "\n",
    "        self.relative_position_bias_table = nn.Parameter(torch.randn(num_heads, np.prod(relative_limits)))\n",
    "        # (num_heads, num_patches_z * num_patches_y * num_patches_x)\n",
    "\n",
    "        # Pair-wise relative position index for each token inside the window\n",
    "        coords = get_coords_grid(grid_size)\n",
    "        coords_flatten = rearrange(coords, \"three d h w -> three (d h w)\", three=3)\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "        relative_coords[:, :, 0] += grid_size[0] - 1\n",
    "        relative_coords[:, :, 1] += grid_size[1] - 1\n",
    "        relative_coords[:, :, 2] += grid_size[2] - 1\n",
    "        relative_position_index: torch.Tensor = (\n",
    "            relative_coords[:, :, 0] * relative_limits[1] * relative_limits[2]\n",
    "            + relative_coords[:, :, 1] * relative_limits[2]\n",
    "            + relative_coords[:, :, 2]\n",
    "        )\n",
    "        self.relative_position_index = relative_position_index.flatten()\n",
    "        # (num_patches, num_patches)\n",
    "\n",
    "    def forward(self):\n",
    "        relative_position_embeddings = self.relative_position_bias_table[:, self.relative_position_index]\n",
    "        # (num_heads, num_patches, num_patches)\n",
    "        relative_position_embeddings = relative_position_embeddings.reshape(\n",
    "            1, np.prod(self.num_patches), np.prod(self.num_patches), -1\n",
    "        )\n",
    "        # (1, num_patches, num_patches, num_heads)\n",
    "        relative_position_embeddings = relative_position_embeddings.permute(0, 3, 1, 2).contiguous()\n",
    "        # (1, num_heads, num_patches, num_patches)\n",
    "        return relative_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mRelativePositionEmbeddings3D\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = RelativePositionEmbeddings3D(6, (4, 4, 4))\n",
    "display(test)\n",
    "display(test().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class RelativePositionEmbeddings3DMetaNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_heads,\n",
    "        grid_size: tuple[int, int, int],\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.num_patches = grid_size\n",
    "\n",
    "        # TODO: Add embed_spacing_info functionality\n",
    "        self.cpb_mlp = nn.Sequential(\n",
    "            nn.Linear(3, 512, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_heads, bias=False),\n",
    "        )\n",
    "\n",
    "        relative_limits = (2 * grid_size[0] - 1, 2 * grid_size[1] - 1, 2 * grid_size[2] - 1)\n",
    "\n",
    "        # Relative coordinates table\n",
    "        relative_coords_table = get_coords_grid(relative_limits).float()\n",
    "        for i in range(3):\n",
    "            relative_coords_table[i] = (relative_coords_table[i] - (grid_size[0] - 1)) / (\n",
    "                grid_size[0] - 1 + 1e-8  # small value added to ensure there is no NaN when window size is 1\n",
    "            )\n",
    "        relative_coords_table = rearrange(\n",
    "            relative_coords_table,\n",
    "            \"three num_patches_z num_patches_y num_patches_x -> num_patches_z num_patches_y num_patches_x three\",\n",
    "        ).contiguous()\n",
    "        relative_coords_table *= 8  # Normalize to -8, 8\n",
    "        relative_coords_table = (\n",
    "            torch.sign(relative_coords_table) * torch.log2(torch.abs(relative_coords_table) + 1.0) / np.log2(8)\n",
    "        )\n",
    "        # (num_patches_z, num_patches_y, num_patches_x, 3)\n",
    "        # Allow moving this to and from cuda whenever required but don't save to state_dict\n",
    "        self.register_buffer(\"relative_coords_table\", relative_coords_table, persistent=False)\n",
    "\n",
    "        # Pair-wise relative position index for each token inside the window\n",
    "        coords = get_coords_grid(grid_size)\n",
    "        coords_flatten = rearrange(coords, \"three d h w -> three (d h w)\", three=3)\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "        relative_coords[:, :, 0] += grid_size[0] - 1\n",
    "        relative_coords[:, :, 1] += grid_size[1] - 1\n",
    "        relative_coords[:, :, 2] += grid_size[2] - 1\n",
    "        relative_position_index: torch.Tensor = (\n",
    "            relative_coords[:, :, 0] * relative_limits[1] * relative_limits[2]\n",
    "            + relative_coords[:, :, 1] * relative_limits[2]\n",
    "            + relative_coords[:, :, 2]\n",
    "        )\n",
    "        self.relative_position_index = relative_position_index.flatten()\n",
    "        # (num_patches, num_patches)\n",
    "\n",
    "    def forward(self):\n",
    "        # (num_patches_z, num_patches_y, num_patches_x, 3)\n",
    "        relative_position_embeddings_table = self.cpb_mlp(self.relative_coords_table)\n",
    "        # (num_patches_z, num_patches_y, num_patches_x, num_heads)\n",
    "        relative_position_embeddings_table = relative_position_embeddings_table.reshape(-1, self.num_heads)\n",
    "        # (num_patches, num_heads)\n",
    "        relative_position_embeddings = relative_position_embeddings_table[self.relative_position_index]\n",
    "        # (num_patches * num_patches, num_heads)\n",
    "        relative_position_embeddings = rearrange(\n",
    "            relative_position_embeddings,\n",
    "            \"(num_patches1 num_patches2) num_heads -> num_heads num_patches1 num_patches2\",\n",
    "            num_patches1=np.prod(self.num_patches),\n",
    "            num_patches2=np.prod(self.num_patches),\n",
    "            num_heads=self.num_heads,\n",
    "        ).contiguous()\n",
    "        # (num_heads, num_patches, num_patches)\n",
    "        relative_position_embeddings = 16 * torch.sigmoid(relative_position_embeddings)\n",
    "        # (num_heads, num_patches, num_patches)\n",
    "        return relative_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mRelativePositionEmbeddings3DMetaNetwork\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m6\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = RelativePositionEmbeddings3DMetaNetwork(6, (4, 4, 4))\n",
    "display(test)\n",
    "display(test().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "RelativePositionEmbeddings = Union[RelativePositionEmbeddings3D, RelativePositionEmbeddings3DMetaNetwork]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_absolute_position_embeddings_3d(dim, grid_size, spacing=(1, 1, 1)):\n",
    "    if dim % 6 != 0:\n",
    "        raise ValueError(\"embed_dim must be divisible by 6\")\n",
    "\n",
    "    grid = get_coords_grid(grid_size)\n",
    "    # (3, d, h, w)\n",
    "\n",
    "    grid = rearrange(grid, \"x d h w -> x 1 d h w\")\n",
    "    # (3, 1, d, h, w)\n",
    "\n",
    "    omega = torch.arange(dim // 6, dtype=torch.float32)\n",
    "    omega /= dim / 6.0\n",
    "    omega = 1.0 / 10000**omega\n",
    "    # (dim // 6)\n",
    "\n",
    "    patch_multiplier = torch.Tensor(spacing) / min(spacing)\n",
    "\n",
    "    position_embeddings = []\n",
    "    for i, grid_subset in enumerate(grid):\n",
    "        grid_subset = grid_subset.reshape(-1)\n",
    "        out = torch.einsum(\"m,d->md\", grid_subset, omega)\n",
    "\n",
    "        emb_sin = torch.sin(out)\n",
    "        emb_cos = torch.cos(out)\n",
    "\n",
    "        emb = torch.cat([emb_sin, emb_cos], axis=1) * patch_multiplier[i]\n",
    "        position_embeddings.append(emb)\n",
    "\n",
    "    position_embeddings = torch.cat(position_embeddings, axis=1)\n",
    "    # (dim, d * h * w)\n",
    "    position_embeddings = rearrange(\n",
    "        position_embeddings, \"(d h w) e -> 1 e d h w\", d=grid_size[0], h=grid_size[1], w=grid_size[2]\n",
    "    )\n",
    "    # (1, dim, d, h, w)\n",
    "\n",
    "    return position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class AbsolutePositionEmbeddings3D(nn.Module):\n",
    "    def __init__(self, dim, grid_size: tuple[int, int, int] | None = None, learnable=False, spacing=(1, 1, 1)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "\n",
    "        if learnable and grid_size is None:\n",
    "            raise ValueError(\"grid_size must be provided when learnable=True\")\n",
    "\n",
    "        self.position_embeddings_cache = {}\n",
    "        self.position_embeddings = None\n",
    "        if grid_size is not None:\n",
    "            self.position_embeddings_cache[grid_size] = get_absolute_position_embeddings_3d(\n",
    "                dim, grid_size, spacing=spacing\n",
    "            )\n",
    "            self.position_embeddings = nn.Parameter(self.position_embeddings_cache[grid_size], requires_grad=learnable)\n",
    "\n",
    "    def forward(self, batch_size=None, grid_size=None, spacings=None, device=torch.device('cpu')):\n",
    "        assert (\n",
    "            self.position_embeddings is not None or grid_size is not None\n",
    "        ), \"grid_size must be provided\"\n",
    "        assert batch_size is not None or spacings is not None, \"Either batch_size or spacings must be provided\"\n",
    "\n",
    "        if self.position_embeddings is not None:\n",
    "            position_embeddings = self.position_embeddings\n",
    "        else:\n",
    "            if grid_size not in self.position_embeddings_cache:\n",
    "                self.position_embeddings_cache[grid_size] = get_absolute_position_embeddings_3d(self.dim, grid_size)\n",
    "            position_embeddings = self.position_embeddings_cache[grid_size].to(device)\n",
    "        # (1, dim, d, h, w)\n",
    "\n",
    "        if batch_size is not None:\n",
    "            b = batch_size\n",
    "        else:\n",
    "            assert spacings.ndim == 2 and spacings.shape[1] == 3, \"spacings must be of shape (batch_size, 3)\"\n",
    "            assert self.dim % 3 == 0, \"embed_dim must be divisible by 3\"\n",
    "\n",
    "            b = spacings.shape[0]\n",
    "\n",
    "        position_embeddings = repeat(position_embeddings, \"1 e d h w -> b e d h w\", b=b)\n",
    "\n",
    "        if spacings is not None:\n",
    "            # (b, 3)\n",
    "            spacings = repeat(spacings, \"b three -> b (three dim_by_three) 1 1 1\", three=3, dim_by_three=self.dim // 3)\n",
    "            # (b, dim, 1, 1, 1)\n",
    "\n",
    "            position_embeddings = position_embeddings * spacings\n",
    "            # (b, dim, d, h, w)\n",
    "\n",
    "        return position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mAbsolutePositionEmbeddings3D\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = AbsolutePositionEmbeddings3D(6, (4, 4, 4), learnable=True)\n",
    "display(test)\n",
    "display(test(batch_size=2).shape)\n",
    "display(test(spacings=torch.randn(4, 3)).shape)\n",
    "\n",
    "test = AbsolutePositionEmbeddings3D(6)\n",
    "display(test(grid_size=(3, 3, 3), batch_size=2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class PatchEmbeddings3D(nn.Module):\n",
    "    def __init__(self, patch_size: tuple[int, int, int], in_channels: int, dim: int, norm_layer=\"layernorm\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.patch_embeddings = nn.Conv3d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=patch_size,\n",
    "        )\n",
    "\n",
    "        if norm_layer is None:\n",
    "            self.normalization = nn.Identity()\n",
    "        elif isinstance(norm_layer, nn.Module):\n",
    "            self.normalization = norm_layer(dim)\n",
    "        else:\n",
    "            self.normalization = get_norm_layer(norm_layer, dim)\n",
    "\n",
    "    def forward(self, pixel_values: torch.Tensor):\n",
    "        # pixel_values: (b, c, z, y, x)\n",
    "\n",
    "        embeddings = self.patch_embeddings(pixel_values)\n",
    "        # (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "        embeddings = rearrange(embeddings, \"b d z y x -> b z y x d\")\n",
    "        # (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "        embeddings = self.normalization(embeddings)\n",
    "        # (b, num_patches_z, num_patches_y, num_patches_x, dim)\n",
    "        embeddings = rearrange(embeddings, \"b z y x d -> b d z y x\")\n",
    "        # (b, dim, num_patches_z, num_patches_y, num_patches_x)\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mPatchEmbeddings3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mpatch_embeddings\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mnormalization\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m12\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = PatchEmbeddings3D((1, 8, 8), 1, 12)\n",
    "display(test)\n",
    "o = test(torch.randn(2, 1, 32, 512, 512))\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough work"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "coords_h = torch.arange(4)\n",
    "coords_w = torch.arange(4)\n",
    "coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing=\"ij\"))\n",
    "coords_flatten = torch.flatten(coords, 1)\n",
    "relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "relative_coords[:, :, 0] += 4 - 1\n",
    "relative_coords[:, :, 1] += 4 - 1\n",
    "relative_coords[:, :, 0] *= 2 * 4 - 1\n",
    "relative_position_index = relative_coords.sum(-1)\n",
    "\n",
    "relative_position_index.min(), relative_position_index.max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "window_size = (4, 4, 4)\n",
    "relative_limits = (7, 7, 7)\n",
    "\n",
    "coords = get_coords_grid(window_size)\n",
    "coords_flatten = rearrange(coords, \"three_dimensional d h w -> three_dimensional (d h w)\", three_dimensional=3)\n",
    "relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "relative_coords[:, :, 0] += window_size[0] - 1\n",
    "relative_coords[:, :, 1] += window_size[1] - 1\n",
    "relative_coords[:, :, 2] += window_size[2] - 1\n",
    "relative_position_index: torch.Tensor = (\n",
    "    relative_coords[:, :, 0] * relative_limits[1] * relative_limits[2]\n",
    "    + relative_coords[:, :, 1] * relative_limits[2]\n",
    "    + relative_coords[:, :, 2]\n",
    ")\n",
    "\n",
    "relative_position_index.min(), relative_position_index.max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "window_size = (2, 2, 2)\n",
    "relative_limits = (2 * window_size[0] - 1, 2 * window_size[1] - 1, 2 * window_size[2] - 1)\n",
    "\n",
    "relative_coords_table = get_coords_grid(relative_limits)\n",
    "relative_coords_table[0] -= window_size[0] - 1\n",
    "relative_coords_table[1] -= window_size[1] - 1\n",
    "relative_coords_table[2] -= window_size[2] - 1\n",
    "relative_coords_table = relative_coords_table.permute(1, 2, 3, 0).contiguous()\n",
    "relative_coords_table[0, 2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
