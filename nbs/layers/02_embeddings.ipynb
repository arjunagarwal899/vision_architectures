{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp layers/embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9ee232",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from functools import lru_cache\n",
    "from typing import Literal, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from einops import rearrange, repeat\n",
    "from torch import nn\n",
    "\n",
    "from vision_architectures.blocks.cnn import CNNBlock3D, CNNBlockConfig\n",
    "from vision_architectures.docstrings import populate_docstring\n",
    "from vision_architectures.utils.activation_checkpointing import ActivationCheckpointing\n",
    "from vision_architectures.utils.custom_base_model import CustomBaseModel, Field, model_validator\n",
    "from vision_architectures.utils.rearrange import rearrange_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f5243",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f98092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class RelativePositionEmbeddings3DConfig(CustomBaseModel):\n",
    "    num_heads: int = Field(..., description=\"Number of query attention heads\")\n",
    "    grid_size: tuple[int, int, int] = Field(..., description=\"Size of entire patch matrix.\")\n",
    "\n",
    "    @property\n",
    "    def num_patches(self) -> int:\n",
    "        \"\"\"Number of patches.\"\"\"\n",
    "        return np.prod(self.grid_size)\n",
    "\n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def validate_before(cls, data):\n",
    "        grid_size = data.get(\"grid_size\")\n",
    "        if isinstance(data[\"grid_size\"], int):\n",
    "            data[\"grid_size\"] = (grid_size, grid_size, grid_size)\n",
    "        return data\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate(self):\n",
    "        super().validate()\n",
    "        if isinstance(self.grid_size, int):\n",
    "            self.grid_size = (self.grid_size, self.grid_size, self.grid_size)\n",
    "        return self\n",
    "\n",
    "\n",
    "class AbsolutePositionEmbeddings3DConfig(CustomBaseModel):\n",
    "    dim: int | None = Field(None, description=\"Dimension of the position embeddings\")\n",
    "    grid_size: tuple[int, int, int] | None = Field(None, description=\"Size of entire patch matrix.\")\n",
    "    learnable: bool = Field(False, description=\"Whether the position embeddings are learnable.\")\n",
    "\n",
    "    @property\n",
    "    def num_patches(self) -> int:\n",
    "        \"\"\"Number of patches.\"\"\"\n",
    "        if self.grid_size is None:\n",
    "            return None\n",
    "        return np.prod(self.grid_size)\n",
    "\n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def validate_before(cls, data):\n",
    "        if isinstance(data.get(\"grid_size\"), int):\n",
    "            data[\"grid_size\"] = (\n",
    "                data[\"grid_size\"],\n",
    "                data[\"grid_size\"],\n",
    "                data[\"grid_size\"],\n",
    "            )\n",
    "        return data\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate(self):\n",
    "        super().validate()\n",
    "        if self.learnable and (self.dim is None or self.grid_size is None):\n",
    "            raise ValueError(\"dim and grid_size must be provided if learnable is True\")\n",
    "        return self\n",
    "\n",
    "\n",
    "class AbsolutePositionEmbeddings1DConfig(CustomBaseModel):\n",
    "    dim: int | None = Field(None, description=\"Dimension of the position embeddings\")\n",
    "    length: int | None = Field(None, description=\"Length of the sequence.\")\n",
    "    learnable: bool = Field(False, description=\"Whether the position embeddings are learnable.\")\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate(self):\n",
    "        super().validate()\n",
    "        if self.learnable and (self.dim is None or self.length is None):\n",
    "            raise ValueError(\"dim and length must be provided if learnable is True\")\n",
    "        return self\n",
    "\n",
    "\n",
    "class RotaryPositionEmbeddings1DConfig(CustomBaseModel):\n",
    "    dim: int | None = Field(None, description=\"Dimension of the position embeddings\")\n",
    "\n",
    "    base: float = Field(10000.0, description=\"Base value for the exponent.\")\n",
    "\n",
    "\n",
    "class RotaryPositionEmbeddings3DConfig(RotaryPositionEmbeddings1DConfig):\n",
    "    split: tuple[float, float, float] | tuple[int, int, int] = Field(\n",
    "        (1 / 3, 1 / 3, 1 / 3),\n",
    "        description=\"Split of the position embeddings. If float, converted to int based on self.dim\",\n",
    "    )\n",
    "\n",
    "    def get_split_as_ints(self, dim: int | None):\n",
    "        if isinstance(self.split[0], int):\n",
    "            return self.split\n",
    "\n",
    "        if dim is None:\n",
    "            dim = self.dim\n",
    "        assert dim is not None, \"dim must be provided if not specified in config\"\n",
    "\n",
    "        return tuple(int(s * dim) for s in self.split)\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate(self):\n",
    "        super().validate()\n",
    "        if self.dim is not None and isinstance(self.split[0], int):\n",
    "            assert sum(self.split) <= self.dim, \"Sum of split must be less than or equal to dim\"\n",
    "        return self\n",
    "\n",
    "\n",
    "class PatchEmbeddings3DConfig(CNNBlockConfig):\n",
    "    patch_size: tuple[int, int, int] = Field(..., description=\"Size of the patches to extract from the input.\")\n",
    "    in_channels: int = Field(..., description=\"Number of input channels.\")\n",
    "    dim: int = Field(..., description=\"Dimension of the embeddings.\")\n",
    "    norm_layer: str = Field(\"layernorm\", description=\"Normalization layer to use.\")\n",
    "\n",
    "    out_channels: None = None\n",
    "    kernel_size: None = None\n",
    "\n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def validate_before(cls, data: dict):\n",
    "        data.setdefault(\"patch_size\", data.pop(\"kernel_size\", None))\n",
    "        data.setdefault(\"dim\", data.pop(\"out_channels\", None))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f67d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsolutePositionEmbeddingsConfig = Union[AbsolutePositionEmbeddings1DConfig, AbsolutePositionEmbeddings3DConfig]\n",
    "RotaryPositionEmbeddingsConfig = Union[RotaryPositionEmbeddings1DConfig, RotaryPositionEmbeddings3DConfig]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ac2ad1",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d585e65",
   "metadata": {},
   "source": [
    "### Position Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c65e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_coords_grid(grid_size: tuple[int, int, int]) -> torch.Tensor:\n",
    "    \"\"\"Get a coordinate grid of shape (3, d, h, w) for a given grid size.\n",
    "\n",
    "    Args:\n",
    "        grid_size: Size of the grid (d, h, w).\n",
    "\n",
    "    Returns:\n",
    "        A tensor of shape (3, d, h, w) containing the coordinates.\n",
    "    \"\"\"\n",
    "    d, h, w = grid_size\n",
    "\n",
    "    grid_d = torch.arange(d, dtype=torch.int32)\n",
    "    grid_h = torch.arange(h, dtype=torch.int32)\n",
    "    grid_w = torch.arange(w, dtype=torch.int32)\n",
    "\n",
    "    grid = torch.meshgrid(grid_d, grid_h, grid_w, indexing=\"ij\")\n",
    "    grid = torch.stack(grid, axis=0)\n",
    "    # (3, d, h, w)\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279d31aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@populate_docstring\n",
    "class RelativePositionEmbeddings3D(nn.Module):\n",
    "    \"\"\"Learnable 3D Relative Position Embeddings. This can be passed directly to the attention layers.\n",
    "    {CLASS_DESCRIPTION_3D_DOC}\"\"\"\n",
    "\n",
    "    @populate_docstring\n",
    "    def __init__(self, config: RelativePositionEmbeddings3DConfig = {}, **kwargs):\n",
    "        \"\"\"Initialize RelativePositionEmbeddings3D.\n",
    "\n",
    "        Args:\n",
    "            config: {CONFIG_INSTANCE_DOC}\n",
    "            **kwargs: {CONFIG_KWARGS_DOC}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = RelativePositionEmbeddings3DConfig.model_validate(config | kwargs)\n",
    "\n",
    "        num_heads = self.config.num_heads\n",
    "        grid_size = self.config.grid_size\n",
    "\n",
    "        # TODO: Add embed_spacing_info functionality\n",
    "\n",
    "        relative_limits = (\n",
    "            2 * grid_size[0] - 1,\n",
    "            2 * grid_size[1] - 1,\n",
    "            2 * grid_size[2] - 1,\n",
    "        )\n",
    "\n",
    "        self.relative_position_bias_table = nn.Parameter(torch.randn(num_heads, np.prod(relative_limits)))\n",
    "        # (num_heads, num_patches_z * num_patches_y * num_patches_x)\n",
    "\n",
    "        # Pair-wise relative position index for each token inside the window\n",
    "        coords = get_coords_grid(grid_size)\n",
    "        coords_flatten = rearrange(coords, \"three d h w -> three (d h w)\", three=3).contiguous()\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "        relative_coords[:, :, 0] += grid_size[0] - 1\n",
    "        relative_coords[:, :, 1] += grid_size[1] - 1\n",
    "        relative_coords[:, :, 2] += grid_size[2] - 1\n",
    "        relative_position_index: torch.Tensor = (\n",
    "            relative_coords[:, :, 0] * relative_limits[1] * relative_limits[2]\n",
    "            + relative_coords[:, :, 1] * relative_limits[2]\n",
    "            + relative_coords[:, :, 2]\n",
    "        )\n",
    "        self.relative_position_index = relative_position_index.flatten()\n",
    "        # (num_patches, num_patches)\n",
    "\n",
    "    def forward(self) -> torch.Tensor:\n",
    "        \"\"\"Get relative position embeddings as specified by the config.\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape (1, num_heads, num_patches, num_patches) containing the relative position embeddings.\n",
    "        \"\"\"\n",
    "        relative_position_embeddings = self.relative_position_bias_table[:, self.relative_position_index].contiguous()\n",
    "        # (num_heads, num_patches, num_patches)\n",
    "        relative_position_embeddings = relative_position_embeddings.reshape(\n",
    "            1, self.config.num_patches, self.config.num_patches, -1\n",
    "        )\n",
    "        # (1, num_patches, num_patches, num_heads)\n",
    "        relative_position_embeddings = rearrange(\n",
    "            relative_position_embeddings,\n",
    "            \"1 num_patches1 num_patches2 num_heads -> 1 num_heads num_patches1 num_patches2\",\n",
    "        ).contiguous()\n",
    "        # (1, num_heads, num_patches, num_patches)\n",
    "        return relative_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a66759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RelativePositionEmbeddings3D</span><span style=\"font-weight: bold\">()</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mRelativePositionEmbeddings3D\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = RelativePositionEmbeddings3D(num_heads=6, grid_size=4)\n",
    "display(test)\n",
    "display(test().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832df173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@populate_docstring\n",
    "class RelativePositionEmbeddings3DMetaNetwork(nn.Module):\n",
    "    \"\"\"3D Relative Position Embeddings obtained from a meta network (inspired by SwinV2). This can be passed directly\n",
    "    to the attention layers. {CLASS_DESCRIPTION_3D_DOC}\"\"\"\n",
    "\n",
    "    @populate_docstring\n",
    "    def __init__(self, config: RelativePositionEmbeddings3DConfig = {}, checkpointing_level: int = 0, **kwargs):\n",
    "        \"\"\"Initialize RelativePositionEmbeddings3DMetaNetwork.\n",
    "\n",
    "        Args:\n",
    "            config: {CONFIG_INSTANCE_DOC}\n",
    "            checkpointing_level: {CHECKPOINTING_LEVEL_DOC}\n",
    "            **kwargs: {CONFIG_KWARGS_DOC}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = RelativePositionEmbeddings3DConfig.model_validate(config | kwargs)\n",
    "\n",
    "        num_heads = self.config.num_heads\n",
    "        grid_size = self.config.grid_size\n",
    "\n",
    "        # TODO: Add embed_spacing_info functionality\n",
    "        self.cpb_mlp = nn.Sequential(\n",
    "            nn.Linear(3, 512, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_heads, bias=False),\n",
    "        )\n",
    "\n",
    "        relative_limits = (\n",
    "            2 * grid_size[0] - 1,\n",
    "            2 * grid_size[1] - 1,\n",
    "            2 * grid_size[2] - 1,\n",
    "        )\n",
    "\n",
    "        # Relative coordinates table\n",
    "        relative_coords_table = get_coords_grid(relative_limits).float()\n",
    "        for i in range(3):\n",
    "            relative_coords_table[i] = (relative_coords_table[i] - (grid_size[0] - 1)) / (\n",
    "                grid_size[0] - 1 + 1e-5  # small value added to ensure there is no NaN when window size is 1\n",
    "            )\n",
    "        relative_coords_table = rearrange(\n",
    "            relative_coords_table,\n",
    "            \"three num_patches_z num_patches_y num_patches_x -> num_patches_z num_patches_y num_patches_x three\",\n",
    "        ).contiguous()\n",
    "        relative_coords_table *= 8  # Normalize to -8, 8\n",
    "        relative_coords_table = (\n",
    "            torch.sign(relative_coords_table) * torch.log2(torch.abs(relative_coords_table) + 1.0) / np.log2(8)\n",
    "        )\n",
    "        # (num_patches_z, num_patches_y, num_patches_x, 3)\n",
    "        # Allow moving this to and from cuda whenever required but don't save to state_dict\n",
    "        self.register_buffer(\"relative_coords_table\", relative_coords_table, persistent=False)\n",
    "\n",
    "        # Pair-wise relative position index for each token inside the window\n",
    "        coords = get_coords_grid(grid_size)\n",
    "        coords_flatten = rearrange(coords, \"three d h w -> three (d h w)\", three=3).contiguous()\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = rearrange(\n",
    "            relative_coords, \"three num_patches1 num_patches2 -> num_patches1 num_patches2 three\"\n",
    "        ).contiguous()\n",
    "        relative_coords[:, :, 0] += grid_size[0] - 1\n",
    "        relative_coords[:, :, 1] += grid_size[1] - 1\n",
    "        relative_coords[:, :, 2] += grid_size[2] - 1\n",
    "        relative_position_index: torch.Tensor = (\n",
    "            relative_coords[:, :, 0] * relative_limits[1] * relative_limits[2]\n",
    "            + relative_coords[:, :, 1] * relative_limits[2]\n",
    "            + relative_coords[:, :, 2]\n",
    "        )\n",
    "        self.relative_position_index = relative_position_index.flatten()\n",
    "        # (num_patches, num_patches)\n",
    "\n",
    "        self.checkpointing_level1 = ActivationCheckpointing(1, checkpointing_level)\n",
    "\n",
    "    def get_relative_position_embeddings_table(self) -> torch.Tensor:\n",
    "        \"\"\"Get the relative position embeddings table from the meta network.\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape (num_patches, num_heads) containing the relative position embeddings table.\n",
    "        \"\"\"\n",
    "        # (num_patches_z, num_patches_y, num_patches_x, 3)\n",
    "        relative_position_embeddings_table: torch.Tensor = self.cpb_mlp(self.relative_coords_table)\n",
    "        # (num_patches_z, num_patches_y, num_patches_x, num_heads)\n",
    "        relative_position_embeddings_table = relative_position_embeddings_table.reshape(-1, self.config.num_heads)\n",
    "        # (num_patches, num_heads)\n",
    "        return relative_position_embeddings_table\n",
    "\n",
    "    def forward(self) -> torch.Tensor:\n",
    "        \"\"\"Get relative position embeddings as specified by the config.\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape (num_heads, num_patches, num_patches) containing the relative position embeddings.\n",
    "        \"\"\"\n",
    "        relative_position_embeddings_table = self.checkpointing_level1(self.get_relative_position_embeddings_table)\n",
    "        # (num_patches, num_heads)\n",
    "        relative_position_embeddings = relative_position_embeddings_table[self.relative_position_index]\n",
    "        # (num_patches * num_patches, num_heads)\n",
    "        relative_position_embeddings = rearrange(\n",
    "            relative_position_embeddings,\n",
    "            \"(num_patches1 num_patches2) num_heads -> num_heads num_patches1 num_patches2\",\n",
    "            num_patches1=self.config.num_patches,\n",
    "            num_patches2=self.config.num_patches,\n",
    "            num_heads=self.config.num_heads,\n",
    "        ).contiguous()\n",
    "        # (num_heads, num_patches, num_patches)\n",
    "        relative_position_embeddings = 16 * torch.sigmoid(relative_position_embeddings)\n",
    "        # (num_heads, num_patches, num_patches)\n",
    "        return relative_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e236a290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RelativePositionEmbeddings3DMetaNetwork</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>cpb_mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ReLU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>checkpointing_level1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ActivationCheckpointing</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">enabled</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35mRelativePositionEmbeddings3DMetaNetwork\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mcpb_mlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m6\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = RelativePositionEmbeddings3DMetaNetwork(num_heads=6, grid_size=(4, 4, 4))\n",
    "display(test)\n",
    "display(test().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "RelativePositionEmbeddings = Union[RelativePositionEmbeddings3D, RelativePositionEmbeddings3DMetaNetwork]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab8a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@populate_docstring\n",
    "def get_sinusoidal_embeddings_3d(\n",
    "    dim: int,\n",
    "    grid_size: tuple[int, int, int],\n",
    "    spacing: tuple[float, float, float] = (1.0, 1.0, 1.0),\n",
    "    crop_offset: tuple[int, int, int] = None,\n",
    "    channels_first: bool = True,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Get 3D sinusoidal position embeddings.\n",
    "\n",
    "    Args:\n",
    "        dim: Embedding dimension. Must be divisible by 6.\n",
    "        grid_size: Size of the patch grid (d, h, w).\n",
    "        spacing: Spacing between patches in each dimension. Useful for medical images.\n",
    "        crop_offset: Used if the embeddings required are of a crop of a larger image. If provided, the grid coordinates\n",
    "            will be offset accordingly.\n",
    "        channels_first: {CHANNELS_FIRST_DOC}\n",
    "\n",
    "    Returns:\n",
    "        {OUTPUT_3D_DOC}\n",
    "    \"\"\"\n",
    "    if dim % 6 != 0:\n",
    "        raise ValueError(\"dim must be divisible by 6\")\n",
    "\n",
    "    grid = get_coords_grid(grid_size)\n",
    "    # (3, d, h, w)\n",
    "\n",
    "    # Apply offset if crop parameters are provided\n",
    "    if crop_offset is not None:\n",
    "        # Offset the grid coordinates to represent their position in the full volume\n",
    "        for i in range(3):\n",
    "            grid[i] = grid[i] + crop_offset[i]\n",
    "\n",
    "    grid = rearrange(grid, \"x d h w -> x 1 d h w\").contiguous()\n",
    "    # (3, 1, d, h, w)\n",
    "\n",
    "    omega = torch.arange(dim // 6, dtype=torch.float32)\n",
    "    omega /= dim / 6.0\n",
    "    omega = 1.0 / (10000**omega)\n",
    "    # (dim // 6)\n",
    "\n",
    "    patch_multiplier = torch.Tensor(spacing) / min(spacing)\n",
    "\n",
    "    embeddings = []\n",
    "    for i, grid_subset in enumerate(grid):\n",
    "        grid_subset = grid_subset.reshape(-1)\n",
    "\n",
    "        out = torch.einsum(\"m,d->md\", grid_subset, omega)\n",
    "\n",
    "        emb_sin = torch.sin(out)\n",
    "        emb_cos = torch.cos(out)\n",
    "\n",
    "        emb = torch.cat([emb_sin, emb_cos], axis=1) * patch_multiplier[i]\n",
    "        embeddings.append(emb)\n",
    "\n",
    "    embeddings = torch.cat(embeddings, axis=1)\n",
    "    # (dim, d * h * w)\n",
    "    embeddings = rearrange(\n",
    "        embeddings,\n",
    "        \"(d h w) e -> 1 e d h w\",\n",
    "        d=grid_size[0],\n",
    "        h=grid_size[1],\n",
    "        w=grid_size[2],\n",
    "    ).contiguous()\n",
    "    # (1, dim, d, h, w)\n",
    "\n",
    "    embeddings = rearrange_channels(embeddings, True, channels_first)\n",
    "    # (1, [dim], d, h, w, [dim])\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "get_absolute_position_embeddings_3d = get_sinusoidal_embeddings_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d658227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@populate_docstring\n",
    "class AbsolutePositionEmbeddings3D(nn.Module):\n",
    "    \"\"\"3D Absolute Position Embeddings. May or may not learnable. These have to be applied on the input manually and\n",
    "    cannot be passed to attention layers directly. {CLASS_DESCRIPTION_3D_DOC}\"\"\"\n",
    "\n",
    "    @populate_docstring\n",
    "    def __init__(self, config: AbsolutePositionEmbeddings3DConfig = {}, **kwargs):\n",
    "        \"\"\"Initialize AbsolutePositionEmbeddings3D.\n",
    "\n",
    "        Args:\n",
    "            config: {CONFIG_INSTANCE_DOC}\n",
    "            **kwargs: {CONFIG_KWARGS_DOC}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = AbsolutePositionEmbeddings3DConfig.model_validate(config | kwargs)\n",
    "\n",
    "        dim = self.config.dim\n",
    "        grid_size = self.config.grid_size\n",
    "        learnable = self.config.learnable\n",
    "\n",
    "        self.position_embeddings_cache = {}\n",
    "        self.position_embeddings = None\n",
    "        if dim is not None and grid_size is not None:\n",
    "            self.position_embeddings = nn.Parameter(\n",
    "                get_absolute_position_embeddings_3d(dim, grid_size), requires_grad=learnable\n",
    "            )\n",
    "\n",
    "    @populate_docstring\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        embedding_type: Literal[\"add\", \"concat\"] = \"add\",\n",
    "        spacings: torch.Tensor = None,\n",
    "        channels_first: bool = True,\n",
    "        crop_offsets: torch.Tensor | None = None,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Apply absolute position embeddings to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x: {INPUT_3D_DOC}\n",
    "            embedding_type: Type of embedding to apply. 'add' to add the position embeddings to the input,\n",
    "                'concat' to concatenate them along the channel dimension.\n",
    "            spacings: {SPACINGS_DOC}\n",
    "            channels_first: {CHANNELS_FIRST_DOC}\n",
    "            crop_offsets: Used if the embeddings required are of a crop of a larger image. If provided, the grid\n",
    "                coordinates will be offset accordingly.\n",
    "\n",
    "        Returns:\n",
    "            {OUTPUT_3D_DOC}\n",
    "        \"\"\"\n",
    "        assert x.ndim == 5, \"Input tensor must be of shape (b, [d], z, y, x, [d])\"\n",
    "        # Check if sufficient information has been provided\n",
    "        if self.position_embeddings is None:\n",
    "            dim = self.config.dim\n",
    "            if dim is None:\n",
    "                dim = x.shape[1] if channels_first else x.shape[-1]\n",
    "            grid_size = self.config.grid_size\n",
    "            if grid_size is None:\n",
    "                grid_size = tuple(x.shape[2:5] if channels_first else x.shape[1:4])\n",
    "        else:\n",
    "            dim = self.config.dim\n",
    "            grid_size = self.config.grid_size\n",
    "\n",
    "        # Estimate batch size\n",
    "        b = x.shape[0]\n",
    "\n",
    "        # Get position embeddings, adjust based on crop offsets if applicable\n",
    "        if self.position_embeddings is not None:\n",
    "            position_embeddings = rearrange_channels(self.position_embeddings, True, channels_first)\n",
    "            position_embeddings = repeat(position_embeddings, \"1 ... -> b ...\", b=b)\n",
    "        else:\n",
    "            if isinstance(grid_size, int):\n",
    "                grid_size = (grid_size, grid_size, grid_size)\n",
    "\n",
    "            if crop_offsets is None:\n",
    "                cache_key = (dim, grid_size, None)\n",
    "                if cache_key not in self.position_embeddings_cache:\n",
    "                    self.position_embeddings_cache[cache_key] = get_absolute_position_embeddings_3d(\n",
    "                        dim, grid_size, channels_first=channels_first\n",
    "                    )\n",
    "                position_embeddings = self.position_embeddings_cache[cache_key]\n",
    "                position_embeddings = repeat(position_embeddings, \"1 ... -> b ...\", b=b)\n",
    "            else:\n",
    "                if crop_offsets.ndim == 1:\n",
    "                    crop_offsets = crop_offsets.unsqueeze(0)\n",
    "\n",
    "                position_embeddings = []\n",
    "                for crop_offset in crop_offsets:\n",
    "                    position_embeddings.append(\n",
    "                        get_absolute_position_embeddings_3d(\n",
    "                            dim, grid_size, crop_offset=crop_offset.tolist(), channels_first=channels_first\n",
    "                        )\n",
    "                    )\n",
    "                position_embeddings = torch.cat(position_embeddings, dim=0)\n",
    "            position_embeddings = position_embeddings.to(x.device)\n",
    "        # (b, [dim], d, h, w, [dim])\n",
    "\n",
    "        # Incorporate spacing information\n",
    "        if spacings is not None:\n",
    "            assert spacings.shape == (b, 3), \"spacings must be of shape (batch_size, 3)\"\n",
    "            assert dim % 3 == 0, \"dim must be divisible by 3\"\n",
    "            # (b, 3)\n",
    "            spacings = repeat(spacings, \"b three -> b (three dim_by_three) 1 1 1\", three=3, dim_by_three=dim // 3)\n",
    "            # (b, dim, 1, 1, 1)\n",
    "            spacings = rearrange_channels(spacings, True, channels_first)\n",
    "            # (b, [dim], 1, 1, 1, [dim])\n",
    "\n",
    "            position_embeddings = position_embeddings * spacings.to(position_embeddings.device)\n",
    "            # (b, [dim], d, h, w, [dim])\n",
    "\n",
    "        if embedding_type == \"add\":\n",
    "            x = x + position_embeddings\n",
    "        elif embedding_type == \"concat\":\n",
    "            x = torch.cat([x, position_embeddings], dim=1 if channels_first else -1)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Only 'add' and 'concat' are supported for embedding_type\")\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b61bf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AbsolutePositionEmbeddings3D</span><span style=\"font-weight: bold\">()</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAbsolutePositionEmbeddings3D\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_input1 = torch.randn(2, 6, 4, 4, 4)\n",
    "\n",
    "test = AbsolutePositionEmbeddings3D(dim=6, grid_size=4, learnable=True)\n",
    "display(test)\n",
    "display(test(sample_input1).shape)\n",
    "display(test(sample_input1, spacings=torch.randn(2, 3)).shape)\n",
    "\n",
    "test = AbsolutePositionEmbeddings3D(dim=6)\n",
    "display(test(sample_input1).shape)\n",
    "\n",
    "test = AbsolutePositionEmbeddings3D()\n",
    "display(test(sample_input1, crop_offsets=torch.Tensor([(0, 0, 0), (10, 10, 10)])).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d74764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AbsolutePositionEmbeddings3D</span><span style=\"font-weight: bold\">()</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAbsolutePositionEmbeddings3D\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_input1 = torch.randn(2, 4, 4, 4, 6)\n",
    "\n",
    "test = AbsolutePositionEmbeddings3D(dim=6, grid_size=4, learnable=True)\n",
    "display(test)\n",
    "display(test(sample_input1, channels_first=False).shape)\n",
    "\n",
    "test = AbsolutePositionEmbeddings3D(dim=6)\n",
    "display(test(sample_input1, channels_first=False).shape)\n",
    "\n",
    "test = AbsolutePositionEmbeddings3D()\n",
    "display(test(sample_input1, channels_first=False).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935522c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_specific_sinusoidal_embeddings_1d(dim: int, indices: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Get 1D sinusoidal position embeddings for specific indices.\n",
    "\n",
    "    Args:\n",
    "        dim: Embedding dimension. Must be divisible by 2.\n",
    "        indices: Indices for which to get the embeddings. Shape: (length,).\n",
    "\n",
    "    Returns:\n",
    "        A tensor of shape (1, length, dim) containing the position embeddings.\n",
    "    \"\"\"\n",
    "    if dim % 2 != 0:\n",
    "        raise ValueError(\"dim must be divisible by 2\")\n",
    "\n",
    "    # Create frequency bands\n",
    "    omega = torch.arange(dim // 2, dtype=torch.float32, device=indices.device)\n",
    "    omega /= dim / 2.0\n",
    "    omega = 1.0 / (10000**omega)\n",
    "    # (dim // 2)\n",
    "\n",
    "    # Outer product of positions / timesteps and frequencies\n",
    "    out = torch.einsum(\"n,d->nd\", indices, omega)\n",
    "    # (length, dim//2)\n",
    "\n",
    "    # Apply sin and cos functions\n",
    "    emb_sin = torch.sin(out)\n",
    "    emb_cos = torch.cos(out)\n",
    "\n",
    "    # Interleave sin and cos embeddings\n",
    "    embeddings = torch.stack([emb_sin, emb_cos], dim=2)\n",
    "    embeddings = embeddings.flatten(1)\n",
    "    # (length, dim)\n",
    "\n",
    "    # Reshape to expected output format\n",
    "    embeddings = rearrange(embeddings, \"length dim -> 1 length dim\").contiguous()\n",
    "    # (1, length, dim)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def get_sinusoidal_embeddings_1d(dim: int, length: int, device=torch.device(\"cpu\")) -> torch.Tensor:\n",
    "    \"\"\"Get 1D sinusoidal position embeddings.\n",
    "\n",
    "    Args:\n",
    "        dim: Embedding dimension. Must be divisible by 2.\n",
    "        length: Length of the sequence.\n",
    "        device: Device to create the embeddings on.\n",
    "\n",
    "    Returns:\n",
    "        A tensor of shape (1, length, dim) containing the position embeddings.\n",
    "    \"\"\"\n",
    "    # Create position / timestep indices\n",
    "    indices = torch.arange(length, dtype=torch.int32, device=device)\n",
    "    # (length,)\n",
    "\n",
    "    return get_specific_sinusoidal_embeddings_1d(dim, indices)\n",
    "\n",
    "\n",
    "get_timestep_embeddings_1d = get_specific_sinusoidal_embeddings_1d\n",
    "get_all_timestep_embeddings_1d = get_sinusoidal_embeddings_1d\n",
    "get_absolute_position_embeddings_1d = get_sinusoidal_embeddings_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a7bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]))</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_timestep_embeddings_1d(2, torch.tensor([1, 5, 11])).shape, get_all_timestep_embeddings_1d(2, 10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ebabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@populate_docstring\n",
    "class AbsolutePositionEmbeddings1D(nn.Module):\n",
    "    \"\"\"1D Absolute Position Embeddings. May or may not learnable. These have to be applied on the input manually and\n",
    "    cannot be passed to attention layers directly. {CLASS_DESCRIPTION_1D_DOC}\"\"\"\n",
    "\n",
    "    @populate_docstring\n",
    "    def __init__(self, config: AbsolutePositionEmbeddings1DConfig = {}, **kwargs):\n",
    "        \"\"\"Initialize AbsolutePositionEmbeddings1D.\n",
    "\n",
    "        Args:\n",
    "            config: {CONFIG_INSTANCE_DOC}\n",
    "            **kwargs: {CONFIG_KWARGS_DOC}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = AbsolutePositionEmbeddings1DConfig.model_validate(config | kwargs)\n",
    "\n",
    "        dim = self.config.dim\n",
    "        length = self.config.length\n",
    "        learnable = self.config.learnable\n",
    "\n",
    "        self.position_embeddings_cache = {}\n",
    "        self.position_embeddings = None\n",
    "        if dim is not None and length is not None:\n",
    "            self.position_embeddings = nn.Parameter(\n",
    "                get_absolute_position_embeddings_1d(dim, length), requires_grad=learnable\n",
    "            )\n",
    "\n",
    "    @populate_docstring\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        embedding_type: Literal[\"add\", \"concat\"] = \"add\",\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Apply absolute position embeddings to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x: {INPUT_1D_DOC}\n",
    "            embedding_type: Type of embedding to apply. 'add' to add the position embeddings to the input,\n",
    "                'concat' to concatenate them along the last dimension.\n",
    "\n",
    "        Returns:\n",
    "            {OUTPUT_1D_DOC}\n",
    "        \"\"\"\n",
    "        assert x.ndim == 3, \"Input tensor must be of shape (b, length, dim)\"\n",
    "        # Check if sufficient information has been provided\n",
    "        if self.position_embeddings is None:\n",
    "            dim = self.config.dim\n",
    "            if dim is None:\n",
    "                dim = x.shape[2]\n",
    "            length = self.config.length\n",
    "            if length is None:\n",
    "                length = x.shape[1]\n",
    "        else:\n",
    "            dim = self.config.dim\n",
    "            length = self.config.length\n",
    "\n",
    "        # Estimate batch size\n",
    "        b = x.shape[0]\n",
    "\n",
    "        # Get position embeddings, adjust based on crop offsets if applicable\n",
    "        if self.position_embeddings is not None:\n",
    "            position_embeddings = self.position_embeddings\n",
    "            position_embeddings = repeat(position_embeddings, \"1 l d-> b l d\", b=b)\n",
    "        else:\n",
    "            cache_key = (dim, length)\n",
    "            if cache_key not in self.position_embeddings_cache:\n",
    "                self.position_embeddings_cache[cache_key] = get_absolute_position_embeddings_1d(dim, length)\n",
    "            position_embeddings = self.position_embeddings_cache[cache_key]\n",
    "            position_embeddings = repeat(position_embeddings, \"1 l d -> b l d\", b=b).to(x.device)\n",
    "        # (b, length, dim)\n",
    "\n",
    "        if embedding_type == \"add\":\n",
    "            x = x + position_embeddings\n",
    "        elif embedding_type == \"concat\":\n",
    "            x = torch.cat([x, position_embeddings], dim=1)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Only 'add' and 'concat' are supported for embedding_type\")\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc6f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AbsolutePositionEmbeddings1D</span><span style=\"font-weight: bold\">()</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAbsolutePositionEmbeddings1D\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_input1 = torch.randn(3, 6, 2)\n",
    "\n",
    "test = AbsolutePositionEmbeddings1D(dim=2, length=6, learnable=True)\n",
    "display(test)\n",
    "display(test(sample_input1).shape)\n",
    "\n",
    "test = AbsolutePositionEmbeddings1D()\n",
    "display(test(sample_input1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d333485",
   "metadata": {},
   "source": [
    "### RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_rope_rotation_coefficients_1d(\n",
    "    dim: int, length: int, base: float = 10000.0\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Get 1D RoPE cos and sin rotation coefficients.\n",
    "\n",
    "    Args:\n",
    "        dim: Embedding dimension. Must be divisible by 2.\n",
    "        length: Length of the sequence.\n",
    "        base: Base value to use for the rotation coefficients.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of tensors containing the cos and sin rotation coefficients.\n",
    "    \"\"\"\n",
    "    if dim % 2 != 0:\n",
    "        raise ValueError(\"Dimension must be even to apply RoPE.\")\n",
    "\n",
    "    half_dim = dim // 2\n",
    "    pair_idx = torch.arange(half_dim)\n",
    "    # (half_dim,)\n",
    "    inverse_frequency = base ** (-pair_idx / half_dim)\n",
    "    # (half_dim,)\n",
    "\n",
    "    positions = torch.arange(length).unsqueeze(-1)\n",
    "    # (length, 1)\n",
    "    angles = positions * inverse_frequency.unsqueeze(0)\n",
    "    # (length, half_dim)\n",
    "\n",
    "    cos = angles.cos()\n",
    "    # (length, half_dim)\n",
    "    sin = angles.sin()\n",
    "    # (length, half_dim)\n",
    "\n",
    "    # Repeat each angle twice to match (even, odd) channels\n",
    "    cos = torch.repeat_interleave(cos, repeats=2, dim=-1)\n",
    "    # (length, dim)\n",
    "    sin = torch.repeat_interleave(sin, repeats=2, dim=-1)\n",
    "    # (length, dim)\n",
    "\n",
    "    return cos, sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641ce93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5403</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5403</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9999</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9999</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4161</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4161</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9998</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9998</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.9900</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.9900</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9996</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9996</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6536</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6536</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9992</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9992</span><span style=\"font-weight: bold\">]])</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8415</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8415</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0100</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0100</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9093</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9093</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0200</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0200</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1411</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1411</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0300</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0300</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.7568</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.7568</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0400</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0400</span><span style=\"font-weight: bold\">]])</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m1.0000\u001b[0m,  \u001b[1;36m1.0000\u001b[0m,  \u001b[1;36m1.0000\u001b[0m,  \u001b[1;36m1.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m0.5403\u001b[0m,  \u001b[1;36m0.5403\u001b[0m,  \u001b[1;36m0.9999\u001b[0m,  \u001b[1;36m0.9999\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.4161\u001b[0m, \u001b[1;36m-0.4161\u001b[0m,  \u001b[1;36m0.9998\u001b[0m,  \u001b[1;36m0.9998\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.9900\u001b[0m, \u001b[1;36m-0.9900\u001b[0m,  \u001b[1;36m0.9996\u001b[0m,  \u001b[1;36m0.9996\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.6536\u001b[0m, \u001b[1;36m-0.6536\u001b[0m,  \u001b[1;36m0.9992\u001b[0m,  \u001b[1;36m0.9992\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0.0000\u001b[0m,  \u001b[1;36m0.0000\u001b[0m,  \u001b[1;36m0.0000\u001b[0m,  \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m0.8415\u001b[0m,  \u001b[1;36m0.8415\u001b[0m,  \u001b[1;36m0.0100\u001b[0m,  \u001b[1;36m0.0100\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m0.9093\u001b[0m,  \u001b[1;36m0.9093\u001b[0m,  \u001b[1;36m0.0200\u001b[0m,  \u001b[1;36m0.0200\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m0.1411\u001b[0m,  \u001b[1;36m0.1411\u001b[0m,  \u001b[1;36m0.0300\u001b[0m,  \u001b[1;36m0.0300\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.7568\u001b[0m, \u001b[1;36m-0.7568\u001b[0m,  \u001b[1;36m0.0400\u001b[0m,  \u001b[1;36m0.0400\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_rope_rotation_coefficients_1d(dim=4, length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c3b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@populate_docstring\n",
    "class RotaryPositionEmbeddings1D(nn.Module):\n",
    "    \"\"\"1D Rotary Position Embeddings. {CLASS_DESCRIPTION_1D_DOC}\"\"\"\n",
    "\n",
    "    @populate_docstring\n",
    "    def __init__(self, config: RotaryPositionEmbeddings1DConfig = {}, **kwargs):\n",
    "        \"\"\"Initialize RotaryPositionEmbeddings1D.\n",
    "\n",
    "        Args:\n",
    "            config: {CONFIG_INSTANCE_DOC}\n",
    "            **kwargs: {CONFIG_KWARGS_DOC}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.config = RotaryPositionEmbeddings1DConfig.model_validate(config | kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    @lru_cache(maxsize=64)\n",
    "    def get_rotation_coefficients(\n",
    "        dim: int, length: int, device: torch.device, dtype=torch.dtype\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        cos, sin = get_rope_rotation_coefficients_1d(dim=dim, length=length)\n",
    "        cos, sin = cos.to(device=device, dtype=dtype), sin.to(device=device, dtype=dtype)\n",
    "        return cos, sin\n",
    "\n",
    "    @staticmethod\n",
    "    def rearrange_for_sin_coefficients(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Split the tensor into pairs along the last axis, flip each pair's order, and then negate the first\n",
    "        element. That is, for an input tensor [a, b, c, d], the output will be [-b, a, -d, c].\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor with last dimension dim\n",
    "\n",
    "        Returns:\n",
    "            Rearranged tensor\n",
    "        \"\"\"\n",
    "        x = rearrange(x, \"... (half_d two) -> ... half_d two\", two=2).contiguous()\n",
    "        # (..., half_d, 2)\n",
    "        x1, x2 = x.unbind(-1)\n",
    "        # (..., half_d), (..., half_d)\n",
    "        x = torch.stack([-x2, x1], dim=-1)\n",
    "        # (..., half_d, 2)\n",
    "        x = rearrange(x, \"... half_d two -> ... (half_d two)\").contiguous()\n",
    "        # (..., dim)\n",
    "        return x\n",
    "\n",
    "    def apply_rope(self, x: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Apply 1D Rotary Position Embeddings to the given tensor.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor with last dimension dim\n",
    "            cos: Cosine rotation coefficients\n",
    "            sin: Sine rotation coefficients\n",
    "\n",
    "        Returns:\n",
    "            Tensor after applying 1D Rotary Position Embeddings\n",
    "        \"\"\"\n",
    "        return x * cos + self.rearrange_for_sin_coefficients(x) * sin\n",
    "\n",
    "    @populate_docstring\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Apply 1D Rotary Position Embeddings.\n",
    "\n",
    "        Args:\n",
    "            x: {INPUT_1D_DOC}\n",
    "\n",
    "        Returns:\n",
    "            {OUTPUT_1D_DOC}\n",
    "        \"\"\"\n",
    "        # Identify dim\n",
    "        if self.config.dim is None:\n",
    "            dim = x.shape[-1]\n",
    "        else:\n",
    "            dim = self.config.dim\n",
    "\n",
    "        # Get rotation coefficients\n",
    "        cos, sin = self.get_rotation_coefficients(dim, x.shape[1], x.device, x.dtype)\n",
    "        # (length, dim)\n",
    "\n",
    "        # Apply rotation\n",
    "        x = self.apply_rope(x, cos, sin)\n",
    "        # (1, length, dim)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"dim={self.config.dim}, base={self.config.base}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95be68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryPositionEmbeddings1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">dim</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #808000; text-decoration-color: #808000\">base</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10000.0</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mRotaryPositionEmbeddings1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mdim\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbase\u001b[0m=\u001b[1;36m10000\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 4])\n",
      "torch.Size([2, 5, 4])\n",
      "Dot product between 2 and 4 input: 1.6273961067199707\n",
      "Dot product between 2 and 4 output: 1.0360474586486816\n",
      "torch.Size([2, 6, 4])\n",
      "torch.Size([2, 6, 4])\n",
      "Dot product between 3 and 5 input: 1.6273961067199707\n",
      "Dot product between 3 and 5 output: 1.0360478162765503\n"
     ]
    }
   ],
   "source": [
    "T = 5\n",
    "sample_input1 = torch.randn((2, T, 4))\n",
    "test = RotaryPositionEmbeddings1D(dim=4)\n",
    "display(test)\n",
    "roped_output1 = test(sample_input1)\n",
    "\n",
    "print(sample_input1.shape)\n",
    "print(roped_output1.shape)\n",
    "\n",
    "i = 2\n",
    "j = 4\n",
    "print(f\"Dot product between {i} and {j} input: {torch.dot(sample_input1[0, i], sample_input1[0, j])}\")\n",
    "print(f\"Dot product between {i} and {j} output: {torch.dot(roped_output1[0, i], roped_output1[0, j])}\")\n",
    "\n",
    "sample_input2 = torch.cat([torch.randn(2, 1, 4), sample_input1], dim=1)\n",
    "roped_output2 = test(sample_input2)\n",
    "\n",
    "print(sample_input2.shape)\n",
    "print(roped_output2.shape)\n",
    "\n",
    "i = 3\n",
    "j = 5\n",
    "print(f\"Dot product between {i} and {j} input: {torch.dot(sample_input2[0, i], sample_input2[0, j])}\")\n",
    "print(f\"Dot product between {i} and {j} output: {torch.dot(roped_output2[0, i], roped_output2[0, j])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1298dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@populate_docstring\n",
    "class RotaryPositionEmbeddings3D(RotaryPositionEmbeddings1D):\n",
    "    \"\"\"3D Rotary Position Embeddings. {CLASS_DESCRIPTION_3D_DOC}\"\"\"\n",
    "\n",
    "    @populate_docstring\n",
    "    def __init__(self, config: RotaryPositionEmbeddings3DConfig = {}, **kwargs):\n",
    "        \"\"\"Initialize RotaryPositionEmbeddings1D.\n",
    "\n",
    "        Args:\n",
    "            config: {CONFIG_INSTANCE_DOC}\n",
    "            **kwargs: {CONFIG_KWARGS_DOC}\n",
    "        \"\"\"\n",
    "        super().__init__(config, **kwargs)\n",
    "\n",
    "        self.config = RotaryPositionEmbeddings3DConfig.model_validate(config | kwargs)\n",
    "\n",
    "    def apply_rope(self, x: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor, axis: int) -> torch.Tensor:\n",
    "        \"\"\"Apply 1D Rotary Position Embeddings to the given tensor specific to partixcular axis.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor with last dimension dim\n",
    "            cos: Cosine rotation coefficients\n",
    "            sin: Sine rotation coefficients\n",
    "            axis: Axis which corresponds to the current dimension\n",
    "\n",
    "        Returns:\n",
    "            Tensor after applying 1D Rotary Position Embeddings\n",
    "        \"\"\"\n",
    "        num_unsqueezes = 3 - axis\n",
    "        for _ in range(num_unsqueezes):\n",
    "            cos = cos.unsqueeze(1)\n",
    "            sin = sin.unsqueeze(1)\n",
    "        return super().apply_rope(x, cos, sin)\n",
    "\n",
    "    @populate_docstring\n",
    "    def forward(self, x: torch.Tensor, channels_first: bool = True) -> torch.Tensor:\n",
    "        \"\"\"Apply 3D Rotary Position Embeddings.\n",
    "\n",
    "        Args:\n",
    "            x: {INPUT_3D_DOC}\n",
    "            channels_first: {CHANNELS_FIRST_DOC}\n",
    "\n",
    "        Returns:\n",
    "            {OUTPUT_3D_DOC}\n",
    "        \"\"\"\n",
    "        # Rearrange to channels last format\n",
    "        x = rearrange_channels(x, channels_first, False)\n",
    "        # (B, Z, Y, X, D)\n",
    "\n",
    "        # Decide on dim\n",
    "        if self.config.dim is None:\n",
    "            dim = x.shape[-1]\n",
    "        else:\n",
    "            dim = self.config.dim\n",
    "\n",
    "        # Split tensor into three parts for each axis\n",
    "        z_dim, y_dim, x_dim = list(self.config.get_split_as_ints(dim))\n",
    "        rest_dim = x.shape[-1] - z_dim - y_dim - x_dim\n",
    "        z_part, y_part, x_part, rest = x.split([z_dim, y_dim, x_dim, rest_dim], dim=-1)\n",
    "        # (B, Z, Y, X, D_z), (B, Z, Y, X, D_y), (B, Z, Y, X, D_x), (B, Z, Y, X, D_rest)\n",
    "\n",
    "        # Get rotation coefficients\n",
    "        cos_z, sin_z = self.get_rotation_coefficients(z_dim, x.shape[1], x.device, x.dtype)\n",
    "        cos_y, sin_y = self.get_rotation_coefficients(y_dim, x.shape[2], x.device, x.dtype)\n",
    "        cos_x, sin_x = self.get_rotation_coefficients(x_dim, x.shape[3], x.device, x.dtype)\n",
    "        # (length, dim)\n",
    "\n",
    "        # Apply rotation\n",
    "        z_part = self.apply_rope(z_part, cos_z, sin_z, axis=1)\n",
    "        y_part = self.apply_rope(y_part, cos_y, sin_y, axis=2)\n",
    "        x_part = self.apply_rope(x_part, cos_x, sin_x, axis=3)\n",
    "\n",
    "        # Concatenate the three parts along the channel dimension\n",
    "        x = torch.cat([z_part, y_part, x_part, rest], dim=-1)\n",
    "        # (B, Z, Y, X, D_z + D_y + D_x + D_rest)\n",
    "\n",
    "        # Revert channels rearrangement\n",
    "        x = rearrange_channels(x, False, channels_first)\n",
    "        # (B, [D], Z, Y, X, [D])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return super().extra_repr() + f\", split={self.config.split}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305ee5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryPositionEmbeddings3D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">dim</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">base</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10000.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">split</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3333333333333333</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3333333333333333</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3333333333333333</span><span style=\"font-weight: bold\">))</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mRotaryPositionEmbeddings3D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mdim\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mbase\u001b[0m=\u001b[1;36m10000\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33msplit\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0.3333333333333333\u001b[0m, \u001b[1;36m0.3333333333333333\u001b[0m, \u001b[1;36m0.3333333333333333\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 10, 11, 12])\n",
      "torch.Size([2, 6, 10, 11, 12])\n",
      "Dot product between (1, 2, 3) and (2, 3, 4) input: 0.8099715113639832\n",
      "Dot product between (1, 2, 3) and (2, 3, 4) output: -2.4859845638275146\n",
      "torch.Size([2, 6, 11, 12, 13])\n",
      "torch.Size([2, 6, 11, 12, 13])\n",
      "Dot product between (2, 3, 4) and (3, 4, 5) input: 0.8099715113639832\n",
      "Dot product between (2, 3, 4) and (3, 4, 5) output: -2.4859840869903564\n"
     ]
    }
   ],
   "source": [
    "sample_input1 = torch.randn((2, 6, 10, 11, 12))\n",
    "test = RotaryPositionEmbeddings3D()\n",
    "display(test)\n",
    "roped_output1 = test(sample_input1)\n",
    "\n",
    "print(sample_input1.shape)\n",
    "print(roped_output1.shape)\n",
    "\n",
    "i = (1, 2, 3)\n",
    "j = (2, 3, 4)\n",
    "print(\n",
    "    f\"Dot product between {i} and {j} input: {torch.dot(sample_input1[0, :, i[0], i[1], i[2]], sample_input1[0, :, j[0], j[1], j[2]])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Dot product between {i} and {j} output: {torch.dot(roped_output1[0, :, i[0], i[1], i[2]], roped_output1[0, :, j[0], j[1], j[2]])}\"\n",
    ")\n",
    "\n",
    "sample_input2 = torch.randn(2, 6, 11, 12, 13)\n",
    "sample_input2[:, :, 1:, 1:, 1:] = sample_input1\n",
    "roped_output2 = test(sample_input2)\n",
    "\n",
    "print(sample_input2.shape)\n",
    "print(roped_output2.shape)\n",
    "\n",
    "i = (2, 3, 4)\n",
    "j = (3, 4, 5)\n",
    "print(\n",
    "    f\"Dot product between {i} and {j} input: {torch.dot(sample_input2[0, :, i[0], i[1], i[2]], sample_input2[0, :, j[0], j[1], j[2]])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Dot product between {i} and {j} output: {torch.dot(roped_output2[0, :, i[0], i[1], i[2]], roped_output2[0, :, j[0], j[1], j[2]])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6add16",
   "metadata": {},
   "source": [
    "### Patch embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f7b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@populate_docstring\n",
    "class PatchEmbeddings3D(CNNBlock3D):\n",
    "    \"\"\"3D Patch Embeddings using a convolutional layer. {CLASS_DESCRIPTION_3D_DOC}\"\"\"\n",
    "\n",
    "    @populate_docstring\n",
    "    def __init__(self, config: PatchEmbeddings3DConfig = {}, checkpointing_level: int = 0, **kwargs):\n",
    "        \"\"\"Initialize PatchEmbeddings3D.\n",
    "\n",
    "        Args:\n",
    "            config: {CONFIG_INSTANCE_DOC}\n",
    "            checkpointing_level: {CHECKPOINTING_LEVEL_DOC}\n",
    "            **kwargs: {CONFIG_KWARGS_DOC}\n",
    "        \"\"\"\n",
    "        self.config = PatchEmbeddings3DConfig.model_validate(config | kwargs)\n",
    "        config = self.config.model_dump() | {\n",
    "            \"kernel_size\": self.config.get(\"patch_size\"),\n",
    "            \"stride\": self.config.get(\"patch_size\"),\n",
    "            \"padding\": 0,\n",
    "            \"out_channels\": self.config.get(\"dim\"),\n",
    "        }\n",
    "        super().__init__(config, checkpointing_level, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f96b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PatchEmbeddings3D</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>conv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv3d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>norm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm3d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ReLU</span><span style=\"font-weight: bold\">()</span>\n",
       "  <span style=\"font-weight: bold\">(</span>checkpointing_level1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ActivationCheckpointing</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">enabled</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35mPatchEmbeddings3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m12\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = PatchEmbeddings3D(patch_size=(1, 8, 8), in_channels=1, dim=12)\n",
    "display(test)\n",
    "o = test(torch.randn(2, 1, 32, 512, 512))\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56759cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PatchEmbeddings3D</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>conv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv3d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>norm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm3d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ReLU</span><span style=\"font-weight: bold\">()</span>\n",
       "  <span style=\"font-weight: bold\">(</span>checkpointing_level1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ActivationCheckpointing</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">enabled</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35mPatchEmbeddings3D\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mConv3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm3d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m12\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mcheckpointing_level1\u001b[1m)\u001b[0m: \u001b[1;35mActivationCheckpointing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m12\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = PatchEmbeddings3D(patch_size=(1, 8, 8), in_channels=1, dim=12)\n",
    "display(test)\n",
    "o = test(torch.randn(2, 32, 512, 512, 1), channels_first=False)\n",
    "display(o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0006f2",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e1e167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a64d1a4e",
   "metadata": {},
   "source": [
    "# Rough work"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3feef579",
   "metadata": {},
   "source": [
    "coords_h = torch.arange(4)\n",
    "coords_w = torch.arange(4)\n",
    "coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing=\"ij\"))\n",
    "coords_flatten = torch.flatten(coords, 1)\n",
    "relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "relative_coords[:, :, 0] += 4 - 1\n",
    "relative_coords[:, :, 1] += 4 - 1\n",
    "relative_coords[:, :, 0] *= 2 * 4 - 1\n",
    "relative_position_index = relative_coords.sum(-1)\n",
    "\n",
    "relative_position_index.min(), relative_position_index.max()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6546f40",
   "metadata": {},
   "source": [
    "window_size = (4, 4, 4)\n",
    "relative_limits = (7, 7, 7)\n",
    "\n",
    "coords = get_coords_grid(window_size)\n",
    "coords_flatten = rearrange(coords, \"three_dimensional d h w -> three_dimensional (d h w)\", three_dimensional=3)\n",
    "relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "relative_coords[:, :, 0] += window_size[0] - 1\n",
    "relative_coords[:, :, 1] += window_size[1] - 1\n",
    "relative_coords[:, :, 2] += window_size[2] - 1\n",
    "relative_position_index: torch.Tensor = (\n",
    "    relative_coords[:, :, 0] * relative_limits[1] * relative_limits[2]\n",
    "    + relative_coords[:, :, 1] * relative_limits[2]\n",
    "    + relative_coords[:, :, 2]\n",
    ")\n",
    "\n",
    "relative_position_index.min(), relative_position_index.max()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a069fc0",
   "metadata": {},
   "source": [
    "window_size = (2, 2, 2)\n",
    "relative_limits = (2 * window_size[0] - 1, 2 * window_size[1] - 1, 2 * window_size[2] - 1)\n",
    "\n",
    "relative_coords_table = get_coords_grid(relative_limits)\n",
    "relative_coords_table[0] -= window_size[0] - 1\n",
    "relative_coords_table[1] -= window_size[1] - 1\n",
    "relative_coords_table[2] -= window_size[2] - 1\n",
    "relative_coords_table = relative_coords_table.permute(1, 2, 3, 0).contiguous()\n",
    "relative_coords_table[0, 2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495a98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
