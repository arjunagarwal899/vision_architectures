{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe257cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils/pipeline_parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70b4cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c2977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import getsource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b1fd21",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ced08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_device(device: torch.device | str) -> torch.device:\n",
    "    \"\"\"Convert to torch.device object.\"\"\"\n",
    "    if isinstance(device, str):\n",
    "        return torch.device(device)\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105bc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def move_to_device(data, device):\n",
    "    \"\"\"\n",
    "    Move data to the specified device.\n",
    "\n",
    "    Args:\n",
    "        data: The data to move.\n",
    "        device: The device to move the data to.\n",
    "\n",
    "    Returns:\n",
    "        The data moved to the specified device.\n",
    "    \"\"\"\n",
    "    device = get_device(device)\n",
    "    if isinstance(data, (list, tuple, set)):\n",
    "        return type(data)(move_to_device(d, device) for d in data)\n",
    "    elif isinstance(data, dict):\n",
    "        return {k: move_to_device(v, device) for k, v in data.items()}\n",
    "    elif isinstance(data, torch.Tensor):\n",
    "        return data.to(device)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a6f3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'a'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1.0959\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1.0058\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m{\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.5093\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'a'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1.0959\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1.0058\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m{\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.5093\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = {\"a\": [torch.randn(1), (torch.randn(1), {torch.randn(1)})]}\n",
    "display(test)\n",
    "\n",
    "test = move_to_device(test, \"cuda:0\")\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fba14f",
   "metadata": {},
   "source": [
    "# Parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3cae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def parallelize_module(\n",
    "    module: nn.Module, processing_device: torch.device | str, output_device: torch.device | str | None = None\n",
    "):\n",
    "    # Get devices\n",
    "    processing_device = get_device(processing_device)\n",
    "    if output_device is None:\n",
    "        output_device = processing_device\n",
    "    output_device = get_device(output_device)\n",
    "\n",
    "    # Move module to processing device\n",
    "    module = module.to(processing_device)\n",
    "\n",
    "    # Store module forward function without parallization\n",
    "    module._forward_without_pipeline_parallelization = module.forward\n",
    "\n",
    "    # Update with parallelized forward function\n",
    "    def forward_with_pipeline_parallelization(*args, **kwargs):\n",
    "        \"\"\"Forward function that moves inputs to the processing device and outputs to the output device. To view the\n",
    "        actual forward logic, use the `_forward_without_pipeline_parallelization` function.\"\"\"\n",
    "        args = move_to_device(args, processing_device)\n",
    "        kwargs = move_to_device(kwargs, processing_device)\n",
    "        output = module._forward_without_pipeline_parallelization(*args, **kwargs)\n",
    "        return move_to_device(output, output_device)\n",
    "\n",
    "    module.forward_with_pipeline_parallelization = forward_with_pipeline_parallelization\n",
    "    module.forward = forward_with_pipeline_parallelization\n",
    "\n",
    "    # Store module extra_repr function without parallization\n",
    "    module._extra_repr_without_pipeline_parallelization = module.extra_repr\n",
    "\n",
    "    # Update with extra_repr function\n",
    "    def extra_repr_with_pipeline_parallelization(*args, **kwargs):\n",
    "        \"\"\"extra_repr function that also shows the processing device and the output device. To view the actual\n",
    "        extra_repr function, use the `_extra_repr_without_pipeline_parallelization` function.\"\"\"\n",
    "        return (\n",
    "            f\"processing_device={processing_device}, output_device={output_device}\"\n",
    "            + module._extra_repr_without_pipeline_parallelization(*args, **kwargs)\n",
    "        )\n",
    "\n",
    "    module.extra_repr_with_pipeline_parallelization = extra_repr_with_pipeline_parallelization\n",
    "    module.extra_repr = extra_repr_with_pipeline_parallelization\n",
    "\n",
    "    # Add flag to module\n",
    "    module._is_pipeline_parallelized = True\n",
    "\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e352bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMyModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[33mprocessing_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:0\u001b[0m, \u001b[33moutput_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:0\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def forward_with_pipeline_parallelization(*args, **kwargs):\n",
      "        \"\"\"Forward function that moves inputs to the processing device and outputs to the output device. To view the\n",
      "        actual forward logic, use the `_forward_without_pipeline_parallelization` function.\"\"\"\n",
      "        args = move_to_device(args, processing_device)\n",
      "        kwargs = move_to_device(kwargs, processing_device)\n",
      "        output = module._forward_without_pipeline_parallelization(*args, **kwargs)\n",
      "        return move_to_device(output, output_device)\n",
      "\n",
      "    def forward_with_pipeline_parallelization(*args, **kwargs):\n",
      "        \"\"\"Forward function that moves inputs to the processing device and outputs to the output device. To view the\n",
      "        actual forward logic, use the `_forward_without_pipeline_parallelization` function.\"\"\"\n",
      "        args = move_to_device(args, processing_device)\n",
      "        kwargs = move_to_device(kwargs, processing_device)\n",
      "        output = module._forward_without_pipeline_parallelization(*args, **kwargs)\n",
      "        return move_to_device(output, output_device)\n",
      "\n",
      "    def forward(self, x):\n",
      "        return self.linear(x)\n",
      "\n",
      "Output device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "module = MyModule()\n",
    "test = parallelize_module(module, \"cuda:0\")\n",
    "display(test)\n",
    "\n",
    "print(getsource(test.forward))\n",
    "print(getsource(test.forward_with_pipeline_parallelization))\n",
    "print(getsource(test._forward_without_pipeline_parallelization))\n",
    "\n",
    "sample_input = torch.randn(1, 10)\n",
    "output = test(sample_input)\n",
    "print(f\"Output device: {output.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b157b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def unparallelize_module(module: nn.Module, common_device: torch.device | str | None = None):\n",
    "    \"\"\"Unparallelize a module that was parallelized with `parallelize_module`. This will move the module to the common\n",
    "    device and restore the original forward and extra_repr functions.\"\"\"\n",
    "    # If common_device is provided, move the module to that device\n",
    "    if common_device is not None:\n",
    "        common_device = get_device(common_device)\n",
    "        module = module.to(common_device)\n",
    "\n",
    "    # Check if module is parallelized\n",
    "    is_pipeline_parallelized = getattr(module, \"_is_pipeline_parallelized\", False)\n",
    "    if not is_pipeline_parallelized:\n",
    "        return module\n",
    "\n",
    "    # Restore model's original forward function and delete extra functions\n",
    "    module.forward = module._forward_without_pipeline_parallelization\n",
    "    del module.forward_with_pipeline_parallelization, module._forward_without_pipeline_parallelization\n",
    "\n",
    "    # Restore model's original extra_repr function and delete extra functions\n",
    "    module.extra_repr = module._extra_repr_without_pipeline_parallelization\n",
    "    del module.extra_repr_with_pipeline_parallelization, module._extra_repr_without_pipeline_parallelization\n",
    "\n",
    "    # Update flag (although it can be deleted too, it's useful for debugging)\n",
    "    module._is_pipeline_parallelized = False\n",
    "\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461215c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMyModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMyModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def forward(self, x):\n",
      "        return self.linear(x)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unparallelize_module(module)\n",
    "display(test)\n",
    "\n",
    "unparallelize_module(test, \"cuda:3\")\n",
    "display(test)\n",
    "\n",
    "print(getsource(test.forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98156677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def parallelize_pipeline(\n",
    "    model: nn.Module, module_to_device: dict[str, torch.device | str | list[torch.device | str]]\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    Parallelize a model across multiple devices. It is recommended to pass a root device too i.e. {\"\": DEVICE, ...} to\n",
    "    avoid errors in the calculations of the outermost modules.\n",
    "\n",
    "    Args:\n",
    "        model: The model to parallelize. An unparallelized model is expected, otherwise you will face recursion errors.\n",
    "        module_to_device: A dictionary mapping module names to devices. Keys are modules names with nested modules\n",
    "            separated by dots (e.g., \"module.submodule\"). Note that the parallelism is performed using Level Order\n",
    "            Traversal (i.e. BFS) of the model. Therefore the device of the deepest module in the dictionary will be\n",
    "            overwritten even if it's parent is also specified in the dictionary. Value is either a device or a 2-tuple\n",
    "            of devices. The first device is the processing device, and the second device is the output device.\n",
    "\n",
    "    Returns:\n",
    "        The parallelized pipeline.\n",
    "    \"\"\"\n",
    "    # Convert all dictionary values to lists\n",
    "    for key, value in module_to_device.items():\n",
    "        if not isinstance(value, list):\n",
    "            module_to_device[key] = [value, value]\n",
    "\n",
    "    # Parallelize the model if required\n",
    "    if \"\" in module_to_device:\n",
    "        # Identify the devices\n",
    "        devices = module_to_device.pop(\"\")\n",
    "        if isinstance(devices, list):\n",
    "            processing_device, output_device = devices\n",
    "        else:\n",
    "            processing_device, output_device = devices, devices\n",
    "\n",
    "        # Parallelize\n",
    "        parallelize_module(model, processing_device, output_device)\n",
    "\n",
    "        # Update the output device of the rest of they modules in the dictionary so that they are able to work together\n",
    "        for key in module_to_device:\n",
    "            module_to_device[key][1] = processing_device\n",
    "\n",
    "    # Identify children submodules and their devices\n",
    "    children_submodules_to_device: dict[str, dict[str, torch.device | str]] = defaultdict(dict)\n",
    "    for module_name, devices in sorted(module_to_device.items()):\n",
    "        # Get the module's name and ensure it is present in the model\n",
    "        module_name_split = module_name.split(\".\")\n",
    "        child_name = module_name_split[0]\n",
    "        if not hasattr(model, child_name):\n",
    "            raise ValueError(f\"Module {child_name} not found in the model.\")\n",
    "\n",
    "        # Add to children_submodules_to_device\n",
    "        children_submodules_to_device[child_name][\".\".join(module_name_split[1:])] = devices\n",
    "\n",
    "    # Iterate over the submodules and assign them to the appropriate devices\n",
    "    for child_name, submodules_to_device in children_submodules_to_device.items():\n",
    "        module = getattr(model, child_name)\n",
    "        parallelize_pipeline(module, submodules_to_device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0daa150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMyModule3\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmodule2\u001b[1m)\u001b[0m: \u001b[1;35mMyModule2\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmodule11\u001b[1m)\u001b[0m: \u001b[1;35mMyModule1\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mMyModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmodule12\u001b[1m)\u001b[0m: \u001b[1;35mMyModule1\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mMyModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMyModule3\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmodule2\u001b[1m)\u001b[0m: \u001b[1;35mMyModule2\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mprocessing_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:3\u001b[0m, \u001b[33moutput_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:0\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmodule11\u001b[1m)\u001b[0m: \u001b[1;35mMyModule1\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[33mprocessing_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:1\u001b[0m, \u001b[33moutput_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:3\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mMyModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mprocessing_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:2\u001b[0m, \u001b[33moutput_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:1\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmodule12\u001b[1m)\u001b[0m: \u001b[1;35mMyModule1\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[33mprocessing_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:3\u001b[0m, \u001b[33moutput_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:3\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mMyModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "class MyModule1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.module = MyModule()\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.module(x) + self.linear(x)\n",
    "\n",
    "\n",
    "class MyModule2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.module11 = MyModule1()\n",
    "        self.module12 = MyModule1()\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.module11(x) + self.module12(x) + self.linear(x)\n",
    "\n",
    "\n",
    "class MyModule3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.module2 = MyModule2()\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.module2(x) + self.linear(x)\n",
    "\n",
    "\n",
    "test = MyModule3().to(\"cuda:0\")\n",
    "display(test)\n",
    "\n",
    "test = parallelize_pipeline(\n",
    "    test,\n",
    "    {\n",
    "        \"module2.module11\": \"cuda:1\",\n",
    "        \"module2.module12\": \"cuda:3\",\n",
    "        \"module2.module11.module\": \"cuda:2\",\n",
    "        \"module2\": [\"cuda:3\", \"cuda:0\"],\n",
    "    },\n",
    ")\n",
    "display(test)\n",
    "\n",
    "sample_input = torch.randn(1, 10).to(\"cuda:0\")\n",
    "output = test(sample_input)\n",
    "print(f\"Output device: {output.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33983d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def unparallelize_pipeline(model: nn.Module, common_device: torch.device | str | None = None) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Unparallelize a model that was parallelized with `parallelize_pipeline`. This will remove any pipeline\n",
    "    parallelization and move the model to the common device.\n",
    "\n",
    "    Args:\n",
    "        model: The model to unparallelize.\n",
    "        common_device: The device to move the model to. If None, the model will not be moved.\n",
    "\n",
    "    Returns:\n",
    "        The model after unparallelization and device transfer.\n",
    "    \"\"\"\n",
    "    # If common_device is provided, get the device object\n",
    "    if common_device is not None:\n",
    "        common_device = get_device(common_device)\n",
    "\n",
    "    # Unparallelize the model\n",
    "    model = unparallelize_module(model, common_device)\n",
    "\n",
    "    # Recurse over all submodules and unparallelize them\n",
    "    for module in model.children():\n",
    "        # Unparallelize the module\n",
    "        unparallelize_pipeline(module, common_device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e8ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMyModule3\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmodule2\u001b[1m)\u001b[0m: \u001b[1;35mMyModule2\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmodule11\u001b[1m)\u001b[0m: \u001b[1;35mMyModule1\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mMyModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmodule12\u001b[1m)\u001b[0m: \u001b[1;35mMyModule1\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mMyModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "unparallelize_pipeline(test, \"cuda:2\")\n",
    "display(test)\n",
    "print(test.module2.module11.linear.weight.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8d948",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682be69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
