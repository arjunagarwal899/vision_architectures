{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe257cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils/pipeline_parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70b4cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b1fd21",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ced08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_device(device: torch.device | str) -> torch.device:\n",
    "    \"\"\"Convert to torch.device object.\"\"\"\n",
    "    if isinstance(device, str):\n",
    "        return torch.device(device)\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105bc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def move_to_device(data, device):\n",
    "    \"\"\"\n",
    "    Move data to the specified device.\n",
    "\n",
    "    Args:\n",
    "        data: The data to move.\n",
    "        device: The device to move the data to.\n",
    "\n",
    "    Returns:\n",
    "        The data moved to the specified device.\n",
    "    \"\"\"\n",
    "    device = get_device(device)\n",
    "    if isinstance(data, (list, tuple, set)):\n",
    "        return type(data)(move_to_device(d, device) for d in data)\n",
    "    elif isinstance(data, dict):\n",
    "        return {k: move_to_device(v, device) for k, v in data.items()}\n",
    "    elif isinstance(data, torch.Tensor):\n",
    "        return data.to(device)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a6f3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'a'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.7945\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.5051\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m{\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2.3460\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'a'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.7945\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.5051\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m{\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2.3460\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = {\"a\": [torch.randn(1), (torch.randn(1), {torch.randn(1)})]}\n",
    "display(test)\n",
    "\n",
    "test = move_to_device(test, \"cuda:0\")\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fba14f",
   "metadata": {},
   "source": [
    "# Parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0068ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class PipelineModule(nn.Module):\n",
    "    def __init__(\n",
    "        self, module: nn.Module, processing_device: torch.device | str, output_device: torch.device | str | None = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.processing_device = get_device(processing_device)\n",
    "        if output_device is None:\n",
    "            output_device = processing_device\n",
    "        self.output_device = get_device(output_device)\n",
    "        self.module = module.to(processing_device)\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        args = move_to_device(args, self.processing_device)\n",
    "        kwargs = move_to_device(kwargs, self.processing_device)\n",
    "        output = self.module(*args, **kwargs)\n",
    "        return move_to_device(output, self.output_device)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"processing_device={self.processing_device}, output_device={self.output_device}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091a1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mPipelineModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[33mprocessing_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:0\u001b[0m, \u001b[33moutput_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:0\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mMyModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "module = MyModule()\n",
    "test = PipelineModule(module, \"cuda:0\")\n",
    "display(test)\n",
    "\n",
    "sample_input = torch.randn(1, 10)\n",
    "output = test(sample_input)\n",
    "print(f\"Output device: {output.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98156677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def paralellize_pipeline(\n",
    "    model: nn.Module, module_to_device: dict[str, torch.device | str | list[torch.device | str]]\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    Parallelize a model across multiple devices.\n",
    "\n",
    "    Args:\n",
    "        model: The model to parallelize.\n",
    "        module_to_device: A dictionary mapping module names to devices. Keys are modules names with nested modules\n",
    "            separated by dots (e.g., \"module.submodule\"). Note that the parallelism is performed using Level Order\n",
    "            Traversal (i.e. BFS) of the model. Therefore the device of the deepest module in the dictionary will be\n",
    "            overwritten even if it's parent is also specified in the dictionary. Value is either a device or a 2-tuple\n",
    "            of devices. The first device is the processing device, and the second device is the output device.\n",
    "\n",
    "    Returns:\n",
    "        The parallelized pipeline.\n",
    "    \"\"\"\n",
    "    # Do not allow parent pipeline parallelism to affect child pipeline parallelism\n",
    "    if isinstance(model, PipelineModule):\n",
    "        model = model.module\n",
    "\n",
    "    # Convert all dictionary values to lists\n",
    "    for key, value in module_to_device.items():\n",
    "        if not isinstance(value, list):\n",
    "            module_to_device[key] = [value, value]\n",
    "\n",
    "    children_submodules_to_device: dict[str, dict[str, torch.device | str]] = defaultdict(dict)\n",
    "    for module_name in sorted(module_to_device.keys()):\n",
    "        # Identify the devices\n",
    "        devices = module_to_device[module_name]\n",
    "        if isinstance(devices, list):\n",
    "            processing_device, output_device = devices\n",
    "        else:\n",
    "            processing_device, output_device = devices, devices\n",
    "\n",
    "        # Get the module's name and ensure it is present in the model\n",
    "        module_name_split = module_name.split(\".\")\n",
    "        child_name = module_name_split[0]\n",
    "        if not hasattr(model, child_name):\n",
    "            raise ValueError(f\"Module {child_name} not found in the model.\")\n",
    "\n",
    "        if len(module_name_split) == 1:\n",
    "            # If it is the module in question, replace it with PipelineModule\n",
    "            module = getattr(model, child_name)\n",
    "            setattr(model, child_name, PipelineModule(module, processing_device, output_device))\n",
    "\n",
    "            # This will always be the first element of the dictionary for every subtree, if at all. Update the\n",
    "            # output_device of all the rest of they modules in the dictionary so that they are able to work together\n",
    "            for key in module_to_device:\n",
    "                if key.startswith(child_name + \".\"):\n",
    "                    module_to_device[key][1] = processing_device\n",
    "        else:\n",
    "            # Add to the submodules_to_device\n",
    "            children_submodules_to_device[child_name][\".\".join(module_name_split[1:])] = [\n",
    "                processing_device,\n",
    "                output_device,\n",
    "            ]\n",
    "\n",
    "    # Iterate over the submodules and assign them to the appropriate devices\n",
    "    for child_name, submodules_to_device in children_submodules_to_device.items():\n",
    "        module = getattr(model, child_name)\n",
    "        paralellize_pipeline(module, submodules_to_device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0daa150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMyModule3\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmodule2\u001b[1m)\u001b[0m: \u001b[1;35mMyModule2\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmodule11\u001b[1m)\u001b[0m: \u001b[1;35mMyModule1\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mMyModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmodule12\u001b[1m)\u001b[0m: \u001b[1;35mMyModule1\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mMyModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMyModule3\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmodule2\u001b[1m)\u001b[0m: \u001b[1;35mPipelineModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mprocessing_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:3\u001b[0m, \u001b[33moutput_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:0\u001b[0m\n",
       "    \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mMyModule2\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmodule11\u001b[1m)\u001b[0m: \u001b[1;35mPipelineModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mprocessing_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:1\u001b[0m, \u001b[33moutput_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:3\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mMyModule1\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mPipelineModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mprocessing_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:2\u001b[0m, \u001b[33moutput_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:1\u001b[0m\n",
       "            \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mMyModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "              \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmodule12\u001b[1m)\u001b[0m: \u001b[1;35mPipelineModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mprocessing_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:3\u001b[0m, \u001b[33moutput_device\u001b[0m=\u001b[35mcu\u001b[0m\u001b[1;92mda\u001b[0m\u001b[1;92m:3\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mMyModule1\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m: \u001b[1;35mMyModule\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "class MyModule1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.module = MyModule()\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.module(x) + self.linear(x)\n",
    "\n",
    "\n",
    "class MyModule2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.module11 = MyModule1()\n",
    "        self.module12 = MyModule1()\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.module11(x) + self.module12(x) + self.linear(x)\n",
    "\n",
    "\n",
    "class MyModule3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.module2 = MyModule2()\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.module2(x) + self.linear(x)\n",
    "\n",
    "\n",
    "test = MyModule3().to(\"cuda:0\")\n",
    "display(test)\n",
    "\n",
    "test = paralellize_pipeline(\n",
    "    test,\n",
    "    {\n",
    "        \"module2.module11\": \"cuda:1\",\n",
    "        \"module2.module12\": \"cuda:3\",\n",
    "        \"module2.module11.module\": \"cuda:2\",\n",
    "        \"module2\": [\"cuda:3\", \"cuda:0\"],\n",
    "    },\n",
    ")\n",
    "display(test)\n",
    "\n",
    "sample_input = torch.randn(1, 10).to(\"cuda:0\")\n",
    "output = test(sample_input)\n",
    "print(f\"Output device: {output.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8d948",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682be69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
