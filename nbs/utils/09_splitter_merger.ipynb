{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76603452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils/splitter_merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2379b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "from collections.abc import Generator\n",
    "from functools import wraps\n",
    "from typing import Literal\n",
    "\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from vision_architectures.utils.custom_base_model import CustomBaseModel, Field, model_validator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a5ac25",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70004c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SplitterConfig(CustomBaseModel):\n",
    "    split_dims: int = Field(3, description=\"Number of spatial dimensions.\")\n",
    "    split_size: int | tuple[int, ...]\n",
    "    stride: int | tuple[int, ...]\n",
    "    extend_mode: Literal[\"pad\", \"wrap\"] | None = Field(\n",
    "        \"pad\",\n",
    "        description=(\n",
    "            \"Whether to pad or wrap the input tensor to get correct windows. If None, exact divisibility is expected\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    raise_large_stride_error: bool = True\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate(self):\n",
    "        super().validate()\n",
    "        if isinstance(self.split_size, int):\n",
    "            self.split_size = (self.split_size,) * self.split_dims\n",
    "        if isinstance(self.stride, int):\n",
    "            self.stride = (self.stride,) * self.split_dims\n",
    "\n",
    "        assert (\n",
    "            len(self.stride) == len(self.split_size) == self.split_dims\n",
    "        ), \"Length of stride and split size must be equal to the number of spatial dimensions.\"\n",
    "\n",
    "        if self.raise_large_stride_error:\n",
    "            assert all(\n",
    "                st <= s for st, s in zip(self.stride, self.split_size)\n",
    "            ), \"Stride must be smaller than split size.\"\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f1f297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mSplitterConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33msplit_dims\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "        \u001b[33msplit_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33mextend_mode\u001b[0m=\u001b[32m'pad'\u001b[0m,\n",
       "        \u001b[33mraise_large_stride_error\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mSplitterConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33msplit_dims\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "        \u001b[33msplit_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33mextend_mode\u001b[0m=\u001b[32m'pad'\u001b[0m,\n",
       "        \u001b[33mraise_large_stride_error\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mSplitterConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33msplit_dims\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "        \u001b[33msplit_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33mextend_mode\u001b[0m=\u001b[32m'pad'\u001b[0m,\n",
       "        \u001b[33mraise_large_stride_error\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    SplitterConfig(split_size=6, stride=4),\n",
    "    SplitterConfig(split_size=6, stride=(4, 4, 4)),\n",
    "    SplitterConfig(split_size=(4, 5, 6), stride=(4, 4, 4)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056d019",
   "metadata": {},
   "source": [
    "# The magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ac9d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Splitter:\n",
    "    def __init__(self, config: SplitterConfig = {}, **kwargs):\n",
    "        self.config = SplitterConfig.model_validate(config | kwargs)\n",
    "\n",
    "    def get_expanded_shape(self, input_shape: tuple[int, ...] | torch.Size | torch.Tensor) -> tuple[int, ...]:\n",
    "        \"\"\"Get the shape of the input tensor after padding / wrapping.\n",
    "\n",
    "        Args:\n",
    "            input_shape: The shape of the input tensor. Only the last \"split_dims\" dimensions are considered. If a\n",
    "                tensor is passed, its shape will be used.\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing the shape of the input tensor after padding / wrapping.\n",
    "        \"\"\"\n",
    "        if isinstance(input_shape, torch.Tensor):\n",
    "            input_shape = input_shape.shape\n",
    "        self._check_input_shape(input_shape)\n",
    "        input_shape = list(input_shape[-self.config.split_dims :])\n",
    "\n",
    "        # Get shape after padding / wrapping\n",
    "        expanded_shape = []\n",
    "        for i in range(self.config.split_dims):\n",
    "            actual_length = input_shape[i]\n",
    "            split_length = self.config.split_size[i]\n",
    "            stride = self.config.stride[i]\n",
    "\n",
    "            # Minimum length is split size\n",
    "            total_length = max(actual_length, split_length)\n",
    "\n",
    "            # If a particular dimension can be split into n different splits, then the length of that dimensions is\n",
    "            # equal to split_size + (n - 1) * stride\n",
    "            # So the total length minus the split size must be divisible by the stride\n",
    "            total_length = total_length + (stride - (total_length - split_length)) % stride\n",
    "\n",
    "            input_shape[i] = total_length\n",
    "\n",
    "            expanded_shape.append(total_length)\n",
    "\n",
    "        return expanded_shape\n",
    "\n",
    "    def get_positions(self, input_shape: tuple[int, ...] | torch.Size | torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get the top-left coordinates of all the splits that will be generated using the config.\n",
    "\n",
    "        Args:\n",
    "            input_shape: The shape of the input tensor. Only the last \"split_dims\" dimensions are considered. If a\n",
    "                tensor is passed, its shape will be used.\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape (num_splits, split_dims) containing the top-left coordinates of each split.\n",
    "        \"\"\"\n",
    "        if isinstance(input_shape, torch.Tensor):\n",
    "            input_shape = input_shape.shape\n",
    "        self._check_input_shape(input_shape)\n",
    "        input_shape = list(input_shape[-self.config.split_dims :])\n",
    "\n",
    "        expanded_shape = self.get_expanded_shape(input_shape)\n",
    "\n",
    "        positions = []\n",
    "        for i in range(self.config.split_dims):\n",
    "            total_length = expanded_shape[i]\n",
    "            split_length = self.config.split_size[i]\n",
    "            stride = self.config.stride[i]\n",
    "\n",
    "            positions.append(torch.arange(0, total_length - split_length + 1, stride))\n",
    "        positions = torch.stack(torch.meshgrid(*positions, indexing=\"ij\"), dim=0)\n",
    "        positions = rearrange(positions, \"split_dims ... -> (...) split_dims\").contiguous()\n",
    "\n",
    "        return positions\n",
    "\n",
    "    def get_num_splits(self, input_shape: tuple[int, ...] | torch.Size | torch.Tensor) -> int:\n",
    "        \"\"\"Get the number of splits that will be generated using the config.\n",
    "\n",
    "        Args:\n",
    "            input_shape: The shape of the input tensor. Only the last \"split_dims\" dimensions are considered. If a\n",
    "                tensor is passed, its shape will be used.\n",
    "\n",
    "        Returns:\n",
    "            The number of splits that will be generated.\n",
    "        \"\"\"\n",
    "        if isinstance(input_shape, torch.Tensor):\n",
    "            input_shape = input_shape.shape\n",
    "        self._check_input_shape(input_shape)\n",
    "        input_shape = list(input_shape[-self.config.split_dims :])\n",
    "\n",
    "        positions = self.get_positions(input_shape)\n",
    "        num_splits = positions.shape[0]\n",
    "\n",
    "        return num_splits\n",
    "\n",
    "    def expand(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Expand the input tensor to the shape after padding / wrapping.\n",
    "\n",
    "        Args:\n",
    "            x: The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            The expanded tensor.\n",
    "        \"\"\"\n",
    "        self._check_input_shape(x.shape)\n",
    "        expanded_shape = self.get_expanded_shape(x.shape)\n",
    "\n",
    "        for i in range(self.config.split_dims):\n",
    "            dim = x.ndim - self.config.split_dims + i\n",
    "            expansion = expanded_shape[i] - x.shape[dim]\n",
    "            if expansion > 0:\n",
    "                if self.config.extend_mode == \"pad\":\n",
    "                    padding = (0, 0) * (self.config.split_dims - i - 1) + (expansion // 2, expansion - expansion // 2)\n",
    "                    x = F.pad(x, padding)\n",
    "                elif self.config.extend_mode == \"wrap\":\n",
    "                    x = torch.cat([x, x.narrow(dim, 0, expansion)], dim=dim)\n",
    "                elif self.config.extend_mode is None:\n",
    "                    assert expansion == 0, \"Exact divisibility is expected when extend_mode is None.\"\n",
    "\n",
    "        return x\n",
    "\n",
    "    def split(self, x: torch.Tensor) -> Generator[torch.Tensor, None, None]:\n",
    "        \"\"\"Split the input tensor into smaller tensors using the config.\n",
    "\n",
    "        Args:\n",
    "            x: The input tensor.\n",
    "\n",
    "        Yields:\n",
    "            A tensor of shape (*split_size) for each split.\n",
    "        \"\"\"\n",
    "        input_shape = x.shape\n",
    "        x = self.expand(x)\n",
    "        positions = self.get_positions(input_shape)\n",
    "\n",
    "        splits = []\n",
    "        for position in positions:\n",
    "            starts = position.tolist()\n",
    "            ends = [start + size for start, size in zip(starts, self.config.split_size)]\n",
    "\n",
    "            slices = [slice(None)] * (x.ndim - self.config.split_dims)\n",
    "            slices += [slice(starts[d], ends[d]) for d in range(self.config.split_dims)]\n",
    "            yield x[tuple(slices)]\n",
    "\n",
    "    @wraps(split)\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.split(*args, **kwargs)\n",
    "\n",
    "    def _check_input_shape(self, input_shape: tuple[int, ...]):\n",
    "        # Some checks\n",
    "        assert (\n",
    "            len(input_shape) >= self.config.split_dims\n",
    "        ), f\"Input shape {input_shape} must have at least {self.config.split_dims} length\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb2e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0\u001b[0m,  \u001b[1;36m1\u001b[0m,  \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m4\u001b[0m,  \u001b[1;36m5\u001b[0m,  \u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m8\u001b[0m,  \u001b[1;36m9\u001b[0m, \u001b[1;36m10\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m2\u001b[0m,  \u001b[1;36m3\u001b[0m,  \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m6\u001b[0m,  \u001b[1;36m7\u001b[0m,  \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m11\u001b[0m,  \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split in Splitter(split_dims=2, split_size=3, stride=2)(torch.arange(12).reshape((3, 4))):\n",
    "    display(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ab24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Merger:\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError(\"Merger is yet to be implemented.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2f605a",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024af1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c375a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
