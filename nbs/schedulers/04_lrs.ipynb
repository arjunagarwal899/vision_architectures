{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp schedulers/lrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from vision_architectures.schedulers.decaying_sine import DecayingSineLR  # noqa:F401\n",
    "from vision_architectures.schedulers.sigmoid import SigmoidLR  # noqa:F401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ConstantLRWithWarmup(LambdaLR):\n",
    "    def __init__(self, optimizer, warmup_steps, min_lr_ratio: float = 0.001, *args, **kwargs):\n",
    "        def lambda_fn(step):\n",
    "            return min(1, min_lr_ratio + (1 - min_lr_ratio) * (step / warmup_steps))\n",
    "\n",
    "        super().__init__(optimizer, lambda_fn, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: [0.001]\n",
      "Value: [0.1009]\n",
      "Value: [0.2008]\n",
      "Value: [0.30069999999999997]\n",
      "Value: [0.4006]\n",
      "Value: [0.5005]\n",
      "Value: [0.6003999999999999]\n",
      "Value: [0.7002999999999999]\n",
      "Value: [0.8002]\n",
      "Value: [0.9001]\n",
      "Value: [1]\n",
      "Value: [1]\n",
      "Value: [1]\n",
      "Value: [1]\n",
      "Value: [1]\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam([nn.Parameter()], 1)\n",
    "scheduler = ConstantLRWithWarmup(optimizer, 10)\n",
    "\n",
    "for _ in range(15):\n",
    "    print(f\"Value: {scheduler.get_lr()}\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
